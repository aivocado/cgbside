[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "KPMG Capstone Project",
    "section": "",
    "text": "이홍주, 이화정, 홍수민 으로 구성된 팀입니다."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CGBeta : CGINSIDE X KPMG Internship Team B",
    "section": "",
    "text": "프로젝트를 시작합니다!!!\n\n\n\n\n\n\n\n\n  \n\n\n\n\n1121_Sumin\n\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2023\n\n\nSumin Hong\n\n\n\n\n\n\n  \n\n\n\n\n1121_Data Plan\n\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2023\n\n\nHongJu Lee, Sumin Hong, Hwajeong Lee\n\n\n\n\n\n\n  \n\n\n\n\n1121_Hwajeong\n\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2023\n\n\nHwajeong Lee\n\n\n\n\n\n\n  \n\n\n\n\n1109_HongJu\n\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 20, 2023\n\n\nHongJu Lee\n\n\n\n\n\n\n  \n\n\n\n\nMarkDown 문법정리\n\n\n\n\n\n\n\ncode\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2023\n\n\nLee hong ju\n\n\n\n\n\n\n  \n\n\n\n\n1109_Sumin\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2023\n\n\nSumin Hong\n\n\n\n\n\n\n  \n\n\n\n\n1109_HongJu\n\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2023\n\n\nHongJu Lee\n\n\n\n\n\n\n  \n\n\n\n\n1109_Hwajeong\n\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 9, 2023\n\n\nHwaJeong Lee\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/1109_sumin/index.html",
    "href": "posts/1109_sumin/index.html",
    "title": "1109_Sumin",
    "section": "",
    "text": "Open AI DevDay Keynote\n\n시행 일시: 2023.11.07\nOpen AI가 실시한 첫 개발자 컨퍼런스  \n\n\nOpenAI가 새롭게 발표한 기능 정리\n\nGPT Builder: 대화형 챗봇 개발 환경 \n\n챗봇 사용 목적 등을 설명해주고, 추가 자료(pdf, img 등) 입력하면 맞춤형 챗봇 개발 가능\nGPT Store 이용해 GPT Builder로 개발된 챗봇 공유 및 사용 가능\n\nGPT Store 사이트 링크: https://gptbuilderstore.com/ (11월 말 런칭 예정) \n\n\nAPI 개선\n\nAssistants API\n\nBlackbox 해소 위해 Code interpreter, 답 제공 시 사용된 주요 parameter 제공\n\nJSON 모드 추가\n\nJSON 타입으로 답변\n\nSEED 값 세팅 가능\nLog Probability 제공 \n\nGPT-4 Turbo 출시\n\nContext Length 증가\n\n32K → 128K\n\nMore user control\n\n답변의 형식 지정 가능\n여러 함수 한 번에 처리 가능\n외부 문서, 정보 학습시켜서 사용 가능\n\nNew modalities\n\nVision, Speech 가능\n\nData Update\n\n2023년 4월 정보까지 학습됨  \n\n\n\n\n\n느낀점..\n컨퍼런스 영상을 시청하며, 아래의 두 장면이 가장 기억에 남았다.  \n이제 인공지능이 음성명령만으로 중요한 정보를 담아 포스터를 만들어주고, 인공지능을 간편하게 커스텀하여 여행 가이드로 사용할 수 있는 시대가 되었다.\n이 장면들을 보며, 전 세계 사람들이 각자만의 아이디어로 커스텀한 인공지능을 공유한다면, 어떤 획기적인 인공지능 서비스가 탄생할지 11월 말이 기대가 되었다.\n그러나, 데이터 사이언티스트를 꿈꾸며 인공지능을 공부하는 학생으로서, 다소 우려가 되기도 하였다. 기존에는 인공지능을 활용해 서비스를 런칭할 때, 데이터를 수집하고, 정제하여, 코드로 fine-tuning하는 작업을 거쳐야했다. 그러나 이제는 코드 없이 음성명령만으로 간편하게 모델을 커스텀하는 것이 가능해졌다. 다시 말해, 인공지능 개발자나 데이터 사이언티스트가 아닌 일반인들도 단순히 인공지능 서비스를 소비하는 것을 넘어 인공지능을 활용할 수 있게 되었다. 이러한 상황에서 데이터 사이언티스트의 역할과 데이터 사이언티스트가 지녀야 할 소양이 무엇일지에 대한 고민을 해보게 되었다.\n추가적으로, 음성명령만으로 인공지능에게 입금을 하도록 하는 시연을 보며, 인공지능이 검색 엔진, 금융 시스템, 사내 데이터베이스 등과 결합된다면 훨씬 더 편리하고 효율적인 일상이 되겠다는 상상을 할 수 있었다. 다만, 이를 위해서는 개인정보 보호 문제, 저작권 문제 등이 먼저 해결되어야 하는 만큼, 기술적으로는 개인정보를 보호할 수 있는 방법에 대한 연구, 윤리적으로는 개인정보 및 저작물 활용에 대한 논의가 우선적으로 필요할 것으로 보인다."
  },
  {
    "objectID": "posts/1109_sumin/index.html#홍수민-블로그-테스트중입니다.",
    "href": "posts/1109_sumin/index.html#홍수민-블로그-테스트중입니다.",
    "title": "1109_Sumin",
    "section": "",
    "text": "세부 사항은 추후 추가해서 올리겠습니다."
  },
  {
    "objectID": "how_to_use_github.html",
    "href": "how_to_use_github.html",
    "title": "GitHub 협업 사용 방법 정리",
    "section": "",
    "text": "GitHub 협업 사용 방법 정리\n\n공유 레포지토리에서 fork로 내 고유 레포지토리로 불러오기\n내 레포지토리 URL을 내가 원하는 파일의 터미널로 들어가 [git clone URL주소] 입력\nvscode를 열고 clone한 파일 가져오기\n원하는 내용 수정\nvscode -&gt; 소스제어 -&gt; commit 메세지 입력 후 (commit + 동기화)\ngithub에서 변경사항 잘 저장 되었는지 확인\n변경사항 확인 후 이상 없으면 pull requests 진행\n관리자에게 merge 요청 하기\n\n\n(번외)\n\n기존 프로젝트 내용 가져오고 싶을땐 내 고유 레포지토리에 sync fork 진행 후 해당 폴더 경로로 들어가 [git pull] 후 작업 진행"
  },
  {
    "objectID": "posts/1109_hongju/index.html",
    "href": "posts/1109_hongju/index.html",
    "title": "1109_HongJu",
    "section": "",
    "text": "open AI 컨퍼런스 정리\n얼마 전 open ai에서 개발자들을 대상으로 devday 행사가 열렸다. 이에 유튜브로 해당 내용들을 확인하고 정리해 보고자 한다.\n\n\n\nAI 서비스의 핵심이 된 gpt의 사용자 현황\n\n\n이번 컨퍼런스의 핵심 내용은 gpts 서비스 제공인 것 같다. 앞서 발표자가 설명하는 gpt4 turbo의 변경사항들 모두 gpts 서비스 제공을 위한 개선 사항들이라고 할 수 있을 정도로 gpts 서비스 제공에 초점을 맞춘 업데이트라고 생각된다.\n\n\nGPT4 turbo 업데이트 사항\n\n수용 가능한 input의 크기 변화\n→ 기존의 input 크기 토큰 8,000개에서 토큰 128,000개로 input의 수용 가능한 크기를 대폭 향상시켜 더 큰 데이터를 학습 시키고 질문할 수 있게 바뀌었다. 이는 300페이지 짜리 문서도 학습 시킬 수 있다는 것으로 논문이나 책, 보고서 등의 학습도 가능해졌다.\napi 가격 절감\n→ 기존 gpt4와 비교했을 때 input은 3배, output은 2배의 비용을 절감시켜 일반 개발자들이 더 싼 비용으로 gpt의 ai 서비스 호출이 가능해졌다.\nJSON 형태로 output 지정 가능\n→ JSON 형태로 호출 지정을 가능하게 해줘 서버 및 다른 api와의 연동 또한 사용하기 쉬워졌다.\nDALL-E 3 모델 지원 및 text-음성 변환 기술 제공\n→ 사진의 캡션을 생성하거나, 실제 이미지를 상세히 분석하고, 그림이 포함된 문서를 읽는 등의 작업이 가능해졌다. 여기서 핵심은 api에서 DELL-E 3를 사용 가능해 졌기 때문에 자신이 생성한 앱에 이 기능을 api형태로 추가 가능해 졌다는 것이다.\n데이터 보안\n→ OpenAI API에 전달된 데이터와 파일은 모델을 훈련하는 데 사용되지 않으며, 개발자는 적절하다고 판단될 때 데이터를 삭제할 수 있어 기업의 데이터 유출 문제를 해결할 수 있다. 또한 데이터에 민감한 기업에게는 custom models을 제공해 다른 고객에게 제공되거나 공유되지 않고 다른 모델을 훈련하는 데에도 사용되지 않는다.\n\n\n\nGPTs 서비스\n\n\n\nassistant api 적용 화면\n\n\n\n\n\ncode interpreter 적용 화면\n\n\n앞서 설명한 gpt4 turbo 모델을 이용해서 최종적으로 open ai에서 할 목표는 gpts 서비스 제공이다. 대부분의 LLM모델의 단점이 모든 도메인을 아우르는 LLM모델을 만들기 어렵다는 점이다. 특정 도메인 분야에서 더 정확한 모델을 얻기 위해서는 각 도메인의 데이터를 이용해 사전 학습하는 과정을 거쳐야 하고 gpt에서는 학습을 위해 긴 프롬프팅이 필요하다. 이번 open ai 컨퍼런스의 gpts는 이 문제를 해결할 것으로 보인다. 앞서 설명했던 input 크기 향상, 다양한 형태의 데이터 api 전송 가능, 가격 인하로 인해 더 많은 개발자들이 도메인 맞춤형 gpt를 생성할 수 있게 되었고 이를 서비스해 수익까지 창출할 수 있게 되었다. 기존의 app store의 형태처럼 AI 서비스 역시 맞춤형 gpt 모델을 제공하면서 일반 사용자들이 보다 더 쉽게 ai 서비스 접근이 가능해진 것이다. 또한 모델의 사전 학습 단계에서도 gpt를 사용해 학습이 가능하기 때문에 일반 사용자들도 데이터만 있다면 ai 개발자가 되어 자신만의 맞춤형 모델을 생성하고 서비스 가능해졌다. 실제로 open ai에서 시연했던 assistant api를 보면 이것이 구현 가능함을 보여줬다. 이로 인해 AI에 대한 일반인들의 접근성이 좋아져 더 활발한 AI 생태계 구축을 목표로 하는 것 같다.\n\n\nGPTs를 보며 든 나의 생각\ngpts를 보면서 나는 두 가지 사항을 생각해 보았다.\n첫 번째로 산업의 개편이다. gpts가 상용화된다면 AI서비스를 개인 맞춤형으로 사용 가능해질 것이다. assistant api와 같은 서비스가 활성화된다면 기존의 AI모델을 사용 및 개발하기 위한 사전 지식의 역치가 많이 낮아질 것이다. 따라서 개발자나 컨설턴트 등의 직종이 심각하게 위협을 받을 것으로 예상된다.\n두 번째로는 정보 보안이 더욱 중요해질 것으로 보인다. 컨퍼런스에서는 기업의 데이터를 학습하지 않는다고 했지만 이는 open ai에서 주장하는 바로 실제로 데이터를 학습하는지 여부는 알 수 없다. 삼성, KT과 같은 대기업들에서 gpt를 사용하지 않고 자체적인 LLM모델을 만들어 사용하려는 이유도 여기에 있다. 따라서 데이터를 암호화해서 학습시키고 결과를 도출해 내는 동형 암호와 같은 암호 기술들의 발전이 산업에서의 AI 활성화에 있어 필수 조건이라고 생각된다."
  },
  {
    "objectID": "posts/1109_hongju/index.html#이홍주-블로그-테스트중입니다.",
    "href": "posts/1109_hongju/index.html#이홍주-블로그-테스트중입니다.",
    "title": "1109_HongJu",
    "section": "",
    "text": "세부 사항은 추후 추가해서 올리겠습니다."
  },
  {
    "objectID": "posts/1109_hwajeong/index.html",
    "href": "posts/1109_hwajeong/index.html",
    "title": "1109_Hwajeong",
    "section": "",
    "text": "지난 1년간, OpenAI는 ChatGPT, GPT-4, DALL•E 3(이미지 모델) 등의 모델을 출시하였고, 약 2백만 개발자와 92% 이상의 포춘 500 대기업이 OpenAI 제품을 사용하고 있다고 한다.\n\nChatGPT는 주간 활성 사용자가 무려 약 1억 명에 이른다고 한다. 이를 통해 OpenAI는 현재 세계에서 가장 선진적이고 널리 사용되는 AI 플랫폼임을 입증한 것 같다.\n\n\n\n\nKeynote의 하이라이트는 다양한 사용자 요구를 처리하는 혁신적인 모델인 GPT-4 Turbo의 소개였다. 여섯 가지 주요 개선 사항을 반영하였는데 내용은 다음과 같다.\n\nContext length : 기존 8k context에서 16배 긴 128k context 지원. (128,000 토큰, 표준 서적의 300페이지에 달함)\nMore control : Json Load 기능, Logprobs 기능, 재현 가능한 출력이라는 새로운 기능을 도입(시드 매개변수를 전달하면 모델이 일관된 출력을 반환한다.)\nBetter knowledge : 검색 기능을 도입하여 외부 지식 통합가능, 지식 cutoff도 2023.4월로 업데이트 됨.\nNew modalities : DALL•E 3, GPT-4 Turbo, 그리고 새로운 TTS 모델이 모두 API에 도입됨. *오픈 소스 음성 인식 모델인 Whisper V3의 다음 버전 출시 예정이며 이 또한 곧 API에 도입될 예정.\nCostomization : GPT-3.5 16k fine-tuning 가능, GPT-4 fine-tuning 일부 사용자에게 access 허용, custom model 출시(기업 고객용)\nHigher rate limit : 토큰당 분당 속도를 두 배로 늘릴 예정. API 계정 설정에서 추가적인 속도 제한과 할당량을 변경할 수 있게 됨.\n\n\n\n\n\nOpenai devday에서, 발표자들이 ’저작권’과 ’보안’에 대한 언급을 자주 하는 것을 볼 수 있다.\n\n기업 고객들을 더 끌어들이기 위해서는 걸림돌인 ‘저작권 및 보안’ 문제를 언급하지 않을 수 없는데 이 문제에서 벗어나기 위한 노력의 일환으로 ‘Copyright Shield’ 서비스 또한 새롭게 선보였다.\n\n저작권 침해에 대한 법적 주장이 제기될 경우, OpenAI가 고객을 대신하여 법적 대응을 지원하고 관련 비용을 부담한다는 내용이었다. ChatGPT Enterprise와 API 모두에 적용이 될 예정이다.\n\n다시한번, OpenAI는 API나 ChatGPT Enterprise에서의 데이터로 훈련하지 않는다는 점을 강조하였다.\n\n+추가적으로 가장 중요한 2가지 개선사항을 발표하였다.\n\n\n\n\nGPT-4 Turbo : 천 개의 프롬프트 토큰당 1센트, 천 개의 완료 토큰당 0.03달러 (프롬프트 토큰에 대해 3배, 완료 토큰에 대해 2배의 비율로 GPT-4보다 저렴, 3.75% 이상 더 저렴)\nGPT-3.5 Turbo 16k : input 토큰은 3배, ouput 토큰은 2배 더 저렴\nGPT-4 Turbo 속도 개선 예정\n\n여기까지, 모델 자체에 대한 개선사항이었다.\n\n\n\n다음으로는 Microsoft의 CEO인 Satya Nadella가 특별 게스트로 나왔는데, OpenAI와의 파트너십에 대해 강조하였다.\n\nAzure를 기반으로 최고의 시스템을 구축하고 개발자들에게 제공하여 최고의 모델을 만들 수 있도록 지원하겠다고 밝혔다. 또한, 개발자로서 자체 제품을 개발 중이며, OpenAI의 API를 활용하여 GitHub Copilot과 같은 제품을 만들 계획이라고 한다. (현재 Copilot 기능에 gpt api를 도입하는 것 같다.) Azure 마켓플레이스를 통해 제품을 신속히 출시하고 시장에 내놓을 예정이며 마지막으로, Microsoft와 OpenAI의 공통 목표는 인공지능의 이점을 모든 사람에게 전달하는 것이라며 마무리를 하였다.\n\n+또 다른 ‘작은’ 개선사항 하나 더!\n모델 picker가 사라졌다! (드롭다운 박스 없어짐) ChatGPT가 알아서, 언제 어떤 것을 사용해야 하는지 자동으로 처리해 준다고 한다.\n\n\n\n\nOpenAI는 AI의 안전성 문제를 해결하는 가장 효과적인 방법은 점진적이고 반복적인 배포라고 강조하고 있다. 이에 그 첫 단계로 GPTs라는 새로운 기술을 소개했다.\nGPTs는 특정 목적을 위해 구성된 ChatGPT의 맞춤형 버전이다.\n여기서도 ’보안’에 대한 언급을 한다. 모든 작업을 수행하기 전 ’allow’를 통해 사용자의 허가를 받게 끔 설정되어 있다.\n코딩 없이, 자연어로만으로 GPT를 만드는 데모를 보여준다.\n\n\n\n\n위에서 소개한 다양한 맞춤형 GPTs들을 생성하고 공유할 수 있는 마켓플레이스인 GPT Store가 출시예정이다.\n+사용자 수에 따른 수익 창출도 가능하다고 하니, 다양한 사람들의 다양한 GPT들이 공유될 수 있는 장을 마련한 것 같다. 어떤 GPT들이 나올지 기대가 된다.\n\n\n\n개인적으로는 GPT API를 통해서 개발 경험이 없어서 와닿지는 않았던 부분이지만, 개발자들이 API를 활용하여 더욱 효율적으로 개발할 수 있도록 개선된 부분인 것 같다.\n\nGPT API를 활용하여 에이전트 형태의 경험을 제공하는 앱이 이미 개발되고 있는데, 과거에는 이를 개발하는 것이 어렵고 시간이 많이 걸렸다.하지만 새롭게 출시된 Assistants API를 통해 이를 더 쉽고 편리하게 할 수 있다.\nAssistants API에는 Threading, Python 인터프리터, Function calling 등 다양한 기능이 포함되어 있다.\n음성인식으로 만든 Assistant API를 통해서 Devday 참석자들에게 토큰 500달러를 지급하는 데모를 보여주었다!\n\n\n\n\n\nOpenAI의 Devday를 통해 다양한 기능들이 소개되었다. GPT-4 Turbo는 기존의 GPT-3.5와 비교했을 때 더욱 강력한 기능들을 가지고 있었다. 특히 GPTs, GPT store가 출시됨에 따라 어떤 다양한 커스텀된 GPT들이 나올지 기대가 된다.\nAI가 모든 것에 통합되면서, 마치 스마트폰이 우리의 삶에 깊숙이 녹아든 것처럼, ChatGPT 없이는 생활이 불가능한 시대가 올 것 같다.\n인상깊었던 부분은, OpenAI가 많은 사람들이 인공지능 기술을 접근 가능하게 하기위해 노력하고 있는 부분이었다. OpensAI는 AI기술을 사용할 때 개인의 권한 및 효용성을 최고로 살리는 것이 중요하다는 점을 끊임없이 강조한다. 이를 통해 개인들이 더 나은 도구를 활용하여 세상을 변화시킬 수 있는 기회를 얻을 수 있을 것 같다."
  },
  {
    "objectID": "posts/1109_hwajeong/index.html#이화정-블로그-테스트중입니다.",
    "href": "posts/1109_hwajeong/index.html#이화정-블로그-테스트중입니다.",
    "title": "1109_Hwajeong",
    "section": "",
    "text": "세부 사항은 추후 추가해서 올리겠습니다."
  },
  {
    "objectID": "posts/how_to_use_markdown/index.html",
    "href": "posts/how_to_use_markdown/index.html",
    "title": "MarkDown 문법정리",
    "section": "",
    "text": "이건 인용하는데 사용하는 코드입니다.\n\n\n\n\ngit 공부\n프로젝트 수정\n\n\n\n\n\n작대기\n\n점\n\n더하기\n\n\n\n\n\n\npython 코드\ndef greet(name):\n    print(f\"Hello, {name}!\")\ndef hello():\n    print(\"hello world\")\n코드 종료\n\n\n\n\n구글 링크 추가 구글 링크\n\n\n\n\n\n\n\nAlt text"
  },
  {
    "objectID": "posts/how_to_use_markdown/index.html#마크다운-문법-정리입니다.",
    "href": "posts/how_to_use_markdown/index.html#마크다운-문법-정리입니다.",
    "title": "MarkDown 문법정리",
    "section": "",
    "text": "이건 인용하는데 사용하는 코드입니다.\n\n\n\n\ngit 공부\n프로젝트 수정\n\n\n\n\n\n작대기\n\n점\n\n더하기\n\n\n\n\n\n\npython 코드\ndef greet(name):\n    print(f\"Hello, {name}!\")\ndef hello():\n    print(\"hello world\")\n코드 종료\n\n\n\n\n구글 링크 추가 구글 링크\n\n\n\n\n\n\n\nAlt text"
  },
  {
    "objectID": "about.html#이홍주",
    "href": "about.html#이홍주",
    "title": "KPMG 캡스톤",
    "section": "이홍주",
    "text": "이홍주"
  },
  {
    "objectID": "ihongju.html",
    "href": "ihongju.html",
    "title": "CGINSIDE_TEAM B",
    "section": "",
    "text": "여기에 이홍주의 추가 정보 및 프로필 내용을 작성하세요."
  },
  {
    "objectID": "posts/1109_hwajeong/index.html#openai-devday-개막-keynote",
    "href": "posts/1109_hwajeong/index.html#openai-devday-개막-keynote",
    "title": "1109_Hwajeong",
    "section": "",
    "text": "지난 1년간, OpenAI는 ChatGPT, GPT-4, DALL•E 3(이미지 모델) 등의 모델을 출시하였고, 약 2백만 개발자와 92% 이상의 포춘 500 대기업이 OpenAI 제품을 사용하고 있다고 한다.  ChatGPT는 주간 활성 사용자가 무려 약 1억 명에 이른다고 한다. 이를 통해 OpenAI는 현재 세계에서 가장 선진적이고 널리 사용되는 AI 플랫폼임을 입증한 것 같다.\n\n\n\nKeynote의 하이라이트는 다양한 사용자 요구를 처리하는 혁신적인 모델인 GPT-4 Turbo의 소개였다. 여섯 가지 주요 개선 사항을 반영하였는데 내용은 다음과 같다.\n\nContext length : 기존 8k context에서 16배 긴 128k context 지원. (128,000 토큰, 표준 서적의 300페이지에 달함)\nMore control : Json Load 기능, Logprobs 기능, 재현 가능한 출력이라는 새로운 기능을 도입(시드 매개변수를 전달하면 모델이 일관된 출력을 반환한다.)\nBetter knowledge : 검색 기능을 도입하여 외부 지식 통합가능, 지식 cutoff도 2023.4월로 업데이트 됨.\nNew modalities : DALL•E 3, GPT-4 Turbo, 그리고 새로운 TTS 모델이 모두 API에 도입됨. *오픈 소스 음성 인식 모델인 Whisper V3의 다음 버전 출시 예정이며 이 또한 곧 API에 도입될 예정.\nCostomization : GPT-3.5 16k fine-tuning 가능, GPT-4 fine-tuning 일부 사용자에게 access 허용, custom model 출시(기업 고객용)\nHigher rate limit : 토큰당 분당 속도를 두 배로 늘릴 예정. API 계정 설정에서 추가적인 속도 제한과 할당량을 변경할 수 있게 됨.\n\n\n\n\nOpenai devday에서, 발표자들이 ‘저작권’과 ‘보안’에 대한 언급을 자주 하는 것을 볼 수 있다. 기업 고객들을 더 끌어들이기 위해서는 걸림돌인 ’저작권 및 보안’ 문제를 언급하지 않을 수 없는데 이 문제에서 벗어나기 위한 노력의 일환으로 ‘Copyright Shield’ 서비스 또한 새롭게 선보였다. 저작권 침해에 대한 법적 주장이 제기될 경우, OpenAI가 고객을 대신하여 법적 대응을 지원하고 관련 비용을 부담한다는 내용이었다. ChatGPT Enterprise와 API 모두에 적용이 될 예정이다.  다시한번, OpenAI는 API나 ChatGPT Enterprise에서의 데이터로 훈련하지 않는다는 점을 강조하였다.\n+추가적으로 가장 중요한 2가지 개선사항을 발표하였다.\n\n\n\n\nGPT-4 Turbo : 천 개의 프롬프트 토큰당 1센트, 천 개의 완료 토큰당 0.03달러 (프롬프트 토큰에 대해 3배, 완료 토큰에 대해 2배의 비율로 GPT-4보다 저렴, 3.75% 이상 더 저렴)\nGPT-3.5 Turbo 16k : input 토큰은 3배, ouput 토큰은 2배 더 저렴\nGPT-4 Turbo 속도 개선 예정\n\n여기까지, 모델 자체에 대한 개선사항이었다.\n\n\n\n다음으로는 Microsoft의 CEO인 Satya Nadella가 특별 게스트로 나왔는데, OpenAI와의 파트너십에 대해 강조하였다.\n\nAzure를 기반으로 최고의 시스템을 구축하고 개발자들에게 제공하여 최고의 모델을 만들 수 있도록 지원하겠다고 밝혔다. 또한, 개발자로서 자체 제품을 개발 중이며, OpenAI의 API를 활용하여 GitHub Copilot과 같은 제품을 만들 계획이라고 한다. (현재 Copilot 기능에 gpt api를 도입하는 것 같다.) Azure 마켓플레이스를 통해 제품을 신속히 출시하고 시장에 내놓을 예정이며 마지막으로, Microsoft와 OpenAI의 공통 목표는 인공지능의 이점을 모든 사람에게 전달하는 것이라며 마무리를 하였다.\n\n+또 다른 ‘작은’ 개선사항 하나 더!\n모델 picker가 사라졌다! (드롭다운 박스 없어짐) ChatGPT가 알아서, 언제 어떤 것을 사용해야 하는지 자동으로 처리해 준다고 한다.\n\n\n\n\nOpenAI는 AI의 안전성 문제를 해결하는 가장 효과적인 방법은 점진적이고 반복적인 배포라고 강조하고 있다. 이에 그 첫 단계로 GPTs라는 새로운 기술을 소개했다.\nGPTs는 특정 목적을 위해 구성된 ChatGPT의 맞춤형 버전이다.\n여기서도 ’보안’에 대한 언급을 한다. 모든 작업을 수행하기 전 ’allow’를 통해 사용자의 허가를 받게 끔 설정되어 있다.\n코딩 없이, 자연어로만으로 GPT를 만드는 데모를 보여준다.\n\n\n\n\n위에서 소개한 다양한 맞춤형 GPTs들을 생성하고 공유할 수 있는 마켓플레이스인 GPT Store가 출시예정이다.\n+사용자 수에 따른 수익 창출도 가능하다고 하니, 다양한 사람들의 다양한 GPT들이 공유될 수 있는 장을 마련한 것 같다. 어떤 GPT들이 나올지 기대가 된다.\n\n\n\n개인적으로는 GPT API를 통해서 개발 경험이 없어서 와닿지는 않았던 부분이지만, 개발자들이 더욱 효율적으로 개발할 수 있도록 개선된 부분인 것 같다. - GPT API를 활용하여 에이전트 형태의 경험을 제공하는 앱이 이미 개발되고 있는데, 과거에는 이를 개발하는 것이 어렵고 시간이 많이 걸렸다. - 하지만 새롭게 출시된 Assistants API를 통해 이를 더 쉽고 편리하게 할 수 있다. - Assistants API에는 대화 기록, Python 인터프리터, 기능 호출 등 다양한 기능이 포함되어 있다. - 음성인식으로 만든 Assistant API를 통해서 Devday 참석자들에게 토큰 500달러를 지급하는 데모를 보여주었다!\n\n\n\n\nOpenAI의 Devday를 통해 다양한 기능들이 소개되었다. GPT-4 Turbo는 기존의 GPT-3.5와 비교했을 때 더욱 강력한 기능들을 가지고 있었다. 특히 GPTs, GPT store가 출시됨에 따라 얼마나 다양한 커스텀된 GPT들이 나올지 기대가 된다.\nAI가 모든 것에 통합되면서, 마치 스마트폰이 우리의 삶에 깊숙이 녹아든 것처럼, ChatGPT 없이는 생활이 불가능한 시대가 올 것 같다.\n인상깊었던 부분은, OpenAI가 많은 사람들이 인공지능 기술을 접근 가능하게 하기위해 노력하고 있는 부분이었다. OpensAI는 AI기술을 사용할 때 개인의 권한 및 효용성을 최고로 살리는 것이 중요하다는 점을 끊임없이 강조한다. 이를 통해 개인들이 더 나은 도구를 활용하여 세상을 변화시킬 수 있는 기회를 얻을 수 있을 것 같다."
  },
  {
    "objectID": "posts/1109_hwajeong/index.html#월-말-gpt-store-공개-예정",
    "href": "posts/1109_hwajeong/index.html#월-말-gpt-store-공개-예정",
    "title": "1109_Hwajeong",
    "section": "11월 말, GPT Store 공개 예정",
    "text": "11월 말, GPT Store 공개 예정\nOpenAI는 GPT Store를 공개했습니다. 이는 개발자들이 다양한 애플리케이션에 대해 맞춤형 GPT를 생성하고 공유할 수 있는 마켓플레이스입니다. GPT Store는 자연어 프로그래밍을 강조하며, 사용자가 대화식으로 상호작용하여 GPT를 프로그래밍할 수 있게 합니다.\n수익 분배도 가능함\n\nassistant API에서의 새로운 모달리티와 개선 사항(개발자들을 위한)\n앱 내 특수 보조자, 문서 파싱 기능, 그리고 동적 코드 생성 및 실행을 가능하게 하는 Code Interpreter가 포함되어있다.\n\nGPT API를 활용하여 에이전트 형태의 경험을 제공하는 앱이 이미 개발되고 있는데, 과거에는 이를 개발하는 것이 어렵고 시간이 많이 걸렸다.\n하지만 오늘날, 새롭게 출시된 Assistants API를 통해 이를 더 쉽고 편리하게 할 수 있다.\nAssistants API에는 대화 기록, Python 인터프리터, 기능 호출 등 다양한 기능이 포함되어 있다.\n또한, 개발자 경험도 개선되었으며, 이를 위해 새로운 모달리티가 도입되었다\n\n데모(음성인식으로 만든 assistant api를 통해서 500달러 지급)\n\n\n\n\n결론\n\nAI 기술을 사용할 때 개인의 권한 및 효용성을 최고로 살리는 것이 가장 중요하다고 본다. 이를 통해 인류는 세계사에서 결코 본 적 없는 차원의 혁신을 이룰 수 있을 것이다.\n모든 것이 AI로 접목됨에 따라, 우리는 모두가 수요에 따라 상황에 맞추어 초능력을 발휘할 수 있게 될 것이다.\nOpenAI 팀은 이러한 기술이 보다 혁신적이고 발전된 모습으로 발표될 것을 약속하며, 우리가 함께 만들어갈 길고 놀라운 미래를 기대한다.\nopenai devday를 보면, 중간중간 발표자들이 ’저작권’과 ’보안’에 대한 언급을 자주 하는 것을 볼 수 있다.\n\n\n우리는 ’저작권 보호’를 도입하고 있습니다. 저작권 보호란 저희가 고객들을 지원하고, 저작권 침해에 대한 법적 주장에 직면했을 때 발생하는 비용을 지불하겠다는 것을 의미하며, 이는 ChatGPT Enterprise와 API 모두에 적용됩니다. 확실히 말하자면, 이것은 사람들에게 우리가 API나 ChatGPT Enterprise에서의 데이터로 훈련하지 않는다는 것을 상기시키는 좋은 시기입니다."
  },
  {
    "objectID": "posts/1109_hwajeong/index.html#openai-devday-opening-keynote-리뷰",
    "href": "posts/1109_hwajeong/index.html#openai-devday-opening-keynote-리뷰",
    "title": "1109_Hwajeong",
    "section": "",
    "text": "지난 1년간, OpenAI는 ChatGPT, GPT-4, DALL•E 3(이미지 모델) 등의 모델을 출시하였고, 약 2백만 개발자와 92% 이상의 포춘 500 대기업이 OpenAI 제품을 사용하고 있다고 한다.\n\nChatGPT는 주간 활성 사용자가 무려 약 1억 명에 이른다고 한다. 이를 통해 OpenAI는 현재 세계에서 가장 선진적이고 널리 사용되는 AI 플랫폼임을 입증한 것 같다.\n\n\n\n\nKeynote의 하이라이트는 다양한 사용자 요구를 처리하는 혁신적인 모델인 GPT-4 Turbo의 소개였다. 여섯 가지 주요 개선 사항을 반영하였는데 내용은 다음과 같다.\n\nContext length : 기존 8k context에서 16배 긴 128k context 지원. (128,000 토큰, 표준 서적의 300페이지에 달함)\nMore control : Json Load 기능, Logprobs 기능, 재현 가능한 출력이라는 새로운 기능을 도입(시드 매개변수를 전달하면 모델이 일관된 출력을 반환한다.)\nBetter knowledge : 검색 기능을 도입하여 외부 지식 통합가능, 지식 cutoff도 2023.4월로 업데이트 됨.\nNew modalities : DALL•E 3, GPT-4 Turbo, 그리고 새로운 TTS 모델이 모두 API에 도입됨. *오픈 소스 음성 인식 모델인 Whisper V3의 다음 버전 출시 예정이며 이 또한 곧 API에 도입될 예정.\nCostomization : GPT-3.5 16k fine-tuning 가능, GPT-4 fine-tuning 일부 사용자에게 access 허용, custom model 출시(기업 고객용)\nHigher rate limit : 토큰당 분당 속도를 두 배로 늘릴 예정. API 계정 설정에서 추가적인 속도 제한과 할당량을 변경할 수 있게 됨.\n\n\n\n\n\nOpenai devday에서, 발표자들이 ’저작권’과 ’보안’에 대한 언급을 자주 하는 것을 볼 수 있다.\n\n기업 고객들을 더 끌어들이기 위해서는 걸림돌인 ‘저작권 및 보안’ 문제를 언급하지 않을 수 없는데 이 문제에서 벗어나기 위한 노력의 일환으로 ‘Copyright Shield’ 서비스 또한 새롭게 선보였다.\n\n저작권 침해에 대한 법적 주장이 제기될 경우, OpenAI가 고객을 대신하여 법적 대응을 지원하고 관련 비용을 부담한다는 내용이었다. ChatGPT Enterprise와 API 모두에 적용이 될 예정이다.\n\n다시한번, OpenAI는 API나 ChatGPT Enterprise에서의 데이터로 훈련하지 않는다는 점을 강조하였다.\n\n+추가적으로 가장 중요한 2가지 개선사항을 발표하였다.\n\n\n\n\nGPT-4 Turbo : 천 개의 프롬프트 토큰당 1센트, 천 개의 완료 토큰당 0.03달러 (프롬프트 토큰에 대해 3배, 완료 토큰에 대해 2배의 비율로 GPT-4보다 저렴, 3.75% 이상 더 저렴)\nGPT-3.5 Turbo 16k : input 토큰은 3배, ouput 토큰은 2배 더 저렴\nGPT-4 Turbo 속도 개선 예정\n\n여기까지, 모델 자체에 대한 개선사항이었다.\n\n\n\n다음으로는 Microsoft의 CEO인 Satya Nadella가 특별 게스트로 나왔는데, OpenAI와의 파트너십에 대해 강조하였다.\n\nAzure를 기반으로 최고의 시스템을 구축하고 개발자들에게 제공하여 최고의 모델을 만들 수 있도록 지원하겠다고 밝혔다. 또한, 개발자로서 자체 제품을 개발 중이며, OpenAI의 API를 활용하여 GitHub Copilot과 같은 제품을 만들 계획이라고 한다. (현재 Copilot 기능에 gpt api를 도입하는 것 같다.) Azure 마켓플레이스를 통해 제품을 신속히 출시하고 시장에 내놓을 예정이며 마지막으로, Microsoft와 OpenAI의 공통 목표는 인공지능의 이점을 모든 사람에게 전달하는 것이라며 마무리를 하였다.\n\n+또 다른 ‘작은’ 개선사항 하나 더!\n모델 picker가 사라졌다! (드롭다운 박스 없어짐) ChatGPT가 알아서, 언제 어떤 것을 사용해야 하는지 자동으로 처리해 준다고 한다.\n\n\n\n\nOpenAI는 AI의 안전성 문제를 해결하는 가장 효과적인 방법은 점진적이고 반복적인 배포라고 강조하고 있다. 이에 그 첫 단계로 GPTs라는 새로운 기술을 소개했다.\nGPTs는 특정 목적을 위해 구성된 ChatGPT의 맞춤형 버전이다.\n여기서도 ’보안’에 대한 언급을 한다. 모든 작업을 수행하기 전 ’allow’를 통해 사용자의 허가를 받게 끔 설정되어 있다.\n코딩 없이, 자연어로만으로 GPT를 만드는 데모를 보여준다.\n\n\n\n\n위에서 소개한 다양한 맞춤형 GPTs들을 생성하고 공유할 수 있는 마켓플레이스인 GPT Store가 출시예정이다.\n+사용자 수에 따른 수익 창출도 가능하다고 하니, 다양한 사람들의 다양한 GPT들이 공유될 수 있는 장을 마련한 것 같다. 어떤 GPT들이 나올지 기대가 된다.\n\n\n\n개인적으로는 GPT API를 통해서 개발 경험이 없어서 와닿지는 않았던 부분이지만, 개발자들이 API를 활용하여 더욱 효율적으로 개발할 수 있도록 개선된 부분인 것 같다.\n\nGPT API를 활용하여 에이전트 형태의 경험을 제공하는 앱이 이미 개발되고 있는데, 과거에는 이를 개발하는 것이 어렵고 시간이 많이 걸렸다.하지만 새롭게 출시된 Assistants API를 통해 이를 더 쉽고 편리하게 할 수 있다.\nAssistants API에는 Threading, Python 인터프리터, Function calling 등 다양한 기능이 포함되어 있다.\n음성인식으로 만든 Assistant API를 통해서 Devday 참석자들에게 토큰 500달러를 지급하는 데모를 보여주었다!\n\n\n\n\n\nOpenAI의 Devday를 통해 다양한 기능들이 소개되었다. GPT-4 Turbo는 기존의 GPT-3.5와 비교했을 때 더욱 강력한 기능들을 가지고 있었다. 특히 GPTs, GPT store가 출시됨에 따라 어떤 다양한 커스텀된 GPT들이 나올지 기대가 된다.\nAI가 모든 것에 통합되면서, 마치 스마트폰이 우리의 삶에 깊숙이 녹아든 것처럼, ChatGPT 없이는 생활이 불가능한 시대가 올 것 같다.\n인상깊었던 부분은, OpenAI가 많은 사람들이 인공지능 기술을 접근 가능하게 하기위해 노력하고 있는 부분이었다. OpensAI는 AI기술을 사용할 때 개인의 권한 및 효용성을 최고로 살리는 것이 중요하다는 점을 끊임없이 강조한다. 이를 통해 개인들이 더 나은 도구를 활용하여 세상을 변화시킬 수 있는 기회를 얻을 수 있을 것 같다."
  },
  {
    "objectID": "about.html#team-members",
    "href": "about.html#team-members",
    "title": "CGBeta",
    "section": "Team Members",
    "text": "Team Members\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n이홍주\n이화정\n홍수민\n\n\n데이터 사이언티스트\n데이터 사이언티스트\n데이터 사이언티스트"
  },
  {
    "objectID": "about.html#kpmg-capstone-project",
    "href": "about.html#kpmg-capstone-project",
    "title": "KPMG Capstone Project",
    "section": "KPMG Capstone Project",
    "text": "KPMG Capstone Project\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n이홍주\n이화정\n홍수민\n\n\n데이터 사이언티스트\n데이터 사이언티스트\n데이터 사이언티스트"
  },
  {
    "objectID": "posts/1120_hongju/index.html#도메인-지식의-중요성",
    "href": "posts/1120_hongju/index.html#도메인-지식의-중요성",
    "title": "1109_HongJu",
    "section": "1. 도메인 지식의 중요성",
    "text": "1. 도메인 지식의 중요성\n→ 법률 관련 지식이 거의 없다 보니 전달받은 데이터를 확인했을 때 법조문의 분류 체계 및 소관 부서들의 역할들을 잘 몰라 데이터의 구조를 이해하는데 시간이 오래 걸렸다.\nex) 법령 이름과 조문 제목의 차이들에 대해 잘 몰라서 이를 어떻게 구분하는지, provision_key_no 에 들어가 있는 조, 항, 호, 목을 구분하는 방법 등에서 어려움을 겪었다.\n\n\n\n법조문 분류 표"
  },
  {
    "objectID": "posts/1120_hongju/index.html#문자열-데이터-전처리의-어려움",
    "href": "posts/1120_hongju/index.html#문자열-데이터-전처리의-어려움",
    "title": "1109_HongJu",
    "section": "2. 문자열 데이터 전처리의 어려움",
    "text": "2. 문자열 데이터 전처리의 어려움\n→ 데이터를 열어보니 총 60,964개의 법조문이 존재했다. 조, 항을 제외한 나머지 열들이 모두 str 타입이기 때문에 문자열을 어떻게 전처리 할지가 중요하다고 생각했다.\n내가 생각한 전처리 방식은 다음과 같았다. 먼저 열 별로 unique 처리해서 줄일 수 있는 라벨로 변경할 수 있는 열이 무엇이 있는지 확인해 봤다. 처리 결과는 다음과 같았다.\nministrys = main_df['소관부처'].unique()\nlaws = main_df['법령'].unique()\nnames = main_df['조문제목'].unique()\nwork_name = main_df['사무명'].unique()\ntypes = main_df['사무유형'].unique()\nnote = main_df['비고(사무수행주체, 권한위임위탁 근거규정 등 입력)'].unique()\n\nprint(f\"소관부서: {len(ministrys)}개\")\nprint(f\"법령: {len(laws)}개\")\nprint(f\"조문제목: {len(names)}개\")\nprint(f\"사무명: {len(work_name)}개\")\nprint(f\"사무유형: {len(types)}개\")\nprint(f\"비고: {len(note)}개\")\n(결과)\n\n띄어쓰기 처리전 변수별 unique 개수\n\n띄어쓰기 처리 후 변수별 unique 개수\n확인 결과가 이상해서 데이터를 유심히 살펴봤다. 내가 전달받은 사무 유형은 총 16가지였는데 33가지가 나왔기 때문에 더 유심히 데이터를 살펴본 결과 띄어쓰기와 오탈자 등의 문제가 있었다. 따라서 이러한 것들을 EDA 과정에서 찾아내 적절한 범주로 묶고 라벨 인코딩을 진행해야겠다는 생각을 하게 되었다. 추가적으로 사뭇 명은 겹치는 것이 별로 없기 때문에 이 변수를 군집화할지, 자연어 생성 모델을 이용할지 고민해 봐야겠다는 생각을 했다."
  },
  {
    "objectID": "posts/1120_sumin/index.html",
    "href": "posts/1120_sumin/index.html",
    "title": "1121_Sumin",
    "section": "",
    "text": "1121_홍수민 데이터 분석 소감\n\n이번주 진행사항\n\nEDA\n향후 진행방향 논의 \n\n\n\n1. 데이터를 처음 열어본 소감..\n 처음 데이터를 받아 파일을 열려고 했는데, 위와 같이 파일이 열리지 않는 오류가 발생했다. 알고보니 eof(end of file)가 잘 마무리되지 않아 발생한 문제였다. 그동안 수업에서 데이터를 다룰 때는 한 번도 파일이 열리는 과정에서 에러가 나지 않았어서, 이 때부터 가공되지 않은 raw data의 위력을 실감할 수 있었다.\n엑셀 파일의 경우, 코드북과 실제 데이터셋 안에 있는 column, 데이터 형식이 일치하지 않았다. csv파일의 경우, provision_key가 왜 4자리~6자리로 구성되어 있는지, clause_key에서 각 숫자들이 의미하는 바가 무엇인지 유추해내는 것이 쉽지 않았다.  위와 같이 각 데이터의 의미를 파악을 하는 데에만 상당한 시간이 소요되었다. 법 체계와 사무 추출 작업에 대한 도메인 지식이 있었다면 이 작업을 조금 더 빨리 끝낼 수 있었겠다는 생각이 들었다. 데이터 분석에서 도메인 지식의 중요성을 느꼈던 것 같다. 이에 이동할 때 틈틈히 사무총조사 보고서 파일을 읽으며 부족한 도메인 지식을 채우려 노력하였다. 그래도 혼자 파악했다면 정말 오랜 시간이 걸렸을 것 같은데, 임원들과 공유 notion에 함께 알게 된 내용을 정리하고 공유하며 프로젝트를 진행하여서 더 많은 내용을 더 짧은 시간에 효율적으로 습득할 수 있었다.  \n\n\n2.주된 느낀 점\n이번 주 작업 중 가장 주되게 느낀 것은 EDA와 전처리의 중요성이다. 평소 데이터 전처리가 데이터 분석 과정에서 약 70%를 차지한다는 말을 들어보았으나, 사실 이전에는 크게 이 말을 실감하지 못하였다. Kaggle 등의 데이터를 다루어보았을 때는 전처리를 “모델 성능을 조금 더 높여줄 수도 있는 작업”정도로 생각하였다. 그러나, 이번 기회에 전처리 되지 않은 raw data로는 모델링을 시도할 수 없는 것을 깨달았다. 전처리를 “모델링을 하기 위해 꼭 필요한 작업”으로 인식이 바뀌게 되었다.  \n\n\n3. 배운 내용 활용 방안\n[전처리 방안]  - 법 조문에서 주요한 부분(주어, 서술어 등)을 추출한 후, 이를 따로 column으로 활용해도 좋겠다는 생각을 하였다.  - 국가와 지방자치단체에 소속된 기관을 위계를 표현할 수 있는 tree형태로 정리할 수 있다면, 훨씬 더 정확도 높은 분석을 수행할 수 있을 것 같았다. 이를 머신러닝과 딥러닝이 자체적으로 파악할 수 있을지, 아니면 시간이 많이 걸리더라도 사람이 수작업으로 정리한 후에 학습을 시키면 좋을지 향후 분석을 진행하며 판단해야할 것 같다. \n[모델링 방안]  - 성능이 높다고 평가된 XGBoost, LightGBM 등의 머신러닝 기법을 사용  - 성능이 높다고 평가된 최신 자연어처리 딥러닝 기법을 사용  - 실무에서 생성형 AI의 활용에 대한 관심이 많아지고 있는 것 같다. 이에 생성형 AI를 본 task에 어떻게 적용하면 좋을지도 고민해보면 좋을 것 같다."
  },
  {
    "objectID": "posts/1121_data_plan/index.html#개발환경설정",
    "href": "posts/1121_data_plan/index.html#개발환경설정",
    "title": "1121_Data Plan",
    "section": "개발환경설정",
    "text": "개발환경설정\n\n개발언어 : Python\nIDE : Anaconda, VSCode\n패키지 : numpy, pandas, scikit-learn, pytorch, transformers(hugging face)\n코드 공유 및 코드 저장소: github - cgbside repo"
  },
  {
    "objectID": "posts/1121_data_plan/index.html#eda",
    "href": "posts/1121_data_plan/index.html#eda",
    "title": "1121_Data Plan",
    "section": "EDA",
    "text": "EDA\n\n0. Source\n\nedaing.ipynb\nfinal.pdf\ncodebook_2022.xlsx\n\n\n\n1. Law_MST.csv 파일 로드\n- 349810행 호출 오류\n    \n\n💡 “251889”,“001740”,해양수산부,선원법,“0007001”,④,제7조,출항 전의 검사ㆍ보고의무 등,“제7조(출  “” (따옴표)로 감싸지 않아서 파싱 과정에서 오류가 발생 (잘못 복사된 파일) 파일의 EOF가 잘못 설정되어 이를 수정함 ⇒ 혹시 349810행 뒤에 짤린 부분이 있는지 확인 필요\n\n\n따라서, 이를 제외하고 csv 파일을 로드하였음.\n\ndata = pd.read_csv('law_mst.csv')\n- Output\n\n\n\n결과\n\n\n\n\n2. Feature 설명\n\n\n\n\n\n\n\n\nFeature\n설명\n처리방법\n\n\n\n\nlaw_seq\n법률, 시행규칙, 시행규칙 전체 연번\n정확히 무엇인지?\n\n\nlaw_id\n(법마다 다르다)\n정확히 무엇인지?\n\n\njdt_dept_nm\n소관부처 부처 개수, 부처명 등 파악하기\n\n\n\nlaw_kor_nm\n법령명\n\n\n\nprovision_key_no\n포맷 : _ _ _ _ _ _ _ (1) _ _ _ _ /_ _ 앞 6자리 숫자: 조(4자리)의 몇(2자리)ex) 제 1000조의 1 : 1000 / 01ex) 제 1조 : 0001 / 00ex) 제 15조의 19 : 0015 / 19(2) _ 맨 뒤 1자리 숫자: 0 -&gt; 장, 1-&gt; 장 아님\n-맨 뒤 숫자가 1인 경우, 조 번호만 추출-맨 뒤 숫자가 0인 경우, 행 삭제\n\n\nclause_no\n원숫자 O → 각 항번호 1 → 항 없이 호만 있음nan → 항과 호 모두 없는 법령\n\n\n\nprovision_no_nm\n조 한국어 표기(ex. 제1조, 제2조)\n\n\n\nprovision_title\n조 제목\n\n\n\nprovision_cont\n조 내용\n\n\n\nclause_cont\n항 내용\n\n\n\n\n\n\n\n참고 : 대한민국 법조문 체계\n\n\n+ 대한민국 정부 조직도 체계 참고사항으로 넣기\n+ 정부조직이 업데이트 시(승격 등), 어떻게 반영할 것인지?\n+ 시군구 업데이트 시(승격 등), 어떻게 반영할 것인지?\n+ 업데이트 될 때마다 바로 반영이 가능한가?\n+ 그리고 현재, Law_MST.csv에는 따로 사무여부 등의 레이블링이 되어있지 않은데 그렇다면 학습용데이터는 2019년 자료를 활용해야 하는 것인가?\n그렇다면.. 우리가 학습해야 할 데이터는.. 2019사무목록 최종본(인쇄용 최종).xlsx 파일인데 (레이블링이 되어 있으니) 그렇다면 Law_MST.csv는 어디에 사용하는 걸까?\n\n\n3. EDA - excel 파일\n\n결측치 확인: ‘항’, ‘비고’ column만 null값 존재\n\n\n\n\n출력 결과\n\n\n\nunique값 확인\n\n\n조문 제목과 사무 유형은 동일한 내용임에도 띄어쓰기가 다르게 되어 있는 경우 있었음 ⇒ replace 함수 통해 띄어쓰기 제거\n\n\n\n\ncolumn명\n원래 unique 값\n띄어쓰기 없앤 후 unique 값\n\n\n\n\n소관부서\n41\n41\n\n\n법령\n2859\n2859\n\n\n조문제목\n30034\n29544\n\n\n사무명\n56789\n56418\n\n\n사무유형\n33\n16\n\n\n비고\n4036\n3843\n\n\n\n+) 비고의 경우, 오탈자 존재(ex. 가획재정부 장관) / 동일한 기관 다른 표기 존재(ex.기획재정부 장관, 기재부 장관)\n\n\n4. EDA를 통해 세운 전처리/모델링 전략\n\n‘소관부처’, ‘법령’, ‘비고’ 라벨 인코딩하여 사무 유형 classification 진행해보고자 함\nlaw_mst.csv 파일과 2019사무목록 최종본.xlsx 파일의 연도 정보가 일치하지 않음\nlaw_mst.csv 파일과 2019사무목록 최종본.xlsx 파일을 ’조와 항’을 key로 하여 left join하면 사무인지 아닌지도 파악할 수 있음 (join한 후, 사무명, 사무유형, 비고가 NaN이면 비사무)\n\n⇒ 그러나, 이를 위해서는 2번 문제가 해결되어야 함\n\n사무명의 경우, 법령에서 괄호 속 텍스트 추출하는 방식으로 처리\n\n\n2019사무목록 최종본(인쇄용 최종).xlsx\n\n\n이 파일에는 아래와 같이 레이블링된 사무목록들이 들어있다. 하지만, 사무가 아닌 법령은 제거되어 있는 등(모든 법령들이 들어있지 않다!), 자체적으로 전처리가 되어있는 자료이다. 또한 법의 특성상(?) ’호’는 ’사무’에 대한 내용을 담고 있진 않은듯? 상위의 ’조’나 ’항’에서 ’사무명’을 추출할 수 있는 듯하다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n연번\n소관부처\n법령\n조\n항\n조문제목\n조문\n사무명\n사무유형\n비고"
  },
  {
    "objectID": "posts/1121_data_plan/index.html#예측개발-방법론",
    "href": "posts/1121_data_plan/index.html#예측개발-방법론",
    "title": "1121_Data Plan",
    "section": "예측개발 방법론",
    "text": "예측개발 방법론\n&lt;개발 목적 및 프로세스&gt;\n\n사무 여부 O/X\n사무 여부가 O 일 때, 사무 수행 주체 파악\n→ 데이터 사전 구성? (부처에 뭐가 있는 지 미리 작성)\n위탁 여부 파악 O/X (위탁이 O인 경우 사무 수행 주체 소분류 컬럼 추가 생성 필요)\n사무 유형 파악\n\n—&gt; 부처명, 시군구 범위 변경 시에도 반영이 가능해야 함.\n&lt;목표: 사무유형 classification : 16개 &gt;\n**** 어떤 프로세스를 적용할까요?!***\n** 프로세스 : 문서 구조 분석 -&gt; 엔터티 추출 및 분류 모델(NER 모델을 통한 사무주체 추출) -&gt; ‘위임’,’위탁’등의 관계를 분석하는 알고리즘(종속관계 파악하는 관계 추출 기술…?) -&gt; 모델 학습(어떤 방법론이 가능할지는?) -&gt; 모델 성능 평가 및 하이퍼파라미터 조정 -&gt; 실제 환경에 통합 및 사용자 인터페이스를 통한 결과 제공*\n[시도 방법1] 문서 구조 분석 -&gt; 엔터티 추출 및 분류 모델(NER 모델을 통한 사무주체 추출) -&gt; ‘위임’,’위탁’등의 관계를 분석하는 알고리즘(종속관계 파악하는 관계 추출 기술…?) -&gt; 모델 학습(어떤 방법론이 가능할지는?) -&gt; 모델 성능 평가 및 하이퍼파라미터 조정 -&gt; 실제 환경에 통합 및 사용자 인터페이스를 통한 결과 제공\n[시도 방법2] ‘소관부처’, ‘법령’, ‘비고’ 라벨인코딩 ⇒ 머신러닝 기법(XGBoost, LightGBM, 여러 모델 앙상블) 적용\n[시도 방법3] huggingface에서 nlp 모델 사용 ⇒ 딥러닝 기법 시도"
  },
  {
    "objectID": "posts/1121_data_plan/index.html#모형설계서",
    "href": "posts/1121_data_plan/index.html#모형설계서",
    "title": "1121_Data Plan",
    "section": "모형설계서",
    "text": "모형설계서\n\n\n\n\n\n\n\n\n\n개발 목적/프로세스\n개발 방법론\n사용 모델\nperformance metric\n\n\n\n\n사무 여부 O/X\nrule-based classification\nif-elif 위임되면 사무X : ~령으로 정한다\nf1 score, recall(사무가 맞는데 사무가 아니라고 분류되는게 더 위험하기 때문에)\n\n\n사무 유형 파악\n\n\n\n\n\n사무 여부가 O 일 때, 사무 수행 주체 파악\ntrial1) 문장에서 주어 추출\n\n\n\n\ntrial2) 수행 주체 데이터 사전 구성, 데이터 사전에 있는 명사 모두 추출\n\naccuracy (수행주체 올바르게 추출한 데이터 수 / 전체 데이터 수)\n\n\n\n3) 위탁 여부 파악 O/X\nrule-based classification(위탁이 O이면 경우에 따라 사무가 X가 될 수 있음.)\n정규표현식 사용(‘~조에 따른’ 표현이 있으면 위탁여부 O로 classify)\nf1 score\n\n\n\n&lt;의문점!&gt;\n\n법령정보api는 새로운 조문이 업데이트 되면 이를 학습할 목적으로 사용하는 것인지?\n그럼 일단 학습은 기존의 2019, 2022년 정리된 조문을 바탕으로 학습하는 것인지?\n위임, 조, 규칙, 시행령 등 서로 종속되어 있는 관계는 어떻게 학습을 하는 것인지?\n\n\ntrain / validation / test set 구분\n\n\n2019사무목록 최종본(인쇄용 최종).xlsx 로 지도학습 실시 (확실하지 않음)\nQ: 그럼 Law_MST.csv 어디에 사용?\nLaw_MST.csv로 Demo 시연"
  },
  {
    "objectID": "posts/1120_hwajeong/index.html",
    "href": "posts/1120_hwajeong/index.html",
    "title": "1121_Hwajeong",
    "section": "",
    "text": "최근에 시작한 프로젝트에서 처음으로 ’raw data’와 마주한 이야기를 해볼까 한다.\n\n\n간략하게 이 프로젝트에 대해서 소개를 하자면… 이 프로젝트의 목표는 AI를 활용하여 법령 사무조사 자동화의 가능성을 탐구하는 것이다. 구체적으로는 중앙행정기관과 지방자치단체 간의 ‘사무주체’, ‘사무유형’, ’사무명’을 추출하고, 이를 자동화하는 모형을 개발하는 것인데, 최종적으로는 새로운 법령이 업데이트되어도 사무를 자동으로 구분할 수 있는 시스템을 개발하는 것이 목표가 되겠다.\n\n\n\n이 프로젝트에서 처음으로 접한 것은 학습용으로 레이블링된 데이터와 Open API로 스크랩한 Raw 데이터였다. 데이터를 살펴보다 보니.. 이번 프로젝트는 단순히 조문에 대한 레이블을 학습하는 것을 넘어서, 모든 법령에 대한 구조적인 분석과 종속관계 파악이 필요하지 않을까? 라는 생각을 하게 되었다. 왜냐하면 법조문이라는 데이터의 특성상, 서로 종속된 법령들과(시행령, 시행규칙 등) 다양한 사무주체들이 복잡하게 얽혀 있다. 이 16가지 사무유형을 분류하기까지 너무 많은 경우의 수가 있어 쉽진 않을 것 같다는 생각이 들었다.  + 단순히 조문에 대한 레이블만 학습하면 될 문제인지? 아니면 모든 법령에 대해서 구조적인 분석을 통해 근본적으로 종속관계를 파악하고, 이를 반영할 수 있는 모델을 만들 것인지에 대한 고민이 생겼다.\n그래서 추가적으로, 유사한 프로젝트를 찾아보고 어떤 분석기법이 적합할지 탐색할 필요가 있다.\n\n\n\napi로 불러온 raw data의 전처리에 대한 이야기를 짧게 해 보자면, 우선적으로는 공백을 제거하는 등의 기본적인 전처리를 먼저 진행해야 하겠고, 뿐만 아니라 기존에 레이블링된 데이터는 주로 중앙행정기관과 지방자치단체의 법령만 다뤘지만, Raw 데이터에는 국회, 감사원 등 다양한 기관의 법령도 포함되어 있었기에 이에 대한 처리도 필요할 것으로 보인다.\n\n\n\n당장 1차적으로는 사무유형을 분류하는 데 주력해야겠지만 더 나아가서 앞으로 더 많은 활용을 위해서는 앞으로 법령정보 API를 활용하는 방법에 대해서도 더 고민해봐야겠다. 특히, 국가법령정보 공동활용 홈페이지에서 제공하는 Open API를 활용해, 업데이트 된 시행령을 반영하기 위해서는 [efYd] 변수를 이용해 자동화가 가능하도록 구성하는 방안 또한 필요해 보인다.\n\n\n\n이 프로젝트가 성공적으로 마무리되면, 그동안의 흥미 위주의 데이터 분석을 넘어서 실제 현안 해결에 기여할 수 있게 될 것 같아(작은 부분이라도..) 의미 있는 프로젝트가 될 것 같다. 현실의 복잡한 문제를 데이터 분석을 통해 해결해 나가는 과정을 통해 더 많이 배우고 성장할 수 있기를.…!"
  },
  {
    "objectID": "posts/1120_hwajeong/index.html#프로젝트-소개",
    "href": "posts/1120_hwajeong/index.html#프로젝트-소개",
    "title": "1121_Hwajeong",
    "section": "",
    "text": "간략하게 이 프로젝트에 대해서 소개를 하자면… 이 프로젝트의 목표는 AI를 활용하여 법령 사무조사 자동화의 가능성을 탐구하는 것이다. 구체적으로는 중앙행정기관과 지방자치단체 간의 ‘사무주체’, ‘사무유형’, ’사무명’을 추출하고, 이를 자동화하는 모형을 개발하는 것인데, 최종적으로는 새로운 법령이 업데이트되어도 사무를 자동으로 구분할 수 있는 시스템을 개발하는 것이 목표가 되겠다."
  },
  {
    "objectID": "posts/1120_hwajeong/index.html#데이터-탐색-및-모형-개발-process에-대한-생각",
    "href": "posts/1120_hwajeong/index.html#데이터-탐색-및-모형-개발-process에-대한-생각",
    "title": "1121_Hwajeong",
    "section": "",
    "text": "이 프로젝트에서 처음으로 접한 것은 학습용으로 레이블링된 데이터와 Open API로 스크랩한 Raw 데이터였다. 데이터를 살펴보다 보니.. 이번 프로젝트는 단순히 조문에 대한 레이블을 학습하는 것을 넘어서, 모든 법령에 대한 구조적인 분석과 종속관계 파악이 필요하지 않을까? 라는 생각을 하게 되었다. 왜냐하면 법조문이라는 데이터의 특성상, 서로 종속된 법령들과(시행령, 시행규칙 등) 다양한 사무유형이 복잡하게 얽혀 있기에, 이 16가지 사무유형을 분류하기까지 너무 많은 경우의 수가 있어 쉽진 않을 것 같다는 생각이 들었다. + 단순히 조문에 대한 레이블만 학습하면 될 문제인지? 아니면 모든 법령에 대해서 구조적인 분석을 통해 근본적으로 종속관계를 파악하고, 이를 반영할 수 있는 모델을 만들 것인지에 대한 고민이 생겼다.\n그래서 추가적으로, 유사한 프로젝트를 찾아보고 어떤 분석기법이 적합할지 탐색해 봐야겠다."
  },
  {
    "objectID": "posts/1120_hwajeong/index.html#전처리",
    "href": "posts/1120_hwajeong/index.html#전처리",
    "title": "1121_Hwajeong",
    "section": "",
    "text": "api로 불러온 raw data의 전처리에 대한 이야기를 짧게 해 보자면, 우선적으로는 공백을 제거하는 등의 기본적인 전처리를 먼저 진행해야 하겠고, 뿐만 아니라 기존에 레이블링된 데이터는 주로 중앙행정기관과 지방자치단체의 법령만 다뤘지만, Raw 데이터에는 국회, 감사원 등 다양한 기관의 법령도 포함되어 있었기에 이에 대한 처리도 필요할 것으로 보인다."
  },
  {
    "objectID": "posts/1120_hwajeong/index.html#향후-고민할-점",
    "href": "posts/1120_hwajeong/index.html#향후-고민할-점",
    "title": "1121_Hwajeong",
    "section": "",
    "text": "당장은 1차적으로는 사무유형을 분류하는 데 주력해야겠지만 더 나아가서 앞으로 더 많은 활용을 위해서는 앞으로 법령정보 API를 활용하는 방법에 대해서도 더 고민해봐야겠다. 특히, 국가법령정보 공동활용 홈페이지에서 제공하는 Open API를 활용해, 시행령 업데이트 시 [efYd] 변수를 이용해 자동 업데이트가 가능하도록 구성하는 방안 또한 필요해 보인다."
  },
  {
    "objectID": "posts/1120_hwajeong/index.html#section",
    "href": "posts/1120_hwajeong/index.html#section",
    "title": "1121_Hwajeong",
    "section": "",
    "text": "이 프로젝트가 성공적으로 마무리되면, 그동안의 흥미 위주의 데이터 분석을 넘어서 실제 현안 해결에 기여할 수 있게(작은 부분이라도..) 될 것 같아 현실의 복잡한 문제를 데이터 분석을 통해 해결해 나가는 과정을 통해 더 많이 배우고 성장할 수 있기를 …!"
  },
  {
    "objectID": "posts/1120_hwajeong/index.html#데이터-및-모형-개발-process에-대한-생각",
    "href": "posts/1120_hwajeong/index.html#데이터-및-모형-개발-process에-대한-생각",
    "title": "1121_Hwajeong",
    "section": "",
    "text": "이 프로젝트에서 처음으로 접한 것은 학습용으로 레이블링된 데이터와 Open API로 스크랩한 Raw 데이터였다. 데이터를 살펴보다 보니.. 이번 프로젝트는 단순히 조문에 대한 레이블을 학습하는 것을 넘어서, 모든 법령에 대한 구조적인 분석과 종속관계 파악이 필요하지 않을까? 라는 생각을 하게 되었다. 왜냐하면 법조문이라는 데이터의 특성상, 서로 종속된 법령들과(시행령, 시행규칙 등) 다양한 사무주체들이 복잡하게 얽혀 있다. 이 16가지 사무유형을 분류하기까지 너무 많은 경우의 수가 있어 쉽진 않을 것 같다는 생각이 들었다.  + 단순히 조문에 대한 레이블만 학습하면 될 문제인지? 아니면 모든 법령에 대해서 구조적인 분석을 통해 근본적으로 종속관계를 파악하고, 이를 반영할 수 있는 모델을 만들 것인지에 대한 고민이 생겼다.\n그래서 추가적으로, 유사한 프로젝트를 찾아보고 어떤 분석기법이 적합할지 탐색할 필요가 있다."
  },
  {
    "objectID": "posts/1120_hwajeong/index.html#향후-고민해보아야-할-점들",
    "href": "posts/1120_hwajeong/index.html#향후-고민해보아야-할-점들",
    "title": "1121_Hwajeong",
    "section": "",
    "text": "당장 1차적으로는 사무유형을 분류하는 데 주력해야겠지만 더 나아가서 앞으로 더 많은 활용을 위해서는 앞으로 법령정보 API를 활용하는 방법에 대해서도 더 고민해봐야겠다. 특히, 국가법령정보 공동활용 홈페이지에서 제공하는 Open API를 활용해, 업데이트 된 시행령을 반영하기 위해서는 [efYd] 변수를 이용해 자동화가 가능하도록 구성하는 방안 또한 필요해 보인다."
  },
  {
    "objectID": "posts/1120_hwajeong/index.html#마무리하며..",
    "href": "posts/1120_hwajeong/index.html#마무리하며..",
    "title": "1121_Hwajeong",
    "section": "",
    "text": "이 프로젝트가 성공적으로 마무리되면, 그동안의 흥미 위주의 데이터 분석을 넘어서 실제 현안 해결에 기여할 수 있게 될 것 같아(작은 부분이라도..) 의미 있는 프로젝트가 될 것 같다. 현실의 복잡한 문제를 데이터 분석을 통해 해결해 나가는 과정을 통해 더 많이 배우고 성장할 수 있기를.…!"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "데이터",
    "section": "",
    "text": "Base Table 만들기\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data_posts/MakeBaseTable.html",
    "href": "data_posts/MakeBaseTable.html",
    "title": "Base Table 만들기",
    "section": "",
    "text": "# 필요 라이브러리 설치\nimport numpy as np\nimport pandas as pd\n\n\n# 데이터 load\ndata = pd.read_csv('main_data.csv')\n\n/var/folders/sy/5dw5r1ys5fdb3h0gbq8x0g6m0000gn/T/ipykernel_47971/1248266004.py:2: DtypeWarning: Columns (2,4,5,8,13,16,17,18,19,24) have mixed types. Specify dtype option on import or set low_memory=False.\n  data = pd.read_csv('main_data.csv')\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 861719 entries, 0 to 861718\nData columns (total 25 columns):\n #   Column     Non-Null Count   Dtype  \n---  ------     --------------   -----  \n 0   소관부처명      861666 non-null  object \n 1   법령명        861702 non-null  object \n 2   법령구분       861704 non-null  object \n 3   조번호        861129 non-null  object \n 4   항번호        666590 non-null  object \n 5   호번호        504904 non-null  object \n 6   조문제목       805869 non-null  object \n 7   조문         848856 non-null  object \n 8   사무판단       767124 non-null  object \n 9   사무판단근거     700871 non-null  object \n 10  사무명        60113 non-null   object \n 11  수행주체       60116 non-null   object \n 12  사무유형       60071 non-null   object \n 13  위임사무판단     761139 non-null  object \n 14  위임근거규정     5311 non-null    object \n 15  수임기관       4416 non-null    object \n 16  특행기관       93089 non-null   object \n 17  재위임사무판단    702502 non-null  object \n 18  재위임근거규정    54 non-null      object \n 19  재수임기관      13 non-null      object \n 20  위탁사무판단     758703 non-null  float64\n 21  위탁근거규정     3975 non-null    object \n 22  수탁기관       3952 non-null    object \n 23  사무유형(소분류)  60114 non-null   object \n 24  기타         3 non-null       object \ndtypes: float64(1), object(24)\nmemory usage: 164.4+ MB"
  },
  {
    "objectID": "data_posts/MakeBaseTable.html#라이브러리-설치-및-데이터-불러오기",
    "href": "data_posts/MakeBaseTable.html#라이브러리-설치-및-데이터-불러오기",
    "title": "Base Table 만들기",
    "section": "",
    "text": "# 필요 라이브러리 설치\nimport numpy as np\nimport pandas as pd\n\n\n# 데이터 load\ndata = pd.read_csv('main_data.csv')\n\n/var/folders/sy/5dw5r1ys5fdb3h0gbq8x0g6m0000gn/T/ipykernel_47971/1248266004.py:2: DtypeWarning: Columns (2,4,5,8,13,16,17,18,19,24) have mixed types. Specify dtype option on import or set low_memory=False.\n  data = pd.read_csv('main_data.csv')\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 861719 entries, 0 to 861718\nData columns (total 25 columns):\n #   Column     Non-Null Count   Dtype  \n---  ------     --------------   -----  \n 0   소관부처명      861666 non-null  object \n 1   법령명        861702 non-null  object \n 2   법령구분       861704 non-null  object \n 3   조번호        861129 non-null  object \n 4   항번호        666590 non-null  object \n 5   호번호        504904 non-null  object \n 6   조문제목       805869 non-null  object \n 7   조문         848856 non-null  object \n 8   사무판단       767124 non-null  object \n 9   사무판단근거     700871 non-null  object \n 10  사무명        60113 non-null   object \n 11  수행주체       60116 non-null   object \n 12  사무유형       60071 non-null   object \n 13  위임사무판단     761139 non-null  object \n 14  위임근거규정     5311 non-null    object \n 15  수임기관       4416 non-null    object \n 16  특행기관       93089 non-null   object \n 17  재위임사무판단    702502 non-null  object \n 18  재위임근거규정    54 non-null      object \n 19  재수임기관      13 non-null      object \n 20  위탁사무판단     758703 non-null  float64\n 21  위탁근거규정     3975 non-null    object \n 22  수탁기관       3952 non-null    object \n 23  사무유형(소분류)  60114 non-null   object \n 24  기타         3 non-null       object \ndtypes: float64(1), object(24)\nmemory usage: 164.4+ MB"
  },
  {
    "objectID": "data_posts/MakeBaseTable.html#설명변수소관부처명-법령명-조번호-항번호-호번호-조문제목-조문가-모두-결측치인-행-삭제",
    "href": "data_posts/MakeBaseTable.html#설명변수소관부처명-법령명-조번호-항번호-호번호-조문제목-조문가-모두-결측치인-행-삭제",
    "title": "Base Table 만들기",
    "section": "1) 설명변수(소관부처명, 법령명, 조번호, 항번호, 호번호, 조문제목, 조문)가 모두 결측치인 행 삭제",
    "text": "1) 설명변수(소관부처명, 법령명, 조번호, 항번호, 호번호, 조문제목, 조문)가 모두 결측치인 행 삭제"
  },
  {
    "objectID": "data_posts/MakeBaseTable.html#section",
    "href": "data_posts/MakeBaseTable.html#section",
    "title": "Base Table 만들기",
    "section": "",
    "text": "def x_null_drop(df): \n    select_column = ['소관부처명', '법령명', '조번호', '항번호', '호번호', '조문제목', '조문']\n    delete_row_idx = list(df[df[select_column].isnull().all(axis = 1)].index)\n    delete_row_idx.sort(reverse = True)\n    for i in delete_row_idx:\n        df = df.drop([i],axis = 0)\n    return df\n\n\ndata = x_null_drop(data)\n\n(861711, 25)"
  },
  {
    "objectID": "data_posts/MakeBaseTable.html#소관부처명-결측치-처리",
    "href": "data_posts/MakeBaseTable.html#소관부처명-결측치-처리",
    "title": "Base Table 만들기",
    "section": "2) 소관부처명 결측치 처리",
    "text": "2) 소관부처명 결측치 처리\n\n소관부처명 결측치: 45개\n동일한 법령에 대해서는 동일한 소관부처를 가짐\n이에, 다른 행 중 동일한 법령을 지닌 소관부처 파악 후 결측치 채워줌\n\n\ndef dep_law_preprocessing(df):\n        # department_idx: '법령명'은 채워져있는데 '소관부처명'은 채워져있지 않은 행의 index\n        department_idx = df[df['소관부처명'].isnull() & df['법령명'].notnull()].index\n        # department_name_list: '소관부처명'이 채워져야할 법령명\n        department_name_list = df[df['소관부처명'].isnull() & df['법령명'].notnull()]['법령명'].unique()\n\n        department_dic = {}\n        department_dic['건설산업기본법'] = '국토교통부'\n        department_dic['보건범죄단속에관한특별조치법시행령'] = '보건복지부'\n        department_dic['항로표지법'] = '해양수산부'\n        department_dic['수산자원관리법'] = '해양수산부'\n        department_dic['연안관리법'] = '해양수산부'\n        department_dic['야생생물 보호 및 관리에 관한 법률'] = '환경부'\n\n        for i in range(len(department_idx)):\n                for j in range(len(department_name_list)):\n                        df.loc[department_idx[i],'소관부처명'] = department_dic[department_name_list[j]]\n\n        # '소관부처명', '법령명' 모두 채워져있지 않은 행\n        \n        return df\n\n\ndata = dep_law_preprocessing(data)"
  },
  {
    "objectID": "data_posts/MakeBaseTable.html#법령명-결측치-처리",
    "href": "data_posts/MakeBaseTable.html#법령명-결측치-처리",
    "title": "Base Table 만들기",
    "section": "3) 법령명 결측치 처리",
    "text": "3) 법령명 결측치 처리\n\n조, 항, 조문 통해 법령명 찾아 삽입\n\n\ndef law_name_preprocessing(df):\n    idx = 14168\n    df.loc[idx,'소관부처명'] = '고용노동부'\n    df.loc[idx,'법령명'] = '근로자퇴직급여 보장법'\n    df.loc[idx,'법령구분'] = 1\n\n    idx = 198519\n    df.loc[idx,'소관부처명'] = '국토교통부'\n    df.loc[idx,'법령명'] = '택수운송사업의 발전에 관한 법률'\n    df.loc[idx,'법령구분'] = 1\n    df.loc[idx,'조번호'] = 11\n    df.loc[idx,'항번호'] = 1\n    df.loc[idx,'조문제목'] = '감차계획의 수립 및 시행 등'\n    idx = 686791\n    df.loc[idx,'소관부처명'] = '해양수산부'\n    df.loc[idx,'법령명'] = '수산업ㆍ어촌 공익기능 증진을 위한 직접지불제도 운영에 관한 법률'\n\n    idx = 708300\n    df.loc[idx,'소관부처명'] = '해양수산부'\n    df.loc[idx,'법령명'] = '해양공간계획 및 관리에 관한 법률'\n\n    idx = 708831\n    df.loc[idx,'소관부처명'] = '해양수산부'\n    df.loc[idx,'법령명'] = '해양폐기물 및 해양오염퇴적물 관리법'\n\n    idx = 766079\n    df.loc[idx,'소관부처명'] = '행정안전부'\n    df.loc[idx,'법령명'] = '새마을금고법'\n\n    idx = 859679\n    df.loc[idx,'소관부처명'] = '환경부'\n    df.loc[idx,'법령명'] = '미세먼지 저감 및 관리에 관한 특별법'\n\n    idx = 859692\n    df.loc[idx,'소관부처명'] = '환경부'\n    df.loc[idx,'법령명'] = '미세먼지 저감 및 관리에 관한 특별법'\n\n    idx = 859755\n    df.loc[idx,'소관부처명'] = '환경부'\n    df.loc[idx,'법령명'] = '미세먼지 저감 및 관리에 관한 특별법'\n    \n    return df\n\n\ndata = law_name_preprocessing(data)"
  },
  {
    "objectID": "data_posts/MakeBaseTable.html#법령구분-처리",
    "href": "data_posts/MakeBaseTable.html#법령구분-처리",
    "title": "Base Table 만들기",
    "section": "4) 법령구분 처리",
    "text": "4) 법령구분 처리\n\n법령구분 결측치 처리\n법령구분 자료형 int로 통일\n\n\ndef law_category_preprocessing(df):\n    # '법령구분'이 결측치인 행들의 index\n    null_idx = df[df['법령구분'].isnull()].index\n    # 국가법령정보센터 확인 결과, 결측치인 모든 행들은 법률, 즉 '1'에 해당\n    for i in null_idx:\n        df.loc[i,'법령구분'] = 1\n    \n    # 국가법령정보센터 확인 결과, '법령구분'이 공백으로 되어있는 행은 시행령, 즉 '2'에 해당\n    df.loc[df['법령구분']==' ', \"법령구분\"] = 2\n\n    # 법령구분 자료형 통일\n    df['법령구분'] = df['법령구분'].astype('int64')\n\n    return df\n\n\ndata = law_category_preprocessing(data)"
  },
  {
    "objectID": "data_posts/MakeBaseTable.html#사무판단-처리",
    "href": "data_posts/MakeBaseTable.html#사무판단-처리",
    "title": "Base Table 만들기",
    "section": "5) 사무판단 처리",
    "text": "5) 사무판단 처리\n\n’ ’ -&gt; nan, ‘0’ -&gt; 0 , ‘1’ -&gt; 1, ‘0 1’ -&gt; 2 float 형태로 변환\n\n\ndef decision_preprocessing(df):\n    # 표기방식 통일\n    idx_nan = df[(df['사무판단'] == ' ')].index #idx_nan: '사무판단'이 nan인 행의 index\n    for i in idx_nan:\n        df.loc[i,'사무판단'] = np.nan\n    idx_0 = df[(df['사무판단'] == '0')].index #idx_0: '사무판단'이 '0'인 행의 index\n    for i in idx_0:\n        df.loc[i,'사무판단'] = 0\n    idx_1 = df[(df['사무판단'] == '1')].index #idx_1: '사무판단'이 '1'인 행의 index\n    for i in idx_1:\n        df.loc[i,'사무판단'] = 1\n    idx_2 = df[(df['사무판단'] == '0 1')].index #idx_2: '사무판단'이 '0 1'인 행의 index\n    for i in idx_2:\n        df.loc[i,'사무판단'] = 2\n\n    # 오류 행 삭제\n    ## 경우1: 사무가 아님에도 사무 유형이 분류된 경우\n    delete_0_idx = list((df[(df['사무판단'] == 0)  & (df['사무유형(소분류)'].notna())]).index)\n    df = df.drop(delete_0_idx, axis = 0)\n    \n    ## 경우2: 사무임에도 사무 유형이 분류되지 않은 경우\n    delete_1_idx1 = list((df[(df['사무판단'] == 1)  & (df['사무유형'].isnull())]).index)\n    df = df.drop(delete_1_idx1, axis = 0)\n    \n    delete_1_idx2 = list((df[(df['사무판단'] == 1)  & (df['사무유형(소분류)'].isnull())]).index)\n    df = df.drop(delete_1_idx2, axis = 0)\n\n    # 결측행 처리\n    ## 경우1: 사무 유형이 분류된 경우 =&gt; '1'로 채움\n    change_1_idx = df[(df['사무판단'].isnull())  & (df['사무유형'].notna()) & (df['사무유형(소분류)'].notna())].index\n    df.loc[change_1_idx, '사무판단'] = 1\n    \n    # 경우2: 사무 유형이 분류되지 않은 경우 =&gt; '0'으로 채움\n    change_0_idx = df[(df['사무판단'].isnull())  & (df['사무유형'].isnull()) & (df['사무유형(소분류)'].isnull())].index\n    df.loc[change_0_idx,'사무판단'] = 0\n    \n    # 자료형 통일\n    df['사무판단'] = df['사무판단'].astype('int64')\n\n    return df\n\n\ndata = decision_preprocessing(data)"
  },
  {
    "objectID": "data_posts/MakeBaseTable.html#소관부처명-공백-처리",
    "href": "data_posts/MakeBaseTable.html#소관부처명-공백-처리",
    "title": "Base Table 만들기",
    "section": "6) 소관부처명 공백 처리",
    "text": "6) 소관부처명 공백 처리\n\ndef blank_preprocessing(df):\n    df.loc[df['소관부처명']==\"교육부,\\n고용노동부\", \"소관부처명\"] = '고용노동부,교육부'\n    df.loc[df['소관부처명']==\"과학기술정보통신부, \\n교육부\", \"소관부처명\"] = '과학기술정보통신부,교육부'\n    df.loc[df['소관부처명']==\"교육부,\\n과학기술정보통신부\", \"소관부처명\"] = '과학기술정보통신부,교육부'\n    return df\n    \n\n\ndata = blank_preprocessing(data)"
  },
  {
    "objectID": "data_posts/MakeBaseTable.html#조문-조문-제목-결측치-처리",
    "href": "data_posts/MakeBaseTable.html#조문-조문-제목-결측치-처리",
    "title": "Base Table 만들기",
    "section": "7) 조문, 조문 제목 결측치 처리",
    "text": "7) 조문, 조문 제목 결측치 처리\n\n조문, 조문 제목 null값이면 ’0’으로 채움\n\n\ndef law_preprocessing(df):\n    df.loc[df['조문제목'].isna(), '조문제목'] = '0'\n    df.loc[df['조문'].isna(), '조문'] = '0'\n    return df\n\n\ndata = law_preprocessing(data)"
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "개발개요",
    "section": "",
    "text": "Title\n\n\nAuthor\n\n\n\n\n\n\n딥러닝 코드 정리\n\n\n\n\n\n\n\n\nBase Table 만들기\n\n\n\n\n\n\n\n’조문’에서 수행주체 출력\n\n\n\n\n\n\n\n\nEDA ( BaseTable_2.csv 사용 )\n\n\n\n\n\n\n\n앙상블 코드 정리\n\n\n\n\n\n\n\n사무유형구분_Random Forest\n\n\n\n\n\n\n\nRule-Based Model\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html",
    "href": "dev_posts/MakeBaseTable.html",
    "title": "Base Table 만들기",
    "section": "",
    "text": "# 필요 라이브러리 설치\nimport numpy as np\nimport pandas as pd\n\n\n# 데이터 load\ndata = pd.read_csv('main_data.csv')\n\n/var/folders/zr/_f1rgf8n0w3541q9k8p3smhr0000gn/T/ipykernel_87762/1248266004.py:2: DtypeWarning: Columns (2,4,5,13,16,17,18,19,24) have mixed types. Specify dtype option on import or set low_memory=False.\n  data = pd.read_csv('main_data.csv')\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 861719 entries, 0 to 861718\nData columns (total 25 columns):\n #   Column     Non-Null Count   Dtype  \n---  ------     --------------   -----  \n 0   소관부처명      861666 non-null  object \n 1   법령명        861702 non-null  object \n 2   법령구분       861704 non-null  object \n 3   조번호        861129 non-null  object \n 4   항번호        666590 non-null  object \n 5   호번호        504904 non-null  object \n 6   조문제목       805869 non-null  object \n 7   조문         848856 non-null  object \n 8   사무판단       767124 non-null  float64\n 9   사무판단근거     700871 non-null  object \n 10  사무명        60113 non-null   object \n 11  수행주체       60116 non-null   object \n 12  사무유형       60071 non-null   object \n 13  위임사무판단     761139 non-null  object \n 14  위임근거규정     5311 non-null    object \n 15  수임기관       4416 non-null    object \n 16  특행기관       93089 non-null   object \n 17  재위임사무판단    702502 non-null  object \n 18  재위임근거규정    54 non-null      object \n 19  재수임기관      13 non-null      object \n 20  위탁사무판단     758703 non-null  float64\n 21  위탁근거규정     3975 non-null    object \n 22  수탁기관       3952 non-null    object \n 23  사무유형(소분류)  60114 non-null   object \n 24  기타         3 non-null       object \ndtypes: float64(2), object(23)\nmemory usage: 164.4+ MB"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html#라이브러리-설치-및-데이터-불러오기",
    "href": "dev_posts/MakeBaseTable.html#라이브러리-설치-및-데이터-불러오기",
    "title": "Base Table 만들기",
    "section": "",
    "text": "# 필요 라이브러리 설치\nimport numpy as np\nimport pandas as pd\n\n\n# 데이터 load\ndata = pd.read_csv('main_data.csv')\n\n/var/folders/zr/_f1rgf8n0w3541q9k8p3smhr0000gn/T/ipykernel_87762/1248266004.py:2: DtypeWarning: Columns (2,4,5,13,16,17,18,19,24) have mixed types. Specify dtype option on import or set low_memory=False.\n  data = pd.read_csv('main_data.csv')\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 861719 entries, 0 to 861718\nData columns (total 25 columns):\n #   Column     Non-Null Count   Dtype  \n---  ------     --------------   -----  \n 0   소관부처명      861666 non-null  object \n 1   법령명        861702 non-null  object \n 2   법령구분       861704 non-null  object \n 3   조번호        861129 non-null  object \n 4   항번호        666590 non-null  object \n 5   호번호        504904 non-null  object \n 6   조문제목       805869 non-null  object \n 7   조문         848856 non-null  object \n 8   사무판단       767124 non-null  float64\n 9   사무판단근거     700871 non-null  object \n 10  사무명        60113 non-null   object \n 11  수행주체       60116 non-null   object \n 12  사무유형       60071 non-null   object \n 13  위임사무판단     761139 non-null  object \n 14  위임근거규정     5311 non-null    object \n 15  수임기관       4416 non-null    object \n 16  특행기관       93089 non-null   object \n 17  재위임사무판단    702502 non-null  object \n 18  재위임근거규정    54 non-null      object \n 19  재수임기관      13 non-null      object \n 20  위탁사무판단     758703 non-null  float64\n 21  위탁근거규정     3975 non-null    object \n 22  수탁기관       3952 non-null    object \n 23  사무유형(소분류)  60114 non-null   object \n 24  기타         3 non-null       object \ndtypes: float64(2), object(23)\nmemory usage: 164.4+ MB"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html#설명변수소관부처명-법령명-조번호-항번호-호번호-조문제목-조문가-모두-결측치인-행-삭제",
    "href": "dev_posts/MakeBaseTable.html#설명변수소관부처명-법령명-조번호-항번호-호번호-조문제목-조문가-모두-결측치인-행-삭제",
    "title": "Base Table 만들기",
    "section": "1) 설명변수(소관부처명, 법령명, 조번호, 항번호, 호번호, 조문제목, 조문)가 모두 결측치인 행 삭제",
    "text": "1) 설명변수(소관부처명, 법령명, 조번호, 항번호, 호번호, 조문제목, 조문)가 모두 결측치인 행 삭제\n\ndef x_null_drop(df): \n    select_column = ['소관부처명', '법령명', '조번호', '항번호', '호번호', '조문제목', '조문']\n    delete_row_idx = list(df[df[select_column].isnull().all(axis = 1)].index)\n    delete_row_idx.sort(reverse = True)\n    for i in delete_row_idx:\n        df = df.drop([i],axis = 0)\n    return df\n\n\ndata = x_null_drop(data)"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html#section",
    "href": "dev_posts/MakeBaseTable.html#section",
    "title": "Base Table 만들기",
    "section": "",
    "text": "def x_null_drop(df): \n    select_column = ['소관부처명', '법령명', '조번호', '항번호', '호번호', '조문제목', '조문']\n    delete_row_idx = list(df[df[select_column].isnull().all(axis = 1)].index)\n    delete_row_idx.sort(reverse = True)\n    for i in delete_row_idx:\n        df = df.drop([i],axis = 0)\n    return df\n\n\ndata = x_null_drop(data)\n\n(861711, 25)"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html#소관부처명-결측치-처리",
    "href": "dev_posts/MakeBaseTable.html#소관부처명-결측치-처리",
    "title": "Base Table 만들기",
    "section": "2) 소관부처명 결측치 처리",
    "text": "2) 소관부처명 결측치 처리\n\n소관부처명 결측치: 45개\n동일한 법령에 대해서는 동일한 소관부처를 가짐\n이에, 다른 행 중 동일한 법령을 지닌 소관부처 파악 후 결측치 채워줌\n소관부처명 중복 처리\n\n\ndef dep_law_preprocessing(df):\n        # department_idx: '법령명'은 채워져있는데 '소관부처명'은 채워져있지 않은 행의 index\n        department_idx = df[df['소관부처명'].isnull() & df['법령명'].notnull()].index\n        # department_name_list: '소관부처명'이 채워져야할 법령명\n        department_name_list = df[df['소관부처명'].isnull() & df['법령명'].notnull()]['법령명'].unique()\n\n        department_dic = {}\n        department_dic['건설산업기본법'] = '국토교통부'\n        department_dic['보건범죄단속에관한특별조치법시행령'] = '보건복지부'\n        department_dic['항로표지법'] = '해양수산부'\n        department_dic['수산자원관리법'] = '해양수산부'\n        department_dic['연안관리법'] = '해양수산부'\n        department_dic['야생생물 보호 및 관리에 관한 법률'] = '환경부'\n\n        for i in range(len(department_idx)):\n                for j in range(len(department_name_list)):\n                        df.loc[department_idx[i],'소관부처명'] = department_dic[department_name_list[j]]\n\n        # '소관부처명', '법령명' 모두 채워져있지 않은 행\n        \n        return df\n\n\ndef blank_preprocessing(df):\n    df.loc[df['소관부처명']==\"교육부,\\n고용노동부\", \"소관부처명\"] = '고용노동부,교육부'\n    df.loc[df['소관부처명']==\"과학기술정보통신부, \\n교육부\", \"소관부처명\"] = '과학기술정보통신부,교육부'\n    df.loc[df['소관부처명']==\"교육부,\\n과학기술정보통신부\", \"소관부처명\"] = '과학기술정보통신부,교육부'\n    return df\n\n\ndata = dep_law_preprocessing(data)\ndata = blank_preprocessing(data)"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html#법령명-결측치-처리",
    "href": "dev_posts/MakeBaseTable.html#법령명-결측치-처리",
    "title": "Base Table 만들기",
    "section": "3) 법령명 결측치 처리",
    "text": "3) 법령명 결측치 처리\n\n조, 항, 조문 통해 법령명 찾아 삽입\n\n\ndef law_name_preprocessing(df):\n    idx = 14168\n    df.loc[idx,'소관부처명'] = '고용노동부'\n    df.loc[idx,'법령명'] = '근로자퇴직급여 보장법'\n    df.loc[idx,'법령구분'] = 1\n\n    idx = 198519\n    df.loc[idx,'소관부처명'] = '국토교통부'\n    df.loc[idx,'법령명'] = '택수운송사업의 발전에 관한 법률'\n    df.loc[idx,'법령구분'] = 1\n    df.loc[idx,'조번호'] = 11\n    df.loc[idx,'항번호'] = 1\n    df.loc[idx,'조문제목'] = '감차계획의 수립 및 시행 등'\n    idx = 686791\n    df.loc[idx,'소관부처명'] = '해양수산부'\n    df.loc[idx,'법령명'] = '수산업ㆍ어촌 공익기능 증진을 위한 직접지불제도 운영에 관한 법률'\n\n    idx = 708300\n    df.loc[idx,'소관부처명'] = '해양수산부'\n    df.loc[idx,'법령명'] = '해양공간계획 및 관리에 관한 법률'\n\n    idx = 708831\n    df.loc[idx,'소관부처명'] = '해양수산부'\n    df.loc[idx,'법령명'] = '해양폐기물 및 해양오염퇴적물 관리법'\n\n    idx = 766079\n    df.loc[idx,'소관부처명'] = '행정안전부'\n    df.loc[idx,'법령명'] = '새마을금고법'\n\n    idx = 859679\n    df.loc[idx,'소관부처명'] = '환경부'\n    df.loc[idx,'법령명'] = '미세먼지 저감 및 관리에 관한 특별법'\n\n    idx = 859692\n    df.loc[idx,'소관부처명'] = '환경부'\n    df.loc[idx,'법령명'] = '미세먼지 저감 및 관리에 관한 특별법'\n\n    idx = 859755\n    df.loc[idx,'소관부처명'] = '환경부'\n    df.loc[idx,'법령명'] = '미세먼지 저감 및 관리에 관한 특별법'\n    \n    return df\n\n\ndata = law_name_preprocessing(data)"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html#법령구분-처리",
    "href": "dev_posts/MakeBaseTable.html#법령구분-처리",
    "title": "Base Table 만들기",
    "section": "4) 법령구분 처리",
    "text": "4) 법령구분 처리\n\n법령구분 결측치 처리\n법령구분 자료형 int로 통일\n\n\ndef law_category_preprocessing(df):\n    # '법령구분'이 결측치인 행들의 index\n    null_idx = df[df['법령구분'].isnull()].index\n    # 국가법령정보센터 확인 결과, 결측치인 모든 행들은 법률, 즉 '1'에 해당\n    for i in null_idx:\n        df.loc[i,'법령구분'] = 1\n    \n    # 국가법령정보센터 확인 결과, '법령구분'이 공백으로 되어있는 행은 시행령, 즉 '2'에 해당\n    df.loc[df['법령구분']==' ', \"법령구분\"] = 2\n\n    # 법령구분 자료형 통일\n    df['법령구분'] = df['법령구분'].astype('int64')\n\n    return df\n\n\ndef change_law(df):\n        change_laws = ['개발제한구역의 지정 및 관리에 관한 특별조치법', '건설기계관리법', '건설산업기본법', '건설산업기본법 시행령', \n                   '건축물의 분양에 관한 법률', '식품ㆍ의약품 등의 안전기술 진흥법 시행규칙', '위생용품 관리법', '지방세징수법 시행규칙',\n                   '대한민국과 아메리카합중국 간의 상호방위조약 제4조에 의한 시설과 구역 및 대한민국에서의 합중국 군대의 지위에 관한 협정의 시행에 관한 민사특별법 시행규칙',\n                   '대한민국과아메리카합중국간의상호방위조약제4조에의한시설과구역및대한민국에서의합중국군대의지위에관한협정의시행에관한민사특별법시행령']\n        remain_value = [2, 2, 2, 1, 0, 2, 2, 2, 0, 0]   # 수정해야 하는 값\n        change_value = [1, 1, 1, 2, 1, 3, 1, 3, 3, 2]   # 수정할 값\n        change_list = []\n        \n        for i in range(len(change_laws)):\n            if i==4:\n                idxs = df[(df['법령명'] == change_laws[i]) & (df['법령구분'] != 1)].index\n            elif i &gt; 7:\n                idxs = df[(df['법령명'] == change_laws[i])].index\n            else:\n                idxs = df[(df['법령명'] == change_laws[i]) & (df['법령구분'] == remain_value[i])].index\n            for idx in idxs:\n                change_list.append([idx, change_value[i]])\n        \n        # 법령 구분 값 변경\n        for change in change_list:\n            df.loc[change[0], \"법령구분\"] = change[1]\n        \n        return df\n\n\ndata = law_category_preprocessing(data)\ndata = change_law(data)"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html#사무판단-처리",
    "href": "dev_posts/MakeBaseTable.html#사무판단-처리",
    "title": "Base Table 만들기",
    "section": "5) 사무판단 처리",
    "text": "5) 사무판단 처리\n\n’ ’ -&gt; nan, ‘0’ -&gt; 0 , ‘1’ -&gt; 1, ‘0 1’ -&gt; 2 float 형태로 변환\n\n\ndef decision_preprocessing(df):\n    # 표기방식 통일\n    idx_nan = df[(df['사무판단'] == ' ')].index #idx_nan: '사무판단'이 nan인 행의 index\n    for i in idx_nan:\n        df.loc[i,'사무판단'] = np.nan\n    idx_0 = df[(df['사무판단'] == '0')].index #idx_0: '사무판단'이 '0'인 행의 index\n    for i in idx_0:\n        df.loc[i,'사무판단'] = 0\n    idx_1 = df[(df['사무판단'] == '1')].index #idx_1: '사무판단'이 '1'인 행의 index\n    for i in idx_1:\n        df.loc[i,'사무판단'] = 1\n    idx_2 = df[(df['사무판단'] == '0 1')].index #idx_2: '사무판단'이 '0 1'인 행의 index\n    for i in idx_2:\n        df.loc[i,'사무판단'] = 2\n\n    # 오류 행 삭제\n    ## 경우1: 사무가 아님에도 사무 유형이 분류된 경우\n    delete_0_idx = list((df[(df['사무판단'] == 0)  & (df['사무유형(소분류)'].notna())]).index)\n    df = df.drop(delete_0_idx, axis = 0)\n    \n    ## 경우2: 사무임에도 사무 유형이 분류되지 않은 경우\n    delete_1_idx1 = list((df[(df['사무판단'] == 1)  & (df['사무유형'].isnull())]).index)\n    df = df.drop(delete_1_idx1, axis = 0)\n    \n    delete_1_idx2 = list((df[(df['사무판단'] == 1)  & (df['사무유형(소분류)'].isnull())]).index)\n    df = df.drop(delete_1_idx2, axis = 0)\n\n    # 결측행 처리\n    ## 경우1: 사무 유형이 분류된 경우 =&gt; '1'로 채움\n    change_1_idx = df[(df['사무판단'].isnull())  & (df['사무유형'].notna()) & (df['사무유형(소분류)'].notna())].index\n    df.loc[change_1_idx, '사무판단'] = 1\n    \n    # 경우2: 사무 유형이 분류되지 않은 경우 =&gt; '0'으로 채움\n    change_0_idx = df[(df['사무판단'].isnull())  & (df['사무유형'].isnull()) & (df['사무유형(소분류)'].isnull())].index\n    df.loc[change_0_idx,'사무판단'] = 0\n    \n    # 자료형 통일\n    df['사무판단'] = df['사무판단'].astype('int64')\n\n    return df\n\n\ndata = decision_preprocessing(data)"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html#소관부처명-공백-처리",
    "href": "dev_posts/MakeBaseTable.html#소관부처명-공백-처리",
    "title": "Base Table 만들기",
    "section": "6) 소관부처명 공백 처리",
    "text": "6) 소관부처명 공백 처리\n\ndef blank_preprocessing(df):\n    df.loc[df['소관부처명']==\"교육부,\\n고용노동부\", \"소관부처명\"] = '고용노동부,교육부'\n    df.loc[df['소관부처명']==\"과학기술정보통신부, \\n교육부\", \"소관부처명\"] = '과학기술정보통신부,교육부'\n    df.loc[df['소관부처명']==\"교육부,\\n과학기술정보통신부\", \"소관부처명\"] = '과학기술정보통신부,교육부'\n    return df\n    \n\n\ndata = blank_preprocessing(data)"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html#조문-조문-제목-결측치-처리",
    "href": "dev_posts/MakeBaseTable.html#조문-조문-제목-결측치-처리",
    "title": "Base Table 만들기",
    "section": "7) 조문, 조문 제목 결측치 처리",
    "text": "7) 조문, 조문 제목 결측치 처리\n\n조문, 조문 제목 null값이면 ’0’으로 채움\n\n\ndef law_preprocessing(df):\n    df.loc[df['조문제목'].isna(), '조문제목'] = '0'\n    df.loc[df['조문'].isna(), '조문'] = '0'\n    return df\n\n\ndata = law_preprocessing(data)"
  },
  {
    "objectID": "dev_posts/BaseTable2_EDA.html",
    "href": "dev_posts/BaseTable2_EDA.html",
    "title": "EDA ( BaseTable_2.csv 사용 )",
    "section": "",
    "text": "# 필요 라이브러리 설치\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\nfrom matplotlib import rc\n%matplotlib inline\n\nrc('font', family='AppleGothic')\nplt.rcParams['axes.unicode_minus'] = False\n\n\n# 데이터 load\ndata = pd.read_csv('BaseTable_2.csv')\n\n/var/folders/fs/zfypqyv96hs22x794hfx0ycm0000gn/T/ipykernel_16581/684496263.py:2: DtypeWarning: Columns (4,5,13,16,17,18,19,24) have mixed types. Specify dtype option on import or set low_memory=False.\n  data = pd.read_csv('BaseTable_2.csv')\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 861624 entries, 0 to 861623\nData columns (total 25 columns):\n #   Column     Non-Null Count   Dtype  \n---  ------     --------------   -----  \n 0   소관부처명      861624 non-null  object \n 1   법령명        861624 non-null  object \n 2   법령구분       861624 non-null  int64  \n 3   조번호        861043 non-null  object \n 4   항번호        666511 non-null  object \n 5   호번호        504874 non-null  object \n 6   조문제목       861624 non-null  object \n 7   조문         861624 non-null  object \n 8   사무판단       861624 non-null  int64  \n 9   사무판단근거     700810 non-null  object \n 10  사무명        60068 non-null   object \n 11  수행주체       60069 non-null   object \n 12  사무유형       60026 non-null   object \n 13  위임사무판단     761044 non-null  object \n 14  위임근거규정     5292 non-null    object \n 15  수임기관       4398 non-null    object \n 16  특행기관       93064 non-null   object \n 17  재위임사무판단    702426 non-null  object \n 18  재위임근거규정    53 non-null      object \n 19  재수임기관      13 non-null      object \n 20  위탁사무판단     758608 non-null  float64\n 21  위탁근거규정     3970 non-null    object \n 22  수탁기관       3943 non-null    object \n 23  사무유형(소분류)  60026 non-null   object \n 24  기타         3 non-null       object \ndtypes: float64(1), int64(2), object(22)\nmemory usage: 164.3+ MB"
  },
  {
    "objectID": "dev_posts/BaseTable2_EDA.html#라이브러리-설치-및-데이터-불러오기",
    "href": "dev_posts/BaseTable2_EDA.html#라이브러리-설치-및-데이터-불러오기",
    "title": "EDA ( BaseTable_2.csv 사용 )",
    "section": "",
    "text": "# 필요 라이브러리 설치\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\nfrom matplotlib import rc\n%matplotlib inline\n\nrc('font', family='AppleGothic')\nplt.rcParams['axes.unicode_minus'] = False\n\n\n# 데이터 load\ndata = pd.read_csv('BaseTable_2.csv')\n\n/var/folders/fs/zfypqyv96hs22x794hfx0ycm0000gn/T/ipykernel_16581/684496263.py:2: DtypeWarning: Columns (4,5,13,16,17,18,19,24) have mixed types. Specify dtype option on import or set low_memory=False.\n  data = pd.read_csv('BaseTable_2.csv')\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 861624 entries, 0 to 861623\nData columns (total 25 columns):\n #   Column     Non-Null Count   Dtype  \n---  ------     --------------   -----  \n 0   소관부처명      861624 non-null  object \n 1   법령명        861624 non-null  object \n 2   법령구분       861624 non-null  int64  \n 3   조번호        861043 non-null  object \n 4   항번호        666511 non-null  object \n 5   호번호        504874 non-null  object \n 6   조문제목       861624 non-null  object \n 7   조문         861624 non-null  object \n 8   사무판단       861624 non-null  int64  \n 9   사무판단근거     700810 non-null  object \n 10  사무명        60068 non-null   object \n 11  수행주체       60069 non-null   object \n 12  사무유형       60026 non-null   object \n 13  위임사무판단     761044 non-null  object \n 14  위임근거규정     5292 non-null    object \n 15  수임기관       4398 non-null    object \n 16  특행기관       93064 non-null   object \n 17  재위임사무판단    702426 non-null  object \n 18  재위임근거규정    53 non-null      object \n 19  재수임기관      13 non-null      object \n 20  위탁사무판단     758608 non-null  float64\n 21  위탁근거규정     3970 non-null    object \n 22  수탁기관       3943 non-null    object \n 23  사무유형(소분류)  60026 non-null   object \n 24  기타         3 non-null       object \ndtypes: float64(1), int64(2), object(22)\nmemory usage: 164.3+ MB"
  },
  {
    "objectID": "dev_posts/BaseTable2_EDA.html#사무판단-개수-파악",
    "href": "dev_posts/BaseTable2_EDA.html#사무판단-개수-파악",
    "title": "EDA ( BaseTable_2.csv 사용 )",
    "section": "1) 사무판단 개수 파악",
    "text": "1) 사무판단 개수 파악\n\n사무판단 종류: 3개\n\n사무판단이 0인 경우 : 801598개\n사무판단이 1인 경우 : 60023개\n사무판단이 2인 경우 : 3개\n\n사무판단이 2인 경우 빼고 0과 1인 경우만 비교하기\n\n\ndef judgment_graph(df):\n    # 전체 갯수\n    N = len(df)\n    \n    # 0의 비율, 1의 비율 계산하기\n    ratio_0 = (len(df[df['사무판단'] == 0]))/N *100\n    print(f\" 0의 비율 : {ratio_0}\")\n    ratio_1 = (len(df[df['사무판단'] == 1]))/N *100\n    print(f\" 1의 비율 : {ratio_1}\")\n    \n    # pie chart 생성\n    ratio = [ratio_0, ratio_1]\n    labels = [0,1]\n    explode = [0, 0.10]\n    colors = sns.color_palette('pastel')[3:5]\n    plt.pie(ratio, colors = colors, autopct='%.0f%%', startangle= 120, explode=explode)\n    plt.legend(['사무가 아니다', '사무이다'], bbox_to_anchor=(1.3, 1))\n    plt.title('\\n\\n 사무판단 비율 \\n')\n    plt.show()\n\n\njudgment_graph(data)\n\n 0의 비율 : 93.03338811360872\n 1의 비율 : 6.966263706674837"
  },
  {
    "objectID": "dev_posts/BaseTable2_EDA.html#소관부처명에-따른-사무판단",
    "href": "dev_posts/BaseTable2_EDA.html#소관부처명에-따른-사무판단",
    "title": "EDA ( BaseTable_2.csv 사용 )",
    "section": "2) 소관부처명에 따른 사무판단",
    "text": "2) 소관부처명에 따른 사무판단\n\n소관부처명의 종류 : 122개\n사무가 가장 많은 5개 소관부처명 파악\n사무 비율이 가장 큰 5개 소관부처명 파악\n\n\n사무가 가장 많은 소관부처명 파악\n\ndef num_department_judgment_graph(df):\n    # 각 소관부처명 별 사무판단 갯수 파악\n    department_judgment = []\n    for ii in df['소관부처명'].unique():\n        department_count_0 = len(df.loc[(df['소관부처명']==ii) & (df['사무판단']==0)])\n        department_count_1 = len(df.loc[(df['소관부처명']==ii) & (df['사무판단']==1)])\n        # [1인 갯수, 0인 갯수, 1인 비율, 소관부처명]\n        department_judgment.append([department_count_1, department_count_0, department_count_1/(department_count_0+department_count_1), ii])\n    \n    # 사무가 가장 많은 소관부처명 파악\n    department_judgment.sort(key=lambda x:x[0], reverse = True)\n    \n    num_department_judgment = []\n    num_department = []\n    for i in range(len(department_judgment)):\n        num_department_judgment.append(department_judgment[i][0])\n        num_department.append(department_judgment[i][3])\n        \n    # 사무가 많은 소관부처명 순서대로 막대 그래프\n    fig, ax = plt.subplots(figsize=(7.5, 4.5))\n    colors = sns.color_palette('pastel')[4]\n    plt.bar(range(len(num_department_judgment)), num_department_judgment, color=colors)\n    plt.title('\\n\\n\\n 소관부처별 사무판단 개수 파악\\n')\n    plt.ylabel('개수')\n    plt.xlim([-1,len(num_department_judgment)])\n    plt.xticks([])\n    plt.ylim([0,6000]);\n    plt.yticks(np.arange(0, 6000, step=1000));\n    \n    # 사무가 가장 많은 소관부처명 5개 순서대로 막대 그래프\n    fig, ax = plt.subplots(figsize=(7.5, 4.5))\n    colors = sns.color_palette('pastel')[4]\n    bar = plt.bar(range(5), num_department_judgment[:5], color=colors)\n    plt.title('\\n\\n\\n 소관부처별 사무판단 Top5 개수 파악\\n')\n    plt.ylabel('개수')\n    plt.xlim([-0.5,4.5])\n    plt.xticks(np.arange(0, 5, 1), labels = [num_department[0],num_department[1],num_department[2],num_department[3],num_department[4]])\n    plt.ylim([0,6000]);\n    plt.yticks(np.arange(0, 6000, step=1000));\n    for rect in bar:\n        height = rect.get_height()\n        plt.text(rect.get_x() + rect.get_width()/2.0, height, '%d' % height, ha='center', va='bottom', size = 10)\n\n\nnum_department_judgment_graph(data)"
  },
  {
    "objectID": "dev_posts/BaseTable2_EDA.html#section-1",
    "href": "dev_posts/BaseTable2_EDA.html#section-1",
    "title": "EDA ( BaseTable_2.csv 사용 )",
    "section": "",
    "text": "사무비율이 가장 큰 소관부처명 파악\n\ndef ratio_department_judgment_graph(df):\n    # 각 소관부처명 별 사무판단 갯수 파악\n    department_judgment = []\n    for ii in df['소관부처명'].unique():\n        department_count_0 = len(df.loc[(df['소관부처명']==ii) & (df['사무판단']==0)])\n        department_count_1 = len(df.loc[(df['소관부처명']==ii) & (df['사무판단']==1)])\n        # [1인 갯수, 0인 갯수, 1인 비율, 소관부처명]\n        department_judgment.append([department_count_1, department_count_0, department_count_1/(department_count_0+department_count_1), ii])\n    \n    # 사무비율이 가장 큰 소관부처명 파악\n    department_judgment.sort(key=lambda x:x[2], reverse = True)\n    \n    ratio_department_judgment = []\n    ratio_department = []\n    for i in range(len(department_judgment)):\n        ratio_department_judgment.append(department_judgment[i][2])\n        ratio_department.append(department_judgment[i][3])\n        \n    # 사무가 많은 소관부처명 순서대로 막대 그래프\n    fig, ax = plt.subplots(figsize=(7.5, 4.5))\n    colors = sns.color_palette('pastel')[4]\n    plt.bar(range(len(ratio_department_judgment)), ratio_department_judgment, color=colors)\n    plt.title('\\n\\n\\n 소관부처별 사무판단 비율 파악\\n')\n    plt.ylabel('비율')\n    plt.xlim([-1,len(ratio_department_judgment)])\n    plt.xticks([])\n    plt.ylim([0,0.4]);\n    plt.yticks(np.arange(0, 0.5, step=0.1));\n    \n    # 사무가 가장 많은 소관부처명 5개 순서대로 막대 그래프\n    fig, ax = plt.subplots(figsize=(7.5, 4.5))\n    colors = sns.color_palette('pastel')[4]\n    bar = plt.bar(range(5), ratio_department_judgment[:5], color=colors)\n    plt.title('\\n\\n\\n 소관부처별 사무판단 Top5 비율 파악\\n')\n    plt.ylabel('비율')\n    plt.xlim([-0.5,4.5])\n    plt.xticks(np.arange(0, 5, 1), labels = [ratio_department[0].replace(',','\\n'),ratio_department[1].replace(',','\\n'),ratio_department[2].replace(',','\\n'),ratio_department[3].replace(',','\\n'),ratio_department[4].replace(',','\\n')])\n    plt.ylim([0,0.4]);\n    plt.yticks(np.arange(0, 0.5, step=0.1));\n    for rect in bar:\n        height = rect.get_height()\n        plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.3f' % height, ha='center', va='bottom', size = 10)\n\n\nratio_department_judgment_graph(data)"
  },
  {
    "objectID": "dev_posts/BaseTable2_EDA.html#법령명에-따른-사무판단",
    "href": "dev_posts/BaseTable2_EDA.html#법령명에-따른-사무판단",
    "title": "EDA ( BaseTable_2.csv 사용 )",
    "section": "3) 법령명에 따른 사무판단",
    "text": "3) 법령명에 따른 사무판단\n\n법령명의 종류 : 4324개\n사무가 가장 많은 5개 법령명 파악\n사무 비율이 가장 큰 5개 법령명 파악\n\n\n사무가 가장 많은 법령명 파악\n\ndef num_lawname_judgment_graph(df):\n    # 각 법령명 별 사무판단 갯수 파악\n    lawname_judgment = []\n    for ii in df['법령명'].unique():\n        lawname_count_0 = len(df.loc[(df['법령명']==ii) & (df['사무판단']==0)])\n        lawname_count_1 = len(df.loc[(df['법령명']==ii) & (df['사무판단']==1)])\n        # [1인 갯수, 0인 갯수, 1인 비율, 법령명]\n        lawname_judgment.append([lawname_count_1, lawname_count_0, lawname_count_1/(lawname_count_0+lawname_count_1), ii])\n    \n    # 사무가 가장 많은 법령명 파악\n    lawname_judgment.sort(key=lambda x:x[0], reverse = True)\n    \n    num_lawname_judgment = []\n    num_lawname = []\n    for i in range(len(lawname_judgment)):\n        num_lawname_judgment.append(lawname_judgment[i][0])\n        num_lawname.append(lawname_judgment[i][3])\n        \n    # 사무가 많은 법령명 순서대로 막대 그래프\n    fig, ax = plt.subplots(figsize=(7.5, 4.5))\n    colors = sns.color_palette('pastel')[4]\n    plt.bar(range(len(num_lawname_judgment)), num_lawname_judgment, color=colors)\n    plt.title('\\n\\n\\n 법령명별 사무판단 개수 파악\\n')\n    plt.ylabel('개수')\n    plt.xlim([-1,len(num_lawname_judgment)])\n    plt.xticks([])\n    plt.ylim([0,400]);\n    plt.yticks(np.arange(0, 400, step=100));\n    \n    # 사무가 가장 많은 법령명 5개 순서대로 막대 그래프\n    fig, ax = plt.subplots(figsize=(7.5, 4.5))\n    colors = sns.color_palette('pastel')[4]\n    bar = plt.bar(range(5), num_lawname_judgment[:5], color=colors)\n    plt.title('\\n\\n\\n 법령명별 사무판단 Top5 개수 파악\\n')\n    plt.ylabel('개수')\n    plt.xlim([-0.5,4.5])\n    plt.xticks(np.arange(0, 5, 1), labels = ['\\n'+num_lawname[0],num_lawname[1],'\\n\\n'+num_lawname[2],num_lawname[3],'\\n'+num_lawname[4]])\n    plt.ylim([0,400]);\n    plt.yticks(np.arange(0, 400, step=100));\n    for rect in bar:\n        height = rect.get_height()\n        plt.text(rect.get_x() + rect.get_width()/2.0, height, '%d' % height, ha='center', va='bottom', size = 10)\n\n\nnum_lawname_judgment_graph(data)\n\n['제주특별자치도 설치 및 국제자유도시 조성을 위한 특별법', '자본시장과 금융투자업에 관한 법률', '지방세특례제한법', '재난 및 안전관리 기본법', '대기환경보전법']"
  },
  {
    "objectID": "dev_posts/BaseTable2_EDA.html#section-3",
    "href": "dev_posts/BaseTable2_EDA.html#section-3",
    "title": "EDA ( BaseTable_2.csv 사용 )",
    "section": "",
    "text": "사무비율이 가장 큰 법령명 파악\n\ndef ratio_lawname_judgment_graph(df):\n    # 각 법령명 별 사무판단 갯수 파악\n    lawname_judgment = []\n    for ii in df['법령명'].unique():\n        lawname_count_0 = len(df.loc[(df['법령명']==ii) & (df['사무판단']==0)])\n        lawname_count_1 = len(df.loc[(df['법령명']==ii) & (df['사무판단']==1)])\n        # [1인 갯수, 0인 갯수, 1인 비율, 법령명]\n        lawname_judgment.append([lawname_count_1, lawname_count_0, lawname_count_1/(lawname_count_0+lawname_count_1), ii])\n    \n    # 사무가 가장 많은 법령명 파악\n    lawname_judgment.sort(key=lambda x:x[2], reverse = True)\n    \n    ratio_lawname_judgment = []\n    ratio_lawname = []\n    for i in range(len(lawname_judgment)):\n        ratio_lawname_judgment.append(lawname_judgment[i][2])\n        ratio_lawname.append(lawname_judgment[i][3])\n\n    # 사무가 많은 법령명 순서대로 막대 그래프\n    fig, ax = plt.subplots(figsize=(7.5, 4.5))\n    colors = sns.color_palette('pastel')[4]\n    plt.bar(range(len(ratio_lawname_judgment)), ratio_lawname_judgment, color=colors)\n    plt.title('\\n\\n\\n 법령명별 사무판단 비율 파악\\n')\n    plt.ylabel('비율')\n    plt.xlim([-1,len(ratio_lawname_judgment)])\n    plt.xticks([])\n    plt.ylim([0,1.2]);\n    plt.yticks(np.arange(0, 1.2, step=0.2));\n    \n    # 사무가 가장 많은 법령명 5개 순서대로 막대 그래프\n    fig, ax = plt.subplots(figsize=(7.5, 4.5))\n    colors = sns.color_palette('pastel')[4]\n    bar = plt.bar(range(5), ratio_lawname_judgment[:5], color=colors)\n    plt.title('\\n\\n\\n 법령명별 사무판단 Top5 비율 파악\\n')\n    plt.ylabel('비율')\n    plt.xlim([-0.5,4.5])\n    plt.xticks(np.arange(0, 5, 1), labels = [ratio_lawname[0],'\\n'+ratio_lawname[1],'\\n\\n'+ratio_lawname[2],ratio_lawname[3],'\\n'+ratio_lawname[4]])\n    plt.ylim([0,1.2]);\n    plt.yticks(np.arange(0, 1.2, step=0.2));\n    for rect in bar:\n        height = rect.get_height()\n        plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.3f' % height, ha='center', va='bottom', size = 10)\n\n\nratio_lawname_judgment_graph(data)"
  },
  {
    "objectID": "dev_posts/BaseTable2_EDA.html#법령구분에-따른-사무판단",
    "href": "dev_posts/BaseTable2_EDA.html#법령구분에-따른-사무판단",
    "title": "EDA ( BaseTable_2.csv 사용 )",
    "section": "4) 법령구분에 따른 사무판단",
    "text": "4) 법령구분에 따른 사무판단\n\n법령구분 종류: 3개\n\n법령구분이 1인 경우 : 365424개\n법령구분이 2인 경우 : 319805개\n법령구분이 3인 경우 : 176395개\n\n\n\ndef lawclass_judgment_graph(df):\n    groups = ['1', '2', '3']\n    values1 = [len(df.loc[(df['법령구분']==1) & (df['사무판단']==0) ]), len(df.loc[(df['법령구분']==2) & (df['사무판단']==0) ]), len(df.loc[(df['법령구분']==3) & (df['사무판단']==0) ])]\n    values2 = [len(df.loc[(df['법령구분']==1) & (df['사무판단']==1) ]), len(df.loc[(df['법령구분']==2) & (df['사무판단']==1) ]), len(df.loc[(df['법령구분']==3) & (df['사무판단']==1) ])]\n    fig, ax = plt.subplots(figsize=(3, 5))\n    colors = sns.color_palette('pastel')[3:5]\n\n    # stack bar 로 구성\n    ax.bar(groups, values1, color = colors[0])\n    ax.bar(groups, values2, bottom = values1, color = colors[1])\n    plt.title('법령구분에 따른 사무판단 여부 파악\\n\\n')\n    plt.xlabel('법령구분')\n    plt.ylabel('개수')\n    plt.legend(['사무가 아니다', '사무이다'], bbox_to_anchor=(1.7, 1))\n    plt.ylim([0,400000])\n    plt.yticks(np.arange(0, 500000, step=100000))\n    plt.show()\n\n\nlawclass_judgment_graph(data)\n\n\n\n\n\n# def law_work_count(i):\n#     a = len(df.loc[(df['법령구분']==i) & (df['사무판단']==0), ])\n#     b = len(df.loc[(df['법령구분']==i) & (df['사무판단']==1), ])\n#     c = len(df.loc[(df['법령구분']==i) & (df['사무판단']==2), ])\n\n#     print(f\"법령 구분 {i}일때 ========\")\n#     print(f\"사무x: {a}\")\n#     print(f\"사무O: {b}\")\n#     print(f\"애매: {c}\")\n    \n\n#     result = [a, b, c]\n#     return result\n\n\n# result = []\n# for i in range(1, 4):\n#     result.append(law_work_count(i))\n# result\n\n\n# # 법령 구분에 따른 사무판단 비율 계산\n# ratio_df = df.groupby(['법령구분', '사무판단']).size().unstack().T\n# ratio_df = ratio_df.div(ratio_df.sum(axis=1), axis=0)\n\n# # 비율을 시각화\n# ratio_df.T.plot(kind='bar', stacked=True)\n# plt.title('법령구분에 따른 사무판단 비율')\n# plt.xlabel('법령구분')\n# plt.ylabel('Administrative Decision')\n# plt.show()"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html#조문-조문제목-처리",
    "href": "dev_posts/MakeBaseTable.html#조문-조문제목-처리",
    "title": "Base Table 만들기",
    "section": "5) 조문, 조문제목 처리",
    "text": "5) 조문, 조문제목 처리\n\n조문, 조문 제목 null값이면 ’0’으로 채움\n\n\ndef law_preprocessing(df):\n    df.loc[df['조문제목'].isna(), '조문제목'] = '0'\n    df.loc[df['조문'].isna(), '조문'] = '0'\n    return df\n\n\ndata = law_preprocessing(data)"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html#사무판단-처리-및-보류항-제거",
    "href": "dev_posts/MakeBaseTable.html#사무판단-처리-및-보류항-제거",
    "title": "Base Table 만들기",
    "section": "5) 사무판단 처리 및 보류항 제거",
    "text": "5) 사무판단 처리 및 보류항 제거\n\n’ ’ -&gt; nan, ‘0’ -&gt; 0 , ‘1’ -&gt; 1, ‘0 1’ -&gt; 2 float 형태로 변환\n\n\ndef decision_preprocessing(df):\n    # 표기방식 통일\n    idx_nan = df[(df['사무판단'] == ' ')].index #idx_nan: '사무판단'이 nan인 행의 index\n    for i in idx_nan:\n        df.loc[i,'사무판단'] = np.nan\n    idx_0 = df[(df['사무판단'] == '0')].index #idx_0: '사무판단'이 '0'인 행의 index\n    for i in idx_0:\n        df.loc[i,'사무판단'] = 0\n    idx_1 = df[(df['사무판단'] == '1')].index #idx_1: '사무판단'이 '1'인 행의 index\n    for i in idx_1:\n        df.loc[i,'사무판단'] = 1\n    idx_2 = df[(df['사무판단'] == '0 1')].index #idx_2: '사무판단'이 '0 1'인 행의 index\n    for i in idx_2:\n        df.loc[i,'사무판단'] = 2\n\n    # 오류 행 삭제\n    ## 경우1: 사무가 아님에도 사무 유형이 분류된 경우\n    delete_0_idx = list((df[(df['사무판단'] == 0)  & (df['사무유형(소분류)'].notna())]).index)\n    df = df.drop(delete_0_idx, axis = 0)\n    \n    ## 경우2: 사무임에도 사무 유형이 분류되지 않은 경우\n    delete_1_idx1 = list((df[(df['사무판단'] == 1)  & (df['사무유형'].isnull())]).index)\n    df = df.drop(delete_1_idx1, axis = 0)\n    \n    delete_1_idx2 = list((df[(df['사무판단'] == 1)  & (df['사무유형(소분류)'].isnull())]).index)\n    df = df.drop(delete_1_idx2, axis = 0)\n\n    # 결측행 처리\n    ## 경우1: 사무 유형이 분류된 경우 =&gt; '1'로 채움\n    change_1_idx = df[(df['사무판단'].isnull())  & (df['사무유형'].notna()) & (df['사무유형(소분류)'].notna())].index\n    df.loc[change_1_idx, '사무판단'] = 1\n    \n    # 경우2: 사무 유형이 분류되지 않은 경우 =&gt; '0'으로 채움\n    change_0_idx = df[(df['사무판단'].isnull())  & (df['사무유형'].isnull()) & (df['사무유형(소분류)'].isnull())].index\n    df.loc[change_0_idx,'사무판단'] = 0\n    \n    # 사무판단 보류 행 삭제 \n    delete_index = df[df['사무판단'] == 2].index\n    delete_index = delete_index.sort_values(ascending = False).tolist()\n    for i in delete_index:\n        df.drop(i, inplace=True)\n    \n    # 자료형 통일\n    df['사무판단'] = df['사무판단'].astype('int64')\n\n    return df\n\n\ndata = decision_preprocessing(data)"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html#사무판단-근거-처리",
    "href": "dev_posts/MakeBaseTable.html#사무판단-근거-처리",
    "title": "Base Table 만들기",
    "section": "6) 사무판단 근거 처리",
    "text": "6) 사무판단 근거 처리\n\n사무판단 공백처리, 사무판단 근거: (삭제, 판단 불가) -&gt; np.nan 변환\n\n\n# 열 안의 공백 제거 함수 정의\ndef remove_whitespace(cell):\n    return cell.strip() if isinstance(cell, str) else cell\n\ndata['사무판단근거'] = data['사무판단근거'].apply(remove_whitespace)\n\n\ndef change_null(df):\n    df.loc[df['사무판단근거']=='판단 불가', '사무판단근거'] = np.nan\n    df.loc[df['사무판단근거']=='판단불가', '사무판단근거'] = np.nan\n    df.loc[df['사무판단근거']=='삭제', '사무판단근거'] = np.nan\n    return df\n\n\ndata = change_null(data)"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html#사무유형-처리",
    "href": "dev_posts/MakeBaseTable.html#사무유형-처리",
    "title": "Base Table 만들기",
    "section": "7) 사무유형 처리",
    "text": "7) 사무유형 처리\n\n사무유형 공백 제거, 사무유형에 없는 유형(공동, 정부) 수정\n\n\ndef change_law_type(df):\n    df.loc[df['사무유형']=='국가 ', '사무유형'] = '국가'\n    df.loc[df['사무유형']=='시도 ', '사무유형'] = '시도'\n    df.loc[df['사무유형']=='시군구 ', '사무유형'] = '시군구'\n    df.loc[df['사무유형']=='국가\\n시도', '사무유형'] = '국가-시도'\n    df.loc[df['사무유형']=='국가 ', '사무유형'] = '국가'\n    df.loc[df['사무유형']=='\\n국가-시도-시군구', '사무유형'] = '국가-시도-시군구'\n\n    df.loc[df['사무유형']=='공동', '사무유형'] = '국가-시도'\n    df.loc[df['사무유형']=='정부', '사무유형'] = '국가' \n    return df\n\n\ndata = change_law_type(data)"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html#위임-사무-판단-처리",
    "href": "dev_posts/MakeBaseTable.html#위임-사무-판단-처리",
    "title": "Base Table 만들기",
    "section": "8) 위임 사무 판단 처리",
    "text": "8) 위임 사무 판단 처리\n\n자료형 변경 및 이상치 변경\n\n\ndef change_delegated_tasks(df):\n    df.loc[(df['위임사무판단']==0.0)|(df['위임사무판단']=='0')|(df['위임사무판단']=='0.0')|(df['위임사무판단']==0.0)|(df['위임사무판단'].isna()), '위임사무판단'] = 0\n    df.loc[(df['위임사무판단']==1.0)|(df['위임사무판단']=='1'), '위임사무판단'] = 1\n    df.loc[(df['위임사무판단']=='0 1'), '위임사무판단'] = 2    # 애매한 친구\n\n    df['위임사무판단'] = df['위임사무판단'].astype(int)\n    return df\n\n\ndata = change_delegated_tasks(data)"
  },
  {
    "objectID": "dev_posts/MakeBaseTable.html#나머지-변수들-자료형-통일",
    "href": "dev_posts/MakeBaseTable.html#나머지-변수들-자료형-통일",
    "title": "Base Table 만들기",
    "section": "9) 나머지 변수들 자료형 통일",
    "text": "9) 나머지 변수들 자료형 통일\n\n특행기관, 재위임 사무판단, 재위임 근거 규정, 재수임기관, 위탁사무판단\n\n\ndef change_else(df):\n    # 특행기관\n    df.loc[(df['특행기관']=='-')|(df['특행기관']=='0')|(df['특행기관']=='0.0')|(df['특행기관'].isna())|(df['특행기관']=='`')|(df['특행기관']=='시-도 본부장'), '특행기관'] = 0\n    df.loc[(df['특행기관']==1.0)|(df['특행기관']=='1'), '특행기관'] = 1\n    df['특행기관'] = df['특행기관'].astype(int)\n\n    # 재위임 사무판단\n    df.loc[(df['재위임사무판단']=='국가-시도공동사무')|(df['재위임사무판단']=='0')|(df['재위임사무판단']=='0.0')|(df['재위임사무판단'].isna())|(df['재위임사무판단']==0.0), '재위임사무판단'] = 0\n    df.loc[(df['재위임사무판단']==1.0)|(df['재위임사무판단']=='1'), '재위임사무판단'] = 1\n    df['재위임사무판단'] = df['재위임사무판단'].astype(int)\n\n    # 재위임 근거 규정\n    df.loc[(df['재위임근거규정']==0.0)|(df['재위임근거규정'].isna()), '재위임근거규정'] = np.nan\n\n    # 재수임기관\n    df.loc[(df['재수임기관']==0.0)|(df['재수임기관'].isna()), '재수임기관'] = np.nan\n\n    # 위탁사무판단\n    df.loc[(df['위탁사무판단']==0.)|(df['위탁사무판단'].isna()), '위탁사무판단'] = 0\n    df.loc[(df['위탁사무판단']==1.), '위탁사무판단'] = 1\n    df['위탁사무판단'] = df['위탁사무판단'].astype(int)\n    \n    return df\n\n\ndata = change_else(data)"
  },
  {
    "objectID": "dev_posts/DL정리.html",
    "href": "dev_posts/DL정리.html",
    "title": "딥러닝 코드 정리",
    "section": "",
    "text": "# from google.colab import drive\n# drive.mount('/content/drive')\n# cd /content/drive/MyDrive/Colab Notebooks/법령프로젝트\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm"
  },
  {
    "objectID": "dev_posts/DL정리.html#조문-사무판단-추출",
    "href": "dev_posts/DL정리.html#조문-사무판단-추출",
    "title": "딥러닝 코드 정리",
    "section": "1) [조문, 사무판단] 추출",
    "text": "1) [조문, 사무판단] 추출\n\nsub_df = df.loc[df['사무판단']!=2, [\"조문\", \"사무판단\"]]\nsub_df\n\n\n\n\n\n\n\n\n조문\n사무판단\n\n\n\n\n0\n제1장 총칙\n0\n\n\n1\n제1조(목적) 이 법은 개인정보의 처리 및 보호에 관한 사항을 정함으로써 개인의 자...\n0\n\n\n2\n제2조(정의) 이 법에서 사용하는 용어의 뜻은 다음과 같다. &lt;개정 2014.3.2...\n0\n\n\n3\n1. \"개인정보\"란 살아 있는 개인에 관한 정보로서 다음 각 목의 어느 하나에 해당...\n0\n\n\n4\n1의2. \"가명처리\"란 개인정보의 일부를 삭제하거나 일부 또는 전부를 대체하는 등의...\n0\n\n\n...\n...\n...\n\n\n861616\n1. 한국수자원공사\n0\n\n\n861617\n2. 법 제56조에 따른 한국상하수도협회\n0\n\n\n861618\n제32조(규제의 재검토) 환경부장관은 다음 각 호의 사항에 대하여 다음 각 호의 기...\n0\n\n\n861619\n1. 제23조의2제1항ㆍ제4항 및 별표 7의2에 따른 저수조청소업의 인력ㆍ시설 및 ...\n0\n\n\n861620\n2. 제31조 및 별표 8에 따른 기술진단 대행 기관의 장비와 기술인력: 2014년...\n0\n\n\n\n\n861621 rows × 2 columns\n\n\n\n\n#sub_df.to_csv('sub_df.csv')      # 임시 저장"
  },
  {
    "objectID": "dev_posts/DL정리.html#모델-정의",
    "href": "dev_posts/DL정리.html#모델-정의",
    "title": "딥러닝 코드 정리",
    "section": "1) 모델 정의",
    "text": "1) 모델 정의\n\nimport torch.nn as nn\n\nclass MyModel(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(MyModel, self).__init__()\n        self.layer1 = nn.Linear(input_size, hidden_size)\n        self.batch_norm = nn.BatchNorm1d(hidden_size)  \n        self.relu = nn.ReLU()\n        self.layer2 = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        # 모델의 forward 계산 로직\n        x = self.layer1(input_ids.float())\n        x = self.batch_norm(x)\n        x = self.relu(x)\n        x = self.layer2(x)\n\n        return x\n\n\n# 모델 및 토크나이저 불러오기\nmodel_name = 'klue/roberta-large'\n#model = AutoModelForSequenceClassification.from_pretrained(model_name)   # gpu부족으로 제한\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ninput_size = 512\nhidden_size = 128\noutput_size = 2\n\nmodel = MyModel(input_size, hidden_size, output_size)"
  },
  {
    "objectID": "dev_posts/DL정리.html#입력-데이터셋-정리",
    "href": "dev_posts/DL정리.html#입력-데이터셋-정리",
    "title": "딥러닝 코드 정리",
    "section": "2) 입력 데이터셋 정리",
    "text": "2) 입력 데이터셋 정리\n\n512 차원으로 padding 진행\nbatch size = 16\n\n\n# 데이터셋 정의\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = self.data.iloc[idx]['조문']\n        label = torch.tensor(self.data.iloc[idx]['사무판단'], dtype=torch.long)\n        tokenized_data = tokenizer(text, padding='max_length', max_length=512, truncation=True, return_tensors='pt')\n        return {'input_ids': tokenized_data['input_ids'].squeeze(),\n                'attention_mask': tokenized_data['attention_mask'].squeeze(),\n                'labels': label}\n\n\n# 각 배치의 텍스트 길이를 맞추기\ndef collate_fn(batch):\n    input_ids = [item['input_ids'] for item in batch]\n    attention_mask = [item['attention_mask'] for item in batch]\n    labels = [item['labels'] for item in batch]\n\n    # 패딩\n    input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n    attention_mask = torch.nn.utils.rnn.pad_sequence(attention_mask, batch_first=True, padding_value=0)\n\n    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': torch.stack(labels)}\n\n\n# 데이터로더 생성\nbatch_size = 16  # 배치크기 조절\n\ntrain_dataset = CustomDataset(train_df, tokenizer)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n\nval_dataset = CustomDataset(val_df, tokenizer)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n\n\nval_dataset\n\n&lt;__main__.CustomDataset at 0x2ca5ee6b0&gt;\n\n\n\n# 모델을 GPU로 이동  -&gt; 작은 신경망이라 cpu로 돌림\n#model.to(device)"
  },
  {
    "objectID": "dev_posts/DL정리.html#튜닝-파라미터-지정",
    "href": "dev_posts/DL정리.html#튜닝-파라미터-지정",
    "title": "딥러닝 코드 정리",
    "section": "3) 튜닝 파라미터 지정",
    "text": "3) 튜닝 파라미터 지정\n\noptimizer: Adam\nlearning rate: 1e-5\n\n\n# 나머지 파라미터 정리\noptimizer = AdamW(model.parameters(), lr=1e-5)\nnum_epochs = 5\ntotal_steps = len(train_loader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n\n/Users/ihongju/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn("
  },
  {
    "objectID": "dev_posts/DL정리.html#모델-학습",
    "href": "dev_posts/DL정리.html#모델-학습",
    "title": "딥러닝 코드 정리",
    "section": "4) 모델 학습",
    "text": "4) 모델 학습\n\n# 손실 기록을 위한 리스트\ntrain_losses = []\nval_losses = []\n\n\nfrom sklearn.metrics import recall_score\n\n# 클래스 0에 대한 적절한 가중치를 계산 (imbalance data 고려)\nclass_0_weight = 0.06\nclass_1_weight = 1.0\n\nclass_weights = [class_0_weight, class_1_weight]    # 0, 1의 가중치를 차등 부여\n\n# 학습 루프에서 'labels'를 사용하는 부분 수정\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0.0\n    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} - Training'):\n        inputs = {key: value.to(device) for key, value in batch.items() if key != 'labels'}\n        labels = batch['labels'].to(device)\n\n        # 모델에 토큰화된 입력 데이터 전달\n        logits = model(**inputs)\n        if logits.dtype != torch.float32:\n            logits = logits.float()\n        loss = torch.nn.functional.cross_entropy(logits, labels, weight=torch.Tensor(class_weights).to(device))\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n        total_loss += loss.item()\n\n    avg_train_loss = total_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n    print(f'Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {avg_train_loss}')\n\n    model.eval()\n    val_loss = 0.0\n    y_true = []  # 실제 레이블을 저장할 리스트\n    y_pred = []  # 모델의 예측 결과를 저장할 리스트\n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=f'Epoch {epoch + 1}/{num_epochs} - Validation'):\n            inputs = {key: value.to(device) for key, value in batch.items() if key != 'labels'}\n            labels = batch['labels'].to(device)\n\n            # 모델에 토큰화된 입력 데이터 전달\n            outputs = model(**inputs)\n            if outputs.dtype != torch.float32:\n                outputs = outputs.float()\n\n            _, predictions = torch.max(outputs, 1)\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(predictions.cpu().numpy())\n            val_loss += torch.nn.functional.cross_entropy(outputs, labels, weight=torch.Tensor(class_weights).to(device))\n\n    avg_val_loss = val_loss / len(val_loader)\n    val_losses.append(avg_val_loss)\n    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {avg_val_loss}')\n    # Calculate Recall\n    recall = recall_score(y_true, y_pred, average='weighted')  # 'weighted'는 각 클래스의 샘플 수에 따라 가중 평균을 계산합니다.\n    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Recall: {recall}')\n\nEpoch 1/5 - Training: 100%|██████████████| 43081/43081 [03:14&lt;00:00, 221.63it/s]\nEpoch 1/5 - Validation: 100%|████████████| 10771/10771 [00:40&lt;00:00, 264.66it/s]\nEpoch 2/5 - Training: 100%|██████████████| 43081/43081 [03:13&lt;00:00, 222.08it/s]\nEpoch 2/5 - Validation: 100%|████████████| 10771/10771 [00:40&lt;00:00, 268.15it/s]\nEpoch 3/5 - Training: 100%|██████████████| 43081/43081 [03:11&lt;00:00, 224.61it/s]\nEpoch 3/5 - Validation: 100%|████████████| 10771/10771 [00:40&lt;00:00, 264.87it/s]\nEpoch 4/5 - Training: 100%|██████████████| 43081/43081 [03:12&lt;00:00, 223.36it/s]\nEpoch 4/5 - Validation: 100%|████████████| 10771/10771 [00:41&lt;00:00, 257.78it/s]\nEpoch 5/5 - Training: 100%|██████████████| 43081/43081 [03:12&lt;00:00, 223.52it/s]\nEpoch 5/5 - Validation: 100%|████████████| 10771/10771 [00:40&lt;00:00, 266.81it/s]\n\n\nEpoch 1/5, Average Training Loss: 0.5239665991301568\nEpoch 1/5, Validation Loss: 0.4939045310020447\nEpoch 1/5, Validation Recall: 0.7724125924851298\nEpoch 2/5, Average Training Loss: 0.4985668318130958\nEpoch 2/5, Validation Loss: 0.48241615295410156\nEpoch 2/5, Validation Recall: 0.7729754823734223\nEpoch 3/5, Average Training Loss: 0.4890418174231894\nEpoch 3/5, Validation Loss: 0.4739820957183838\nEpoch 3/5, Validation Recall: 0.7625475119686639\nEpoch 4/5, Average Training Loss: 0.4844063688010349\nEpoch 4/5, Validation Loss: 0.47453540563583374\nEpoch 4/5, Validation Recall: 0.7842100681851153\nEpoch 5/5, Average Training Loss: 0.48282361713480765\nEpoch 5/5, Validation Loss: 0.46963998675346375\nEpoch 5/5, Validation Recall: 0.7725982881183809"
  },
  {
    "objectID": "dev_posts/DL정리.html#loss-그래프",
    "href": "dev_posts/DL정리.html#loss-그래프",
    "title": "딥러닝 코드 정리",
    "section": "1) loss 그래프",
    "text": "1) loss 그래프\n\n# 손실 값 시각화\nplt.plot(train_losses, label='Training Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "dev_posts/DL정리.html#결과-확인",
    "href": "dev_posts/DL정리.html#결과-확인",
    "title": "딥러닝 코드 정리",
    "section": "1) 결과 확인",
    "text": "1) 결과 확인\n\nprob = [sublist[1] for sublist in all_probs]\n\n\n# 결과 데이터프레임 생성\nresult_df = pd.DataFrame({\n    'True_Labels': all_labels,\n    'Predictions': all_preds,\n    'Probability_1': prob\n})\n\nresult_df\n\n\n\n\n\n\n\n\nTrue_Labels\nPredictions\nProbability_1\n\n\n\n\n0\n0\n0\n0.026727\n\n\n1\n0\n0\n0.097768\n\n\n2\n0\n0\n0.036723\n\n\n3\n0\n0\n0.353132\n\n\n4\n0\n1\n0.520629\n\n\n...\n...\n...\n...\n\n\n172320\n0\n0\n0.008365\n\n\n172321\n0\n1\n0.508366\n\n\n172322\n0\n0\n0.012416\n\n\n172323\n1\n1\n0.578635\n\n\n172324\n0\n1\n0.726729\n\n\n\n\n172325 rows × 3 columns\n\n\n\n\n#result_df.to_csv('epo5_result_df.csv')   # 결과 저장\n\n\n#torch.save(model.state_dict(), \"model_06_1_5.pth\")    # 모델 저장"
  },
  {
    "objectID": "dev_posts/DL정리.html#결과-통계량-확인",
    "href": "dev_posts/DL정리.html#결과-통계량-확인",
    "title": "딥러닝 코드 정리",
    "section": "2) 결과 통계량 확인",
    "text": "2) 결과 통계량 확인\n\nresult_df.loc[result_df['Predictions']==0, ].describe()\n\n\n\n\n\n\n\n\nTrue_Labels\nPredictions\nProbability_1\n\n\n\n\ncount\n127067.000000\n127067.0\n127067.000000\n\n\nmean\n0.023350\n0.0\n0.152123\n\n\nstd\n0.151013\n0.0\n0.154932\n\n\nmin\n0.000000\n0.0\n0.002187\n\n\n25%\n0.000000\n0.0\n0.023082\n\n\n50%\n0.000000\n0.0\n0.070822\n\n\n75%\n0.000000\n0.0\n0.275795\n\n\nmax\n1.000000\n0.0\n0.499992\n\n\n\n\n\n\n\n\nresult_df.loc[result_df['Predictions']==1, ].describe()\n\n\n\n\n\n\n\n\nTrue_Labels\nPredictions\nProbability_1\n\n\n\n\ncount\n45258.000000\n45258.0\n45258.000000\n\n\nmean\n0.199700\n1.0\n0.653751\n\n\nstd\n0.399779\n0.0\n0.096457\n\n\nmin\n0.000000\n1.0\n0.500006\n\n\n25%\n0.000000\n1.0\n0.573960\n\n\n50%\n0.000000\n1.0\n0.645236\n\n\n75%\n0.000000\n1.0\n0.723073\n\n\nmax\n1.000000\n1.0\n0.965777"
  },
  {
    "objectID": "dev_posts/DL정리.html#roc-커브-확인",
    "href": "dev_posts/DL정리.html#roc-커브-확인",
    "title": "딥러닝 코드 정리",
    "section": "3) ROC 커브 확인",
    "text": "3) ROC 커브 확인\n\nfrom sklearn.metrics import roc_curve, auc\n\nfpr, tpr, thresholds = roc_curve(result_df['True_Labels'], result_df['Probability_1'])\nroc_auc = auc(fpr, tpr)\n\n# ROC 커브 그리기\nplt.figure(figsize=(8, 8))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc='lower right')\nplt.show()\n\n\n\n\n\n디폴트 threshold 기준 평가 지표 확인\n\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n\n# confusion matrix, accuracy, precision, recall, f1-score 계산\nconf_matrix = confusion_matrix(all_labels, all_preds)\naccuracy = accuracy_score(all_labels, all_preds)\nprecision = precision_score(all_labels, all_preds)\nrecall = recall_score(all_labels, all_preds)\nf1 = f1_score(all_labels, all_preds)\n\n# 디폴트 결과 출력\nprint(f\"Avg Validation Loss: {avg_val_loss}\")\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Precision: {precision}\")\nprint(f\"Recall: {recall}\")\nprint(f\"F1-Score: {f1}\")\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\nAvg Validation Loss: 0.39846527576446533\nAccuracy: 0.7725982881183809\nPrecision: 0.1996995006407707\nRecall: 0.7528529779258643\nF1-Score: 0.31566631157990327\nConfusion Matrix:\n[[124100  36220]\n [  2967   9038]]\n\n\n\nimport seaborn as sns\n\n# seaborn을 사용하여 heatmap으로 confusion matrix 시각화\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])\nplt.title('Confusion Matrix Neural Network')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()"
  },
  {
    "objectID": "dev_posts/DL정리.html#threshold-조절",
    "href": "dev_posts/DL정리.html#threshold-조절",
    "title": "딥러닝 코드 정리",
    "section": "4) threshold 조절",
    "text": "4) threshold 조절\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n\ndef cal_result(preds, y):\n    conf_matrix = confusion_matrix(y, preds)\n    accuracy = accuracy_score(y, preds)\n    precision = precision_score(y, preds)\n    recall = recall_score(y, preds)\n    f1 = f1_score(y, preds)\n    \n    return accuracy, recall\n\n\nx = np.arange(0.15, 0.29, 0.01).tolist()\ny_acc = []\ny_rec = []\n\nfor i in x:\n    threshold = i\n    result_df['new_predictions'] = 0\n    result_df.loc[result_df['Probability_1']&gt;threshold, 'new_predictions'] = 1\n    acc, rec = cal_result(result_df['new_predictions'], result_df['True_Labels'])\n    y_acc.append(acc)\n    y_rec.append(rec)\n\n\nthreshold에 따른 accuracy, recall 그래프 확인\n\n\nimport matplotlib.pyplot as plt\n\n# accuracy 그래프\nplt.plot(x, y_acc, label='accuracy', color='blue')\n\n# recall 그래프\nplt.plot(x, y_rec, label='recall', color='red')\n\n# 그래프에 제목과 축 레이블 추가\nplt.title('Result Line Graph')\nplt.xlabel('Threshold')\nplt.ylabel('Value')\n\n# 범례 추가\nplt.legend()\n\n# 그래프 표시\nplt.show()\n\n\n\n\n\nprint(f\"accuracy 최대값: {y_acc[-1]}, 최소값: {y_acc[0]}\")\nprint(f\"recall 최소값: {y_rec[-1]}, 최대값: {y_rec[0]}\")\n\naccuracy 최대값: 0.6184186856230959, 최소값: 0.5187291455099377\nrecall 최소값: 0.9450229071220325, 최대값: 0.9790920449812578\n\n\n\nprediction 중위수, 3분위수에 따른 결과 모두 출력\n\n\ndef cal_result2(preds, y):\n    conf_matrix = confusion_matrix(y, preds)\n    accuracy = accuracy_score(y, preds)\n    precision = precision_score(y, preds)\n    recall = recall_score(y, preds)\n    f1 = f1_score(y, preds)\n    \n    # 결과 출력\n    print(f\"Avg Validation Loss: {avg_val_loss}\")\n    print(f\"Accuracy: {accuracy}\")\n    print(f\"Precision: {precision}\")\n    print(f\"Recall: {recall}\")\n    print(f\"F1-Score: {f1}\")\n    print(\"Confusion Matrix:\")\n    print(conf_matrix)\n    \n    return conf_matrix\n\n# prediction 중위수\nprint('======threshold = 0.16======')\nthreshold = 0.16\nresult_df['new_predictions'] = 0\nresult_df.loc[result_df['Probability_1']&gt;threshold, 'new_predictions'] = 1\na = cal_result2(result_df['new_predictions'], result_df['True_Labels'])\n\n# prediction 3분위수\nprint('======threshold = 0.28======')\nthreshold = 0.28\nresult_df['new_predictions'] = 0\nresult_df.loc[result_df['Probability_1']&gt;threshold, 'new_predictions'] = 1\nb = cal_result2(result_df['new_predictions'], result_df['True_Labels'])\n\n======threshold = 0.16======\nAvg Validation Loss: 0.39846527576446533\nAccuracy: 0.5263890903815465\nPrecision: 0.1260341678306651\nRecall: 0.9770928779675135\nF1-Score: 0.22326909350463958\nConfusion Matrix:\n[[78980 81340]\n [  275 11730]]\n======threshold = 0.28======\nAvg Validation Loss: 0.39846527576446533\nAccuracy: 0.6184186856230959\nPrecision: 0.14841511754163342\nRecall: 0.9450229071220325\nF1-Score: 0.25654071410804336\nConfusion Matrix:\n[[95224 65096]\n [  660 11345]]\n\n\n\n# seaborn을 사용하여 heatmap으로 confusion matrix 시각화\nplt.figure(figsize=(8, 6))\nsns.heatmap(a, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])\nplt.title('Confusion Matrix Neural Network (0.16)')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(b, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])\nplt.title('Confusion Matrix Neural Network (0.28)')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()"
  },
  {
    "objectID": "dev_posts/앙상블.html",
    "href": "dev_posts/앙상블.html",
    "title": "앙상블 코드 정리",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "dev_posts/앙상블.html#accuracy-recall-11-비율-최적의-threshold-확인",
    "href": "dev_posts/앙상블.html#accuracy-recall-11-비율-최적의-threshold-확인",
    "title": "앙상블 코드 정리",
    "section": "accuracy, recall 1:1 비율 최적의 threshold 확인",
    "text": "accuracy, recall 1:1 비율 최적의 threshold 확인\n\nrf_result = np.sum([rf_y_acc, rf_y_rec], axis=0)\ndeep_result = np.sum([deep_y_acc, deep_y_rec], axis=0)\nlgbm_result = np.sum([lgbm_y_acc, lgbm_y_rec], axis=0)\navg_result = np.sum([avg_y_acc, avg_y_rec], axis=0)\n\nprint(\"====== accuracy, recall 1:1 비율 최적의 threshold =========\")\nprint(\"위치: \",np.argmax(rf_result), np.argmax(deep_result), np.argmax(lgbm_result), np.argmax(avg_result))\nprint(\"임계치값: \", x[2], x[36], x[5], x[25])\nprint(\"최대값: \", rf_result[2], deep_result[36], lgbm_result[5], avg_result[25])\n\n====== accuracy, recall 1:1 비율 최적의 threshold =========\n위치:  2 36 5 25\n임계치값:  0.03 0.37 0.06 0.26\n최대값:  1.6958764956789065 1.5833042533356156 1.71489993923297 1.7053350552169104\n\n\n\nprint('====== rf threshold = 0.03======')\nthreshold = 0.03\nresult['predict'] = 0\nresult.loc[result['rf']&gt;threshold, 'predict'] = 1\na = cal_result2(result['predict'], result['True_Labels'])\n\nprint('====== deep threshold = 0.37======')\nthreshold = 0.37\nresult['predict'] = 0\nresult.loc[result['deep']&gt;threshold, 'predict'] = 1\nb = cal_result2(result['predict'], result['True_Labels'])\n\nprint('====== lgbm threshold = 0.06======')\nthreshold = 0.06\nresult['predict'] = 0\nresult.loc[result['lgbm']&gt;threshold, 'predict'] = 1\nb = cal_result2(result['predict'], result['True_Labels'])\n\nprint('====== avg threshold = 0.02======')\nthreshold = 0.26\nresult['predict'] = 0\nresult.loc[result['avg']&gt;threshold, 'predict'] = 1\nb = cal_result2(result['predict'], result['True_Labels'])\n\n====== rf threshold = 0.03======\nAccuracy: 0.8054141883069781\nPrecision: 0.24914349639918895\nRecall: 0.8904623073719283\nF1-Score: 0.38935023310023315\nConfusion Matrix:\n[[128103  32217]\n [  1315  10690]]\n====== deep threshold = 0.37======\nAccuracy: 0.6770985057304512\nPrecision: 0.16635319662981482\nRecall: 0.9062057476051645\nF1-Score: 0.28110384744580247\nConfusion Matrix:\n[[105802  54518]\n [  1126  10879]]\n====== lgbm threshold = 0.06======\nAccuracy: 0.8288524590163935\nPrecision: 0.2744182446726175\nRecall: 0.8860474802165764\nF1-Score: 0.4190517462130912\nConfusion Matrix:\n[[132195  28125]\n [  1368  10637]]\n====== avg threshold = 0.02======\nAccuracy: 0.8637690410561439\nPrecision: 0.3189380307478612\nRecall: 0.8415660141607664\nF1-Score: 0.46257039512842824\nConfusion Matrix:\n[[138746  21574]\n [  1902  10103]]"
  },
  {
    "objectID": "dev_posts/앙상블.html#accuracy-recall-12-비율-최적의-threshold-확인",
    "href": "dev_posts/앙상블.html#accuracy-recall-12-비율-최적의-threshold-확인",
    "title": "앙상블 코드 정리",
    "section": "accuracy, recall 1:2 비율 최적의 threshold 확인",
    "text": "accuracy, recall 1:2 비율 최적의 threshold 확인\n\nrf_result2 = np.sum([rf_y_acc, np.array(rf_y_rec)*2], axis=0)\ndeep_result2 = np.sum([deep_y_acc, np.array(deep_y_rec)*2], axis=0)\nlgbm_result2 = np.sum([lgbm_y_acc, np.array(lgbm_y_rec)*2], axis=0)\navg_result2 = np.sum([avg_y_acc, np.array(avg_y_rec)*2], axis=0)\n\nprint(\"====== accuracy, recall 1:2 비율 최적의 threshold =========\")\nprint(\"위치: \",np.argmax(rf_result2), np.argmax(deep_result2), np.argmax(lgbm_result2), np.argmax(avg_result2))\nprint(\"임계치값: \", x[0], x[30], x[2], x[16])\nprint(\"최대값: \", rf_result2[0], deep_result2[30], lgbm_result2[2], avg_result2[16])\n\n====== accuracy, recall 1:2 비율 최적의 threshold =========\n위치:  0 30 2 16\n임계치값:  0.01 0.31 0.03 0.17\n최대값:  2.6070843662328667 2.5091515969124765 2.6338171296076704 2.61807193711842\n\n\n\nprint('====== rf threshold = 0.01======')\nthreshold = 0.01\nresult['predict'] = 0\nresult.loc[result['rf']&gt;threshold, 'predict'] = 1\na = cal_result2(result['predict'], result['True_Labels'])\n\nprint('====== deep threshold = 0.31======')\nthreshold = 0.31\nresult['predict'] = 0\nresult.loc[result['deep']&gt;threshold, 'predict'] = 1\nb = cal_result2(result['predict'], result['True_Labels'])\n\nprint('====== lgbm threshold = 0.03======')\nthreshold = 0.03\nresult['predict'] = 0\nresult.loc[result['lgbm']&gt;threshold, 'predict'] = 1\nb = cal_result2(result['predict'], result['True_Labels'])\n\nprint('====== avg threshold = 0.17======')\nthreshold = 0.17\nresult['predict'] = 0\nresult.loc[result['avg']&gt;threshold, 'predict'] = 1\nb = cal_result2(result['predict'], result['True_Labels'])\n\n====== rf threshold = 0.01======\nAccuracy: 0.7551893225010881\nPrecision: 0.21208074178654557\nRecall: 0.9259475218658892\nF1-Score: 0.3451155714928825\nConfusion Matrix:\n[[119022  41298]\n [   889  11116]]\n====== deep threshold = 0.31======\nAccuracy: 0.6359321050340926\nPrecision: 0.15356250256074078\nRecall: 0.936609745939192\nF1-Score: 0.2638631403562293\nConfusion Matrix:\n[[98343 61977]\n [  761 11244]]\n====== lgbm threshold = 0.03======\nAccuracy: 0.7514347889162919\nPrecision: 0.21148482976772043\nRecall: 0.9411911703456893\nF1-Score: 0.34536618168480254\nConfusion Matrix:\n[[118192  42128]\n [   706  11299]]\n====== avg threshold = 0.17======\nAccuracy: 0.7223618163354127\nPrecision: 0.19419082888202469\nRecall: 0.9478550603915036\nF1-Score: 0.32234214328205996\nConfusion Matrix:\n[[113102  47218]\n [   626  11379]]"
  },
  {
    "objectID": "dev_posts/DeepLearning.html",
    "href": "dev_posts/DeepLearning.html",
    "title": "딥러닝 코드 정리",
    "section": "",
    "text": "# from google.colab import drive\n# drive.mount('/content/drive')\n# cd /content/drive/MyDrive/Colab Notebooks/법령프로젝트\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm"
  },
  {
    "objectID": "dev_posts/DeepLearning.html#조문-사무판단-추출",
    "href": "dev_posts/DeepLearning.html#조문-사무판단-추출",
    "title": "딥러닝 코드 정리",
    "section": "1) [조문, 사무판단] 추출",
    "text": "1) [조문, 사무판단] 추출\n\nsub_df = df.loc[df['사무판단']!=2, [\"조문\", \"사무판단\"]]\nsub_df\n\n\n\n\n\n\n\n\n조문\n사무판단\n\n\n\n\n0\n제1장 총칙\n0\n\n\n1\n제1조(목적) 이 법은 개인정보의 처리 및 보호에 관한 사항을 정함으로써 개인의 자...\n0\n\n\n2\n제2조(정의) 이 법에서 사용하는 용어의 뜻은 다음과 같다. &lt;개정 2014.3.2...\n0\n\n\n3\n1. \"개인정보\"란 살아 있는 개인에 관한 정보로서 다음 각 목의 어느 하나에 해당...\n0\n\n\n4\n1의2. \"가명처리\"란 개인정보의 일부를 삭제하거나 일부 또는 전부를 대체하는 등의...\n0\n\n\n...\n...\n...\n\n\n861616\n1. 한국수자원공사\n0\n\n\n861617\n2. 법 제56조에 따른 한국상하수도협회\n0\n\n\n861618\n제32조(규제의 재검토) 환경부장관은 다음 각 호의 사항에 대하여 다음 각 호의 기...\n0\n\n\n861619\n1. 제23조의2제1항ㆍ제4항 및 별표 7의2에 따른 저수조청소업의 인력ㆍ시설 및 ...\n0\n\n\n861620\n2. 제31조 및 별표 8에 따른 기술진단 대행 기관의 장비와 기술인력: 2014년...\n0\n\n\n\n\n861621 rows × 2 columns\n\n\n\n\n#sub_df.to_csv('sub_df.csv')      # 임시 저장"
  },
  {
    "objectID": "dev_posts/DeepLearning.html#모델-정의",
    "href": "dev_posts/DeepLearning.html#모델-정의",
    "title": "딥러닝 코드 정리",
    "section": "1) 모델 정의",
    "text": "1) 모델 정의\n\nimport torch.nn as nn\n\nclass MyModel(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(MyModel, self).__init__()\n        self.layer1 = nn.Linear(input_size, hidden_size)\n        self.batch_norm = nn.BatchNorm1d(hidden_size)  \n        self.relu = nn.ReLU()\n        self.layer2 = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        # 모델의 forward 계산 로직\n        x = self.layer1(input_ids.float())\n        x = self.batch_norm(x)\n        x = self.relu(x)\n        x = self.layer2(x)\n\n        return x\n\n\n# 모델 및 토크나이저 불러오기\nmodel_name = 'klue/roberta-large'\n#model = AutoModelForSequenceClassification.from_pretrained(model_name)   # gpu부족으로 제한\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ninput_size = 512\nhidden_size = 128\noutput_size = 2\n\nmodel = MyModel(input_size, hidden_size, output_size)"
  },
  {
    "objectID": "dev_posts/DeepLearning.html#입력-데이터셋-정리",
    "href": "dev_posts/DeepLearning.html#입력-데이터셋-정리",
    "title": "딥러닝 코드 정리",
    "section": "2) 입력 데이터셋 정리",
    "text": "2) 입력 데이터셋 정리\n\n512 차원으로 padding 진행\nbatch size = 16\n\n\n# 데이터셋 정의\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = self.data.iloc[idx]['조문']\n        label = torch.tensor(self.data.iloc[idx]['사무판단'], dtype=torch.long)\n        tokenized_data = tokenizer(text, padding='max_length', max_length=512, truncation=True, return_tensors='pt')\n        return {'input_ids': tokenized_data['input_ids'].squeeze(),\n                'attention_mask': tokenized_data['attention_mask'].squeeze(),\n                'labels': label}\n\n\n# 각 배치의 텍스트 길이를 맞추기\ndef collate_fn(batch):\n    input_ids = [item['input_ids'] for item in batch]\n    attention_mask = [item['attention_mask'] for item in batch]\n    labels = [item['labels'] for item in batch]\n\n    # 패딩\n    input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n    attention_mask = torch.nn.utils.rnn.pad_sequence(attention_mask, batch_first=True, padding_value=0)\n\n    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': torch.stack(labels)}\n\n\n# 데이터로더 생성\nbatch_size = 16  # 배치크기 조절\n\ntrain_dataset = CustomDataset(train_df, tokenizer)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n\nval_dataset = CustomDataset(val_df, tokenizer)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n\n\nval_dataset\n\n&lt;__main__.CustomDataset at 0x2ca5ee6b0&gt;\n\n\n\n# 모델을 GPU로 이동  -&gt; 작은 신경망이라 cpu로 돌림\n#model.to(device)"
  },
  {
    "objectID": "dev_posts/DeepLearning.html#튜닝-파라미터-지정",
    "href": "dev_posts/DeepLearning.html#튜닝-파라미터-지정",
    "title": "딥러닝 코드 정리",
    "section": "3) 튜닝 파라미터 지정",
    "text": "3) 튜닝 파라미터 지정\n\noptimizer: Adam\nlearning rate: 1e-5\n\n\n# 나머지 파라미터 정리\noptimizer = AdamW(model.parameters(), lr=1e-5)\nnum_epochs = 5\ntotal_steps = len(train_loader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n\n/Users/ihongju/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn("
  },
  {
    "objectID": "dev_posts/DeepLearning.html#모델-학습",
    "href": "dev_posts/DeepLearning.html#모델-학습",
    "title": "딥러닝 코드 정리",
    "section": "4) 모델 학습",
    "text": "4) 모델 학습\n\n# 손실 기록을 위한 리스트\ntrain_losses = []\nval_losses = []\n\n\nfrom sklearn.metrics import recall_score\n\n# 클래스 0에 대한 적절한 가중치를 계산 (imbalance data 고려)\nclass_0_weight = 0.06\nclass_1_weight = 1.0\n\nclass_weights = [class_0_weight, class_1_weight]    # 0, 1의 가중치를 차등 부여\n\n# 학습 루프에서 'labels'를 사용하는 부분 수정\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0.0\n    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} - Training'):\n        inputs = {key: value.to(device) for key, value in batch.items() if key != 'labels'}\n        labels = batch['labels'].to(device)\n\n        # 모델에 토큰화된 입력 데이터 전달\n        logits = model(**inputs)\n        if logits.dtype != torch.float32:\n            logits = logits.float()\n        loss = torch.nn.functional.cross_entropy(logits, labels, weight=torch.Tensor(class_weights).to(device))\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n        total_loss += loss.item()\n\n    avg_train_loss = total_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n    print(f'Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {avg_train_loss}')\n\n    model.eval()\n    val_loss = 0.0\n    y_true = []  # 실제 레이블을 저장할 리스트\n    y_pred = []  # 모델의 예측 결과를 저장할 리스트\n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=f'Epoch {epoch + 1}/{num_epochs} - Validation'):\n            inputs = {key: value.to(device) for key, value in batch.items() if key != 'labels'}\n            labels = batch['labels'].to(device)\n\n            # 모델에 토큰화된 입력 데이터 전달\n            outputs = model(**inputs)\n            if outputs.dtype != torch.float32:\n                outputs = outputs.float()\n\n            _, predictions = torch.max(outputs, 1)\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(predictions.cpu().numpy())\n            val_loss += torch.nn.functional.cross_entropy(outputs, labels, weight=torch.Tensor(class_weights).to(device))\n\n    avg_val_loss = val_loss / len(val_loader)\n    val_losses.append(avg_val_loss)\n    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {avg_val_loss}')\n    # Calculate Recall\n    recall = recall_score(y_true, y_pred, average='weighted')  # 'weighted'는 각 클래스의 샘플 수에 따라 가중 평균을 계산합니다.\n    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Recall: {recall}')\n\nEpoch 1/5 - Training: 100%|██████████████| 43081/43081 [03:14&lt;00:00, 221.63it/s]\nEpoch 1/5 - Validation: 100%|████████████| 10771/10771 [00:40&lt;00:00, 264.66it/s]\nEpoch 2/5 - Training: 100%|██████████████| 43081/43081 [03:13&lt;00:00, 222.08it/s]\nEpoch 2/5 - Validation: 100%|████████████| 10771/10771 [00:40&lt;00:00, 268.15it/s]\nEpoch 3/5 - Training: 100%|██████████████| 43081/43081 [03:11&lt;00:00, 224.61it/s]\nEpoch 3/5 - Validation: 100%|████████████| 10771/10771 [00:40&lt;00:00, 264.87it/s]\nEpoch 4/5 - Training: 100%|██████████████| 43081/43081 [03:12&lt;00:00, 223.36it/s]\nEpoch 4/5 - Validation: 100%|████████████| 10771/10771 [00:41&lt;00:00, 257.78it/s]\nEpoch 5/5 - Training: 100%|██████████████| 43081/43081 [03:12&lt;00:00, 223.52it/s]\nEpoch 5/5 - Validation: 100%|████████████| 10771/10771 [00:40&lt;00:00, 266.81it/s]\n\n\nEpoch 1/5, Average Training Loss: 0.5239665991301568\nEpoch 1/5, Validation Loss: 0.4939045310020447\nEpoch 1/5, Validation Recall: 0.7724125924851298\nEpoch 2/5, Average Training Loss: 0.4985668318130958\nEpoch 2/5, Validation Loss: 0.48241615295410156\nEpoch 2/5, Validation Recall: 0.7729754823734223\nEpoch 3/5, Average Training Loss: 0.4890418174231894\nEpoch 3/5, Validation Loss: 0.4739820957183838\nEpoch 3/5, Validation Recall: 0.7625475119686639\nEpoch 4/5, Average Training Loss: 0.4844063688010349\nEpoch 4/5, Validation Loss: 0.47453540563583374\nEpoch 4/5, Validation Recall: 0.7842100681851153\nEpoch 5/5, Average Training Loss: 0.48282361713480765\nEpoch 5/5, Validation Loss: 0.46963998675346375\nEpoch 5/5, Validation Recall: 0.7725982881183809"
  },
  {
    "objectID": "dev_posts/DeepLearning.html#loss-그래프",
    "href": "dev_posts/DeepLearning.html#loss-그래프",
    "title": "딥러닝 코드 정리",
    "section": "1) loss 그래프",
    "text": "1) loss 그래프\n\n# 손실 값 시각화\nplt.plot(train_losses, label='Training Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "dev_posts/DeepLearning.html#결과-확인",
    "href": "dev_posts/DeepLearning.html#결과-확인",
    "title": "딥러닝 코드 정리",
    "section": "1) 결과 확인",
    "text": "1) 결과 확인\n\nprob = [sublist[1] for sublist in all_probs]\n\n\n# 결과 데이터프레임 생성\nresult_df = pd.DataFrame({\n    'True_Labels': all_labels,\n    'Predictions': all_preds,\n    'Probability_1': prob\n})\n\nresult_df\n\n\n\n\n\n\n\n\nTrue_Labels\nPredictions\nProbability_1\n\n\n\n\n0\n0\n0\n0.026727\n\n\n1\n0\n0\n0.097768\n\n\n2\n0\n0\n0.036723\n\n\n3\n0\n0\n0.353132\n\n\n4\n0\n1\n0.520629\n\n\n...\n...\n...\n...\n\n\n172320\n0\n0\n0.008365\n\n\n172321\n0\n1\n0.508366\n\n\n172322\n0\n0\n0.012416\n\n\n172323\n1\n1\n0.578635\n\n\n172324\n0\n1\n0.726729\n\n\n\n\n172325 rows × 3 columns\n\n\n\n\n#result_df.to_csv('epo5_result_df.csv')   # 결과 저장\n\n\n#torch.save(model.state_dict(), \"model_06_1_5.pth\")    # 모델 저장"
  },
  {
    "objectID": "dev_posts/DeepLearning.html#결과-통계량-확인",
    "href": "dev_posts/DeepLearning.html#결과-통계량-확인",
    "title": "딥러닝 코드 정리",
    "section": "2) 결과 통계량 확인",
    "text": "2) 결과 통계량 확인\n\nresult_df.loc[result_df['Predictions']==0, ].describe()\n\n\n\n\n\n\n\n\nTrue_Labels\nPredictions\nProbability_1\n\n\n\n\ncount\n127067.000000\n127067.0\n127067.000000\n\n\nmean\n0.023350\n0.0\n0.152123\n\n\nstd\n0.151013\n0.0\n0.154932\n\n\nmin\n0.000000\n0.0\n0.002187\n\n\n25%\n0.000000\n0.0\n0.023082\n\n\n50%\n0.000000\n0.0\n0.070822\n\n\n75%\n0.000000\n0.0\n0.275795\n\n\nmax\n1.000000\n0.0\n0.499992\n\n\n\n\n\n\n\n\nresult_df.loc[result_df['Predictions']==1, ].describe()\n\n\n\n\n\n\n\n\nTrue_Labels\nPredictions\nProbability_1\n\n\n\n\ncount\n45258.000000\n45258.0\n45258.000000\n\n\nmean\n0.199700\n1.0\n0.653751\n\n\nstd\n0.399779\n0.0\n0.096457\n\n\nmin\n0.000000\n1.0\n0.500006\n\n\n25%\n0.000000\n1.0\n0.573960\n\n\n50%\n0.000000\n1.0\n0.645236\n\n\n75%\n0.000000\n1.0\n0.723073\n\n\nmax\n1.000000\n1.0\n0.965777"
  },
  {
    "objectID": "dev_posts/DeepLearning.html#roc-커브-확인",
    "href": "dev_posts/DeepLearning.html#roc-커브-확인",
    "title": "딥러닝 코드 정리",
    "section": "3) ROC 커브 확인",
    "text": "3) ROC 커브 확인\n\nfrom sklearn.metrics import roc_curve, auc\n\nfpr, tpr, thresholds = roc_curve(result_df['True_Labels'], result_df['Probability_1'])\nroc_auc = auc(fpr, tpr)\n\n# ROC 커브 그리기\nplt.figure(figsize=(8, 8))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc='lower right')\nplt.show()\n\n\n\n\n\n디폴트 threshold 기준 평가 지표 확인\n\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n\n# confusion matrix, accuracy, precision, recall, f1-score 계산\nconf_matrix = confusion_matrix(all_labels, all_preds)\naccuracy = accuracy_score(all_labels, all_preds)\nprecision = precision_score(all_labels, all_preds)\nrecall = recall_score(all_labels, all_preds)\nf1 = f1_score(all_labels, all_preds)\n\n# 디폴트 결과 출력\nprint(f\"Avg Validation Loss: {avg_val_loss}\")\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Precision: {precision}\")\nprint(f\"Recall: {recall}\")\nprint(f\"F1-Score: {f1}\")\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\nAvg Validation Loss: 0.39846527576446533\nAccuracy: 0.7725982881183809\nPrecision: 0.1996995006407707\nRecall: 0.7528529779258643\nF1-Score: 0.31566631157990327\nConfusion Matrix:\n[[124100  36220]\n [  2967   9038]]\n\n\n\nimport seaborn as sns\n\n# seaborn을 사용하여 heatmap으로 confusion matrix 시각화\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])\nplt.title('Confusion Matrix Neural Network')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()"
  },
  {
    "objectID": "dev_posts/DeepLearning.html#threshold-조절",
    "href": "dev_posts/DeepLearning.html#threshold-조절",
    "title": "딥러닝 코드 정리",
    "section": "4) threshold 조절",
    "text": "4) threshold 조절\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n\ndef cal_result(preds, y):\n    conf_matrix = confusion_matrix(y, preds)\n    accuracy = accuracy_score(y, preds)\n    precision = precision_score(y, preds)\n    recall = recall_score(y, preds)\n    f1 = f1_score(y, preds)\n    \n    return accuracy, recall\n\n\nx = np.arange(0.15, 0.29, 0.01).tolist()\ny_acc = []\ny_rec = []\n\nfor i in x:\n    threshold = i\n    result_df['new_predictions'] = 0\n    result_df.loc[result_df['Probability_1']&gt;threshold, 'new_predictions'] = 1\n    acc, rec = cal_result(result_df['new_predictions'], result_df['True_Labels'])\n    y_acc.append(acc)\n    y_rec.append(rec)\n\n\nthreshold에 따른 accuracy, recall 그래프 확인\n\n\nimport matplotlib.pyplot as plt\n\n# accuracy 그래프\nplt.plot(x, y_acc, label='accuracy', color='blue')\n\n# recall 그래프\nplt.plot(x, y_rec, label='recall', color='red')\n\n# 그래프에 제목과 축 레이블 추가\nplt.title('Result Line Graph')\nplt.xlabel('Threshold')\nplt.ylabel('Value')\n\n# 범례 추가\nplt.legend()\n\n# 그래프 표시\nplt.show()\n\n\n\n\n\nprint(f\"accuracy 최대값: {y_acc[-1]}, 최소값: {y_acc[0]}\")\nprint(f\"recall 최소값: {y_rec[-1]}, 최대값: {y_rec[0]}\")\n\naccuracy 최대값: 0.6184186856230959, 최소값: 0.5187291455099377\nrecall 최소값: 0.9450229071220325, 최대값: 0.9790920449812578\n\n\n\nprediction 중위수, 3분위수에 따른 결과 모두 출력\n\n\ndef cal_result2(preds, y):\n    conf_matrix = confusion_matrix(y, preds)\n    accuracy = accuracy_score(y, preds)\n    precision = precision_score(y, preds)\n    recall = recall_score(y, preds)\n    f1 = f1_score(y, preds)\n    \n    # 결과 출력\n    print(f\"Avg Validation Loss: {avg_val_loss}\")\n    print(f\"Accuracy: {accuracy}\")\n    print(f\"Precision: {precision}\")\n    print(f\"Recall: {recall}\")\n    print(f\"F1-Score: {f1}\")\n    print(\"Confusion Matrix:\")\n    print(conf_matrix)\n    \n    return conf_matrix\n\n# prediction 중위수\nprint('======threshold = 0.16======')\nthreshold = 0.16\nresult_df['new_predictions'] = 0\nresult_df.loc[result_df['Probability_1']&gt;threshold, 'new_predictions'] = 1\na = cal_result2(result_df['new_predictions'], result_df['True_Labels'])\n\n# prediction 3분위수\nprint('======threshold = 0.28======')\nthreshold = 0.28\nresult_df['new_predictions'] = 0\nresult_df.loc[result_df['Probability_1']&gt;threshold, 'new_predictions'] = 1\nb = cal_result2(result_df['new_predictions'], result_df['True_Labels'])\n\n======threshold = 0.16======\nAvg Validation Loss: 0.39846527576446533\nAccuracy: 0.5263890903815465\nPrecision: 0.1260341678306651\nRecall: 0.9770928779675135\nF1-Score: 0.22326909350463958\nConfusion Matrix:\n[[78980 81340]\n [  275 11730]]\n======threshold = 0.28======\nAvg Validation Loss: 0.39846527576446533\nAccuracy: 0.6184186856230959\nPrecision: 0.14841511754163342\nRecall: 0.9450229071220325\nF1-Score: 0.25654071410804336\nConfusion Matrix:\n[[95224 65096]\n [  660 11345]]\n\n\n\n# seaborn을 사용하여 heatmap으로 confusion matrix 시각화\nplt.figure(figsize=(8, 6))\nsns.heatmap(a, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])\nplt.title('Confusion Matrix Neural Network (0.16)')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(b, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])\nplt.title('Confusion Matrix Neural Network (0.28)')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()"
  },
  {
    "objectID": "dev_posts/Ensemble.html",
    "href": "dev_posts/Ensemble.html",
    "title": "앙상블 코드 정리",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "dev_posts/Ensemble.html#accuracy-recall-11-비율-최적의-threshold-확인",
    "href": "dev_posts/Ensemble.html#accuracy-recall-11-비율-최적의-threshold-확인",
    "title": "앙상블 코드 정리",
    "section": "accuracy, recall 1:1 비율 최적의 threshold 확인",
    "text": "accuracy, recall 1:1 비율 최적의 threshold 확인\n\nrf_result = np.sum([rf_y_acc, rf_y_rec], axis=0)\ndeep_result = np.sum([deep_y_acc, deep_y_rec], axis=0)\nlgbm_result = np.sum([lgbm_y_acc, lgbm_y_rec], axis=0)\navg_result = np.sum([avg_y_acc, avg_y_rec], axis=0)\n\nprint(\"====== accuracy, recall 1:1 비율 최적의 threshold =========\")\nprint(\"위치: \",np.argmax(rf_result), np.argmax(deep_result), np.argmax(lgbm_result), np.argmax(avg_result))\nprint(\"임계치값: \", x[2], x[36], x[5], x[25])\nprint(\"최대값: \", rf_result[2], deep_result[36], lgbm_result[5], avg_result[25])\n\n====== accuracy, recall 1:1 비율 최적의 threshold =========\n위치:  2 36 5 25\n임계치값:  0.03 0.37 0.06 0.26\n최대값:  1.6958764956789065 1.5833042533356156 1.71489993923297 1.7053350552169104\n\n\n\nprint('====== rf threshold = 0.03======')\nthreshold = 0.03\nresult['predict'] = 0\nresult.loc[result['rf']&gt;threshold, 'predict'] = 1\na = cal_result2(result['predict'], result['True_Labels'])\n\nprint('====== deep threshold = 0.37======')\nthreshold = 0.37\nresult['predict'] = 0\nresult.loc[result['deep']&gt;threshold, 'predict'] = 1\nb = cal_result2(result['predict'], result['True_Labels'])\n\nprint('====== lgbm threshold = 0.06======')\nthreshold = 0.06\nresult['predict'] = 0\nresult.loc[result['lgbm']&gt;threshold, 'predict'] = 1\nb = cal_result2(result['predict'], result['True_Labels'])\n\nprint('====== avg threshold = 0.02======')\nthreshold = 0.26\nresult['predict'] = 0\nresult.loc[result['avg']&gt;threshold, 'predict'] = 1\nb = cal_result2(result['predict'], result['True_Labels'])\n\n====== rf threshold = 0.03======\nAccuracy: 0.8054141883069781\nPrecision: 0.24914349639918895\nRecall: 0.8904623073719283\nF1-Score: 0.38935023310023315\nConfusion Matrix:\n[[128103  32217]\n [  1315  10690]]\n====== deep threshold = 0.37======\nAccuracy: 0.6770985057304512\nPrecision: 0.16635319662981482\nRecall: 0.9062057476051645\nF1-Score: 0.28110384744580247\nConfusion Matrix:\n[[105802  54518]\n [  1126  10879]]\n====== lgbm threshold = 0.06======\nAccuracy: 0.8288524590163935\nPrecision: 0.2744182446726175\nRecall: 0.8860474802165764\nF1-Score: 0.4190517462130912\nConfusion Matrix:\n[[132195  28125]\n [  1368  10637]]\n====== avg threshold = 0.02======\nAccuracy: 0.8637690410561439\nPrecision: 0.3189380307478612\nRecall: 0.8415660141607664\nF1-Score: 0.46257039512842824\nConfusion Matrix:\n[[138746  21574]\n [  1902  10103]]"
  },
  {
    "objectID": "dev_posts/Ensemble.html#accuracy-recall-12-비율-최적의-threshold-확인",
    "href": "dev_posts/Ensemble.html#accuracy-recall-12-비율-최적의-threshold-확인",
    "title": "앙상블 코드 정리",
    "section": "accuracy, recall 1:2 비율 최적의 threshold 확인",
    "text": "accuracy, recall 1:2 비율 최적의 threshold 확인\n\nrf_result2 = np.sum([rf_y_acc, np.array(rf_y_rec)*2], axis=0)\ndeep_result2 = np.sum([deep_y_acc, np.array(deep_y_rec)*2], axis=0)\nlgbm_result2 = np.sum([lgbm_y_acc, np.array(lgbm_y_rec)*2], axis=0)\navg_result2 = np.sum([avg_y_acc, np.array(avg_y_rec)*2], axis=0)\n\nprint(\"====== accuracy, recall 1:2 비율 최적의 threshold =========\")\nprint(\"위치: \",np.argmax(rf_result2), np.argmax(deep_result2), np.argmax(lgbm_result2), np.argmax(avg_result2))\nprint(\"임계치값: \", x[0], x[30], x[2], x[16])\nprint(\"최대값: \", rf_result2[0], deep_result2[30], lgbm_result2[2], avg_result2[16])\n\n====== accuracy, recall 1:2 비율 최적의 threshold =========\n위치:  0 30 2 16\n임계치값:  0.01 0.31 0.03 0.17\n최대값:  2.6070843662328667 2.5091515969124765 2.6338171296076704 2.61807193711842\n\n\n\nprint('====== rf threshold = 0.01======')\nthreshold = 0.01\nresult['predict'] = 0\nresult.loc[result['rf']&gt;threshold, 'predict'] = 1\na = cal_result2(result['predict'], result['True_Labels'])\n\nprint('====== deep threshold = 0.31======')\nthreshold = 0.31\nresult['predict'] = 0\nresult.loc[result['deep']&gt;threshold, 'predict'] = 1\nb = cal_result2(result['predict'], result['True_Labels'])\n\nprint('====== lgbm threshold = 0.03======')\nthreshold = 0.03\nresult['predict'] = 0\nresult.loc[result['lgbm']&gt;threshold, 'predict'] = 1\nb = cal_result2(result['predict'], result['True_Labels'])\n\nprint('====== avg threshold = 0.17======')\nthreshold = 0.17\nresult['predict'] = 0\nresult.loc[result['avg']&gt;threshold, 'predict'] = 1\nb = cal_result2(result['predict'], result['True_Labels'])\n\n====== rf threshold = 0.01======\nAccuracy: 0.7551893225010881\nPrecision: 0.21208074178654557\nRecall: 0.9259475218658892\nF1-Score: 0.3451155714928825\nConfusion Matrix:\n[[119022  41298]\n [   889  11116]]\n====== deep threshold = 0.31======\nAccuracy: 0.6359321050340926\nPrecision: 0.15356250256074078\nRecall: 0.936609745939192\nF1-Score: 0.2638631403562293\nConfusion Matrix:\n[[98343 61977]\n [  761 11244]]\n====== lgbm threshold = 0.03======\nAccuracy: 0.7514347889162919\nPrecision: 0.21148482976772043\nRecall: 0.9411911703456893\nF1-Score: 0.34536618168480254\nConfusion Matrix:\n[[118192  42128]\n [   706  11299]]\n====== avg threshold = 0.17======\nAccuracy: 0.7223618163354127\nPrecision: 0.19419082888202469\nRecall: 0.9478550603915036\nF1-Score: 0.32234214328205996\nConfusion Matrix:\n[[113102  47218]\n [   626  11379]]"
  },
  {
    "objectID": "dev_posts/subject.html",
    "href": "dev_posts/subject.html",
    "title": "’조문’에서 수행주체 출력",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport re\nfrom tqdm import tqdm\nimport pickle\ntqdm.pandas()"
  },
  {
    "objectID": "dev_posts/subject.html#수행주체를-list로-저장한-subject_list.pkl-로드",
    "href": "dev_posts/subject.html#수행주체를-list로-저장한-subject_list.pkl-로드",
    "title": "’조문’에서 수행주체 출력",
    "section": "1. 수행주체를 list로 저장한 subject_list.pkl 로드",
    "text": "1. 수행주체를 list로 저장한 subject_list.pkl 로드\n\nwith open(\"subject_list.pkl\",\"rb\") as f:\n    subject_list = pickle.load(f)\n\n\nsubject_list[:50]\n\n['대도시',\n '2023 순천만국제정원박람회조직위원회',\n '5·18민주화운동 진상규명조사위원회',\n '계약담당자',\n '대검찰청',\n '대한민국법인',\n '가석방심사위원회',\n '가정보호사건조사관',\n '가정위탁지원센터',\n '가축방역기관장',\n '가축병성감정실시기관',\n '가축전염병피해보상협의회',\n '기관',\n '본부',\n '부대',\n '학교',\n '장관',\n '간사',\n '갈등관리심의위원회',\n '감독기관',\n '감독청',\n '감사',\n '감사관',\n '감사원',\n '감사위원회',\n '감사활동을 수행하는 사람',\n '감염병관리위원회',\n '감염병병원체 확인기관',\n '감정평가법인',\n '감항인증심의위원회',\n '개발센터',\n '개발원',\n '갱생보호회지소장',\n '거래소',\n '거주자',\n '건강보험공단',\n '건강보험분쟁조정위원회',\n '건강보험심사평가원',\n '건설기계사업자설립협회',\n '건설사업자',\n '건설엔지니어링사업자',\n '건설청',\n '건축위원회',\n '건축주',\n '건축허가관청',\n '검사',\n '검사공무원',\n '검사위원회',\n '검역기관',\n '검역본부']\n\n\n\ndf = pd.read_csv('BaseTable4.csv')\n\n/var/folders/sy/5dw5r1ys5fdb3h0gbq8x0g6m0000gn/T/ipykernel_67754/4038033726.py:1: DtypeWarning: Columns (4,5,18,19,24) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv('BaseTable4.csv')"
  },
  {
    "objectID": "dev_posts/subject.html#basetable4의-조문에서-수행주체-뽑아내기",
    "href": "dev_posts/subject.html#basetable4의-조문에서-수행주체-뽑아내기",
    "title": "’조문’에서 수행주체 출력",
    "section": "2. ’BaseTable4’의 ’조문’에서 수행주체 뽑아내기",
    "text": "2. ’BaseTable4’의 ’조문’에서 수행주체 뽑아내기\n\n# \"조문\"이 결측치인 행 제거\ndf['조문'] = df['조문'].apply(lambda x: '' if pd.isna(x) else str(x))\n\n\n# 수행주체 앞에 붙을 수 있는 단어\nprefixes = ['각 목의', '각급', '각군', '각부', '각종', '관계', '관할', '소관', '소속', '해당']\n\n# 수행주체 뒤에 붙을 수 있는 단어\nsuffixes = ['의 장', '장', '의 위원장', '총장', '장관', '위원장', '이 아닌 자', '이사장', '의장',\n            '시장', '회장', '의 의장', '의 본부장', '의 원장', '회장', '등의 장']\n\n# \"수행주체 앞에 붙을 수 있는 단어 + 수행주체 + 수행주체 뒤에 붙을 수 있는 단어\" 미리 붙여서 후보 만들어놓기\ncompiled_patterns = []\nfor subject in subject_list:\n    pattern_list = [re.escape(prefix) + r\"\\s*\" + re.escape(subject) + r\"\\s*\" for prefix in prefixes]\n    pattern_list += [re.escape(subject) + r\"\\s*\" + re.escape(suffix) + r\"\\s*\" for suffix in suffixes]\n    pattern_list.append(re.escape(subject))\n    compiled_patterns += [re.compile(pattern) for pattern in pattern_list]\n\ndef find_subjects_in_text(text):\n    subjects_found = set()\n\n    for pattern in compiled_patterns:\n        match = pattern.search(text)\n        if match:\n            found_subject = ' '.join(match.group().split())  # 공백 정규화\n            subjects_found.add(found_subject)\n\n    # 더 긴 주체가 포함하는 짧은 주체 제거\n    for subject1 in list(subjects_found):\n        for subject2 in list(subjects_found):\n            if subject1 != subject2 and subject1 in subject2:\n                subjects_found.discard(subject1)\n\n    return ', '.join(subjects_found)\n\n# 'new_수행주체' 열 생성\ndf['new_수행주체'] = df['조문'].progress_apply(find_subjects_in_text)\n\n100%|██████████| 861621/861621 [1:26:37&lt;00:00, 165.79it/s]\n\n\n\n# 수행주체 추가하여 basetable 생성\ndf.to_csv('BaseTable4_new_수행주체추가.csv')"
  },
  {
    "objectID": "dev_posts/subject.html#basetable4_new_수행주체추가.csv-살펴보기",
    "href": "dev_posts/subject.html#basetable4_new_수행주체추가.csv-살펴보기",
    "title": "’조문’에서 수행주체 출력",
    "section": "3. BaseTable4_new_수행주체추가.csv 살펴보기",
    "text": "3. BaseTable4_new_수행주체추가.csv 살펴보기\n\ndf_add_subject = pd.read_csv('BaseTable4_new_수행주체추가.csv')\n\n/var/folders/sy/5dw5r1ys5fdb3h0gbq8x0g6m0000gn/T/ipykernel_84304/2884985943.py:1: DtypeWarning: Columns (5,6,19,20,25) have mixed types. Specify dtype option on import or set low_memory=False.\n  df_add_subject = pd.read_csv('BaseTable4_new_수행주체추가.csv')\n\n\n\ndf_add_subject[(df_add_subject['new_수행주체'].notnull()) & (df_add_subject['수행주체'].notnull())][['조문', '수행주체', 'new_수행주체']]\n\n\n\n\n\n\n\n\n조문\n수행주체\nnew_수행주체\n\n\n\n\n35\n① 개인정보 보호에 관한 사무를 독립적으로 수행하기 위하여 국무총리 소속으로 개인정...\n국무총리\n국무총리, 보호위원회\n\n\n92\n① 보호위원회는 다음 각 호의 사항을 심의ㆍ의결한다.\n보호위원회\n보호위원회\n\n\n137\n① 중앙행정기관의 장은 소관 법령의 제정 또는 개정을 통하여 개인정보 처리를 수반하...\n중앙행정기관의 장\n중앙행정기관의 장, 보호위원회\n\n\n141\n① 보호위원회는 개인정보의 보호와 정보주체의 권익 보장을 위하여 3년마다 개인정보 ...\n보호위원회\n중앙행정기관의 장, 관계 중앙행정기관, 보호위원회\n\n\n152\n① 중앙행정기관의 장은 기본계획에 따라 매년 개인정보 보호를 위한 시행계획을 작성하...\n중앙행정기관의 장\n중앙행정기관의 장, 보호위원회\n\n\n...\n...\n...\n...\n\n\n860705\n⑤제1항부터 제4항까지의 규정에 따른 과태료는 대통령령으로 정하는 바에 따라 환경부...\n환경부장관\n군수, 시장, 구청장, 환경부장관, 대통령, 시ㆍ도지사\n\n\n860754\n① 환경부장관은 제11조에 따라 상수원보호구역을 지정하거나 변경하려는 경우에는 주민...\n환경부장관\n환경부장관\n\n\n861016\n④위탁심의위원회의 위원은 다음 각 호의 자 중에서 일반수도사업자가 위촉한다. 이 경...\n일반수도사업자(지방자치단체 등)\n일반수도사업자, 심의위원회\n\n\n861208\n①환경부장관은 협회의 업무를 감독한다.\n환경부장관\n협회, 환경부장관\n\n\n861214\n①환경부장관은 정수장의 안전관리체제를 확립하기 위하여 정수장의 운영 및 시설관리상태...\n환경부장관\n환경부장관, 관리\n\n\n\n\n59270 rows × 3 columns\n\n\n\n\n# '수행주체'열과 조문에서 출력한 'new_수행주체'열 비교\npd.crosstab(df_add_subject['수행주체'].notnull(), df_add_subject['new_수행주체'].notnull())\n\n\n\n\n\n\n\nnew_수행주체\nFalse\nTrue\n\n\n수행주체\n\n\n\n\n\n\nFalse\n410651\n390904\n\n\nTrue\n796\n59270\n\n\n\n\n\n\n\n[결과 분석]  - 원 데이터에서는 ‘수행주체’ 없는데, 위의 코드를 통해 ‘new_수행주체’ 출력된 행: 390904개  - 원 데이터에서는 ‘수행주체’ 있는데, 위의 코드를 통해 ‘new_수행주체’ 출력되지 않은 행: 796개  ⇨ 총 391,700개"
  },
  {
    "objectID": "dev_posts/1214_rulebase.html",
    "href": "dev_posts/1214_rulebase.html",
    "title": "Rule-Based Model",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport re\nfrom tqdm import tqdm\nimport pickle\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n\n# google drive mount\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive\n\n\n\ndf = pd.read_csv('/content/drive/MyDrive/KPMG 캡스톤/사무총조사/BaseTable4_중복제거_수행주체추가.csv')\n\nDtypeWarning: Columns (5,6,19,20,25) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv('/content/drive/MyDrive/KPMG 캡스톤/사무총조사/BaseTable4_중복제거_수행주체추가.csv')\n\n\n\nwith open(\"/content/drive/MyDrive/KPMG 캡스톤/사무총조사/수행주체/subject_list.pkl\",\"rb\") as f:\n    subject_list = pickle.load(f)\n\n\nBaseTable4_중복제거2.csv 만들기\n\nindex1 = df[(df['법령명'] == '석탄산업법 시행령') & (df['조번호'] == '42_2') & (df['항번호'] == 5)].index\nindex2 = df[(df['법령명'] == '석탄산업법 시행령') & (df['조번호'] == '42_2') & (df['항번호'] == 6)].index\n\ndf = df.drop(index1, axis = 0)\ndf = df.drop(index2, axis = 0)\n\n\n\nBaseTable4_중복제거2.csv로 rule_based 적용\n\ndef rule_based(df):\n  df['rule_based'] = 1\n\n  # 조문이 결측치인 행\n  df.loc[df['조문'].isnull(), 'rule_based'] = 0\n\n  # '^제.*\\)$' 표현 0으로\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'^제.*\\)$')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'제\\d+조$')), 'rule_based'] = 0\n\n  # '^제(\\d+)(장|절)' 표현 0으로\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'^제(\\d+)(장|절|편)')), 'rule_based'] = 0\n\n  # 조문제목 == '목적'|'정의' 0으로\n  df.loc[((df['조문제목'].notnull()) & ((df['조문제목'] == '목적') | (df['조문제목'] == '정의'))), 'rule_based'] = 0\n\n  # 삭제된 조문 0으로\n  df.loc[((df['조문'].str.contains(\"삭제 &lt;\"))|(df['조문'].str.contains(\"삭제&lt;\"))), 'rule_based'] = 0\n\n  # 조문이 '목적', '명칭'뿐인 것\n  df.loc[(df['조문'].notnull()) & ((df['조문'].str.match(r\"\\d+\\. 목적\")) | (df['조문'] == '목적')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & ((df['조문'].str.match(r\"\\d+\\. .*명칭\")) | (df['조문'] == '명칭')), 'rule_based'] = 0\n\n  # 조문에서 사무판단 무조건 0인 표현들\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'.*있는 경우$')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'.*없게 된 경우$')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'\\d+\\. .*거짓이나 그 밖의 부정한 방법으로 지정을 받은 경우')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'.*의사를 밝히는 경우')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'\\d+\\. .*인정되는 경우')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'.*친족이었던 경우')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'.*대리인이었던 경우')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'\\d+\\..*인증을 받은 경우')), 'rule_based'] = 0\n\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'.*후견인$')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'\\d+\\. .*소재지')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'\\d+\\. .*정관')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'\\d+\\. .*계획서')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'\\d+\\. .*서류')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'\\d+\\. .*상호$')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'\\d+\\. .*증명서')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'\\d+\\. .*경매')), 'rule_based'] = 0\n\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'\\d+\\. .*공고의 방법')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'\\d+\\. .*대통령령으로 정하는 사항')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'\\d+\\. .*되지 아니한 자')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'\\d+\\. .*그 밖에 필요한 사항')), 'rule_based'] = 0\n  df.loc[(df['조문'].notnull()) & (df['조문'].str.match(r'.*협회는 법인으로 한다')), 'rule_based'] = 0\n\n  return df\n\n\ntqdm.pandas()\n\n\ndf = rule_based(df)\n\n\nconf_matrix = confusion_matrix(df['사무판단'], df['rule_based'])\n\n# heatmap으로 confusion matrix를 시각화\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()"
  },
  {
    "objectID": "dev_posts/수민_사무유형구분_머신러닝.html",
    "href": "dev_posts/수민_사무유형구분_머신러닝.html",
    "title": "사무유형구분_Random Forest",
    "section": "",
    "text": "!sudo apt-get install -y fonts-nanum\n!sudo fc-cache -fv\n!rm ~/.cache/matplotlib -rf\n\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following NEW packages will be installed:\n  fonts-nanum\n0 upgraded, 1 newly installed, 0 to remove and 23 not upgraded.\nNeed to get 10.3 MB of archives.\nAfter this operation, 34.1 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\nFetched 10.3 MB in 1s (9,326 kB/s)\ndebconf: unable to initialize frontend: Dialog\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, &lt;&gt; line 1.)\ndebconf: falling back to frontend: Readline\ndebconf: unable to initialize frontend: Readline\ndebconf: (This frontend requires a controlling tty.)\ndebconf: falling back to frontend: Teletype\ndpkg-preconfigure: unable to re-open stdin: \nSelecting previously unselected package fonts-nanum.\n(Reading database ... 120903 files and directories currently installed.)\nPreparing to unpack .../fonts-nanum_20200506-1_all.deb ...\nUnpacking fonts-nanum (20200506-1) ...\nSetting up fonts-nanum (20200506-1) ...\nProcessing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n/root/.local/share/fonts: skipping, no such directory\n/root/.fonts: skipping, no such directory\n/usr/share/fonts/truetype: skipping, looped directory detected\n/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n/var/cache/fontconfig: cleaning cache directory\n/root/.cache/fontconfig: not cleaning non-existent cache directory\n/root/.fontconfig: not cleaning non-existent cache directory\nfc-cache: succeeded\n\n\n\nimport  matplotlib\nimport  matplotlib.font_manager  as fm\nimport  matplotlib.pyplot  as plt\n\n\nprint('◎ matplotlib version : ', matplotlib.__version__)\nprint()\n\n\nsys_font  = fm.findSystemFonts ( )\n\n[ font  for  font  in  sys_font  if  \"Nanum\"  in font ]\n\n◎ matplotlib version :  3.7.1\n\n\n\n['/usr/share/fonts/truetype/nanum/NanumSquareR.ttf',\n '/usr/share/fonts/truetype/nanum/NanumGothicCodingBold.ttf',\n '/usr/share/fonts/truetype/nanum/NanumSquareRoundB.ttf',\n '/usr/share/fonts/truetype/nanum/NanumMyeongjo.ttf',\n '/usr/share/fonts/truetype/nanum/NanumGothicCoding.ttf',\n '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf',\n '/usr/share/fonts/truetype/nanum/NanumSquareB.ttf',\n '/usr/share/fonts/truetype/nanum/NanumBarunGothicBold.ttf',\n '/usr/share/fonts/truetype/nanum/NanumMyeongjoBold.ttf',\n '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',\n '/usr/share/fonts/truetype/nanum/NanumSquareRoundR.ttf',\n '/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf']\n\n\n\nfe = fm.FontEntry(\n    fname=r'/usr/share/fonts/truetype/nanum/NanumGothic.ttf',\n    name='NanumGothic')\nfm.fontManager.ttflist.insert(0, fe)\nplt.rcParams.update({'font.size': 18, 'font.family': 'NanumGothic'})\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\nimport re\nfrom tqdm import tqdm\nimport pickle\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n\ndf = pd.read_csv('/content/drive/MyDrive/KPMG 캡스톤/사무총조사/filter_df.csv')\n\n\nwith open(\"/content/drive/MyDrive/KPMG 캡스톤/사무총조사/수행주체/subject_list.pkl\",\"rb\") as f:\n    subject_list = pickle.load(f)\n\n\n# df_1: 사무판단 == 1인 행들만 있는 dataframe\ndf_1 = df[df['사무판단'] == 1]\n\n\ndf_1['사무유형(대분류)'] = np.nan\n\nscale_n = ['국가직접처리사무', '특별지방행정기관사무', '국가위탁사무', '시도위임사무', '시군구위임사무', '시군구재위임사무', '시도및시군구위임사무']\nscale_p = ['국가-시도-시군구공동사무', '국가-시도공동사무', '국가-시군구공동사무']\nscale_r = ['시도직접처리사무', '시도위탁사무', '시군구직접처리사무', '시군구위탁사무', '시도-시군구공동사무', '시도-시군구위임사무']\n\nfor ii in range(len(df_1)):\n  minitask = str(df_1.iloc[ii,24])\n  if minitask == 'nan':\n    df_1.iloc[ii,28] = '0'\n  elif minitask in scale_n:\n    df_1.iloc[ii,28] = '국가'\n  elif minitask in scale_p:\n    df_1.iloc[ii,28] = '공동'\n  elif minitask in scale_r:\n    df_1.iloc[ii,28] = '지방'\n\n\n# '조문' string으로 바꾸기\n# df_1 속 '조문'이 결측치인 행 2개 존재\ndf_1['조문'] = df_1['조문'].apply(lambda x: '' if pd.isna(x) else str(x))\n\nSettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_1['조문'] = df_1['조문'].apply(lambda x: '' if pd.isna(x) else str(x))"
  },
  {
    "objectID": "dev_posts/수민_사무유형구분_머신러닝.html#라이브러리-및-데이터-불러오기",
    "href": "dev_posts/수민_사무유형구분_머신러닝.html#라이브러리-및-데이터-불러오기",
    "title": "사무유형구분_Random Forest",
    "section": "",
    "text": "!sudo apt-get install -y fonts-nanum\n!sudo fc-cache -fv\n!rm ~/.cache/matplotlib -rf\n\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following NEW packages will be installed:\n  fonts-nanum\n0 upgraded, 1 newly installed, 0 to remove and 23 not upgraded.\nNeed to get 10.3 MB of archives.\nAfter this operation, 34.1 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\nFetched 10.3 MB in 1s (9,326 kB/s)\ndebconf: unable to initialize frontend: Dialog\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, &lt;&gt; line 1.)\ndebconf: falling back to frontend: Readline\ndebconf: unable to initialize frontend: Readline\ndebconf: (This frontend requires a controlling tty.)\ndebconf: falling back to frontend: Teletype\ndpkg-preconfigure: unable to re-open stdin: \nSelecting previously unselected package fonts-nanum.\n(Reading database ... 120903 files and directories currently installed.)\nPreparing to unpack .../fonts-nanum_20200506-1_all.deb ...\nUnpacking fonts-nanum (20200506-1) ...\nSetting up fonts-nanum (20200506-1) ...\nProcessing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n/root/.local/share/fonts: skipping, no such directory\n/root/.fonts: skipping, no such directory\n/usr/share/fonts/truetype: skipping, looped directory detected\n/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n/var/cache/fontconfig: cleaning cache directory\n/root/.cache/fontconfig: not cleaning non-existent cache directory\n/root/.fontconfig: not cleaning non-existent cache directory\nfc-cache: succeeded\n\n\n\nimport  matplotlib\nimport  matplotlib.font_manager  as fm\nimport  matplotlib.pyplot  as plt\n\n\nprint('◎ matplotlib version : ', matplotlib.__version__)\nprint()\n\n\nsys_font  = fm.findSystemFonts ( )\n\n[ font  for  font  in  sys_font  if  \"Nanum\"  in font ]\n\n◎ matplotlib version :  3.7.1\n\n\n\n['/usr/share/fonts/truetype/nanum/NanumSquareR.ttf',\n '/usr/share/fonts/truetype/nanum/NanumGothicCodingBold.ttf',\n '/usr/share/fonts/truetype/nanum/NanumSquareRoundB.ttf',\n '/usr/share/fonts/truetype/nanum/NanumMyeongjo.ttf',\n '/usr/share/fonts/truetype/nanum/NanumGothicCoding.ttf',\n '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf',\n '/usr/share/fonts/truetype/nanum/NanumSquareB.ttf',\n '/usr/share/fonts/truetype/nanum/NanumBarunGothicBold.ttf',\n '/usr/share/fonts/truetype/nanum/NanumMyeongjoBold.ttf',\n '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',\n '/usr/share/fonts/truetype/nanum/NanumSquareRoundR.ttf',\n '/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf']\n\n\n\nfe = fm.FontEntry(\n    fname=r'/usr/share/fonts/truetype/nanum/NanumGothic.ttf',\n    name='NanumGothic')\nfm.fontManager.ttflist.insert(0, fe)\nplt.rcParams.update({'font.size': 18, 'font.family': 'NanumGothic'})\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\nimport re\nfrom tqdm import tqdm\nimport pickle\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n\ndf = pd.read_csv('/content/drive/MyDrive/KPMG 캡스톤/사무총조사/filter_df.csv')\n\n\nwith open(\"/content/drive/MyDrive/KPMG 캡스톤/사무총조사/수행주체/subject_list.pkl\",\"rb\") as f:\n    subject_list = pickle.load(f)\n\n\n# df_1: 사무판단 == 1인 행들만 있는 dataframe\ndf_1 = df[df['사무판단'] == 1]\n\n\ndf_1['사무유형(대분류)'] = np.nan\n\nscale_n = ['국가직접처리사무', '특별지방행정기관사무', '국가위탁사무', '시도위임사무', '시군구위임사무', '시군구재위임사무', '시도및시군구위임사무']\nscale_p = ['국가-시도-시군구공동사무', '국가-시도공동사무', '국가-시군구공동사무']\nscale_r = ['시도직접처리사무', '시도위탁사무', '시군구직접처리사무', '시군구위탁사무', '시도-시군구공동사무', '시도-시군구위임사무']\n\nfor ii in range(len(df_1)):\n  minitask = str(df_1.iloc[ii,24])\n  if minitask == 'nan':\n    df_1.iloc[ii,28] = '0'\n  elif minitask in scale_n:\n    df_1.iloc[ii,28] = '국가'\n  elif minitask in scale_p:\n    df_1.iloc[ii,28] = '공동'\n  elif minitask in scale_r:\n    df_1.iloc[ii,28] = '지방'\n\n\n# '조문' string으로 바꾸기\n# df_1 속 '조문'이 결측치인 행 2개 존재\ndf_1['조문'] = df_1['조문'].apply(lambda x: '' if pd.isna(x) else str(x))\n\nSettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_1['조문'] = df_1['조문'].apply(lambda x: '' if pd.isna(x) else str(x))"
  },
  {
    "objectID": "dev_posts/수민_사무유형구분_머신러닝.html#column들-생성",
    "href": "dev_posts/수민_사무유형구분_머신러닝.html#column들-생성",
    "title": "사무유형구분_Random Forest",
    "section": "1. column들 생성",
    "text": "1. column들 생성\n\n1st column 생성: 가장 많이 들어있는 수행주체 index 2~3개 추출\n\n수행주체_freq1: 가장 많이 들어있는 수행주체 index\n수행주체_freq2: 두 번째로 많이 들어있는 수행주체 index\n수행주체_freq3: 세 번째로 많이 들어있는 수행주체 index\n\n\ndf_1.columns\n\nIndex(['Unnamed: 0', '소관부처명', '법령명', '법령구분', '조번호', '항번호', '호번호', '조문제목', '조문',\n       '사무판단', '사무판단근거', '사무명', '수행주체', '사무유형', '위임사무판단', '위임근거규정', '수임기관',\n       '특행기관', '재위임사무판단', '재위임근거규정', '재수임기관', '위탁사무판단', '위탁근거규정', '수탁기관',\n       '사무유형(소분류)', '기타', '조문_명_동', 'new_수행주체', '사무유형(대분류)', '수행주체_freq1',\n       '수행주체_freq2', '수행주체_freq3', '수행주체_국가', '수행주체_지방', '수행주체_공동',\n       '수행주체_국가_교', '수행주체_지방_교', '수행주체_공동_교'],\n      dtype='object')\n\n\n\ndf_1['new_수행주체'] = df_1['new_수행주체'].apply(lambda x: '' if pd.isna(x) else str(x))\n\nword_vec = []\nfor item in df_1['new_수행주체']:\n    row_vec = [0] * len(subject_list)\n    for subject in subject_list:\n        count = item.count(subject)\n        if count &gt; 0:\n            index = subject_list.index(subject)\n            row_vec[index] += count\n    word_vec.append(row_vec)\n\nSettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_1['new_수행주체'] = df_1['new_수행주체'].apply(lambda x: '' if pd.isna(x) else str(x))\n\n\n\nword_vec = pd.DataFrame(word_vec)\n\n\ndef get_nlargest_index(row, n):\n    if row.nlargest(n).iloc[-1] == 0:\n        return np.nan\n    else:\n        return row.nlargest(n).index[-1]\n\n# 각 열에 대한 값을 계산하고 NaN 조건을 적용합니다.\ndf_1['수행주체_freq1'] = word_vec.apply(lambda row: np.nan if row.max() == 0 else row.idxmax(), axis=1)\ndf_1['수행주체_freq2'] = word_vec.apply(lambda row: get_nlargest_index(row, 2), axis=1)\ndf_1['수행주체_freq3'] = word_vec.apply(lambda row: get_nlargest_index(row, 3), axis=1)\n\nSettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_1['수행주체_freq1'] = word_vec.apply(lambda row: np.nan if row.max() == 0 else row.idxmax(), axis=1)\n&lt;ipython-input-10-6c8980145691&gt;:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_1['수행주체_freq2'] = word_vec.apply(lambda row: get_nlargest_index(row, 2), axis=1)\n&lt;ipython-input-10-6c8980145691&gt;:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_1['수행주체_freq3'] = word_vec.apply(lambda row: get_nlargest_index(row, 3), axis=1)\n\n\n\n# NaN값에는 그냥 2000 넣어줌, 자료형 int로 바꿔줌\n\ndf_1[['수행주체_freq1', '수행주체_freq2', '수행주체_freq3']] = df_1[['수행주체_freq1', '수행주체_freq2', '수행주체_freq3']].fillna(2000)\ndf_1 = df_1.astype({'수행주체_freq1': 'int', '수행주체_freq2': 'int', '수행주체_freq3': 'int'})\n\nSettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_1[['수행주체_freq1', '수행주체_freq2', '수행주체_freq3']] = df_1[['수행주체_freq1', '수행주체_freq2', '수행주체_freq3']].fillna(2000)\n\n\n\n\n2nd column 생성: ‘국가’, ‘지방’, ’공동’에 들어있는 수행주체 구분하기\n\n수행주체_국가: ’국가사무’에만 존재하는 수행주체가 ’조문’에서 언급된 횟수\n수행주체_지방: ’지방사무’에만 존재하는 수행주체가 ’조문’에서 언급된 횟수\n수행주체_공동: ’공동사무’에만 존재하는 수행주체가 ’조문’에서 언급된 횟수\n\n\n\n수행주체_국가_교: ’국가사무’에 존재하는 수행주체가 ’조문’에서 언급된 횟수\n수행주체_지방_교: ’지방사무’에 존재하는 수행주체가 ’조문’에서 언급된 횟수\n수행주체_공동_교: ’공동사무’에 존재하는 수행주체가 ’조문’에서 언급된 횟수\n\n\ndf_country = df_1[df_1['사무유형(대분류)'] == '국가']\ndf_province = df_1[df_1['사무유형(대분류)'] == '지방']\ndf_both = df_1[df_1['사무유형(대분류)'] == '공동']\n\n\n# 국가사무, 지방사무, 공동사무 각각의 조문에 언급된 수행주체 뽑아내기\n\n# 국가사무 '조문'에 들어있는 수행주체\nsubject_country = []\nfor subject in subject_list:\n  if df_country['조문'].str.contains(subject).any():\n    subject_country.append(subject)\n\n# 지방사무 '조문'에 들어있는 수행주체\nsubject_province = []\nfor subject in subject_list:\n  if df_province['조문'].str.contains(subject).any():\n    subject_province.append(subject)\n\n# 공동사무 '조문'에 들어있는 수행주체\nsubject_both = []\nfor subject in subject_list:\n  if df_both['조문'].str.contains(subject).any():\n    subject_both.append(subject)\n\n\nset_country = set(subject_country)\nset_province = set(subject_province)\nset_both = set(subject_both)\n\n# 국가, 지방, 공동사무 모두에 존재하는 수행주체\ncommon_elements = set_country.intersection(set_province).intersection(set_both)\n\n# 국가사무에만 존재하는 수행주체\nunique_country = set_country - set_province - set_both\n\n# 지방사무에만 존재하는 수행주체\nunique_province = set_province - set_country - set_both\n\n# 공동사무에만 존재하는 수행주체\nunique_both = set_both - set_country - set_province\n\n# 결과 출력\nprint('==================')\nprint(\"국가, 지방, 공동 모두 존재\")\nprint(\"주체:\", common_elements)\nprint(\"개수:\",len(common_elements))\nprint('==================')\nprint(\"국가사무에만 존재\")\nprint(\"주체:\", unique_country)\nprint(\"개수:\",len(unique_country))\nprint('==================')\nprint(\"지방사무에만 존재\")\nprint(\"주체:\", unique_province)\nprint(\"개수:\",len(unique_province))\nprint('==================')\nprint(\"공동사무에만 존재\")\nprint(\"주체:\", unique_both)\nprint(\"개수:\",len(unique_both))\nprint('==================')\n\n==================\n국가, 지방, 공동 모두 존재\n주체: {'기업체', '지방의회', '통계청', '특별시', '지방국세청', '행정관청', '청장', '산림조합중앙회', '소장', '자산관리공사', '신청인', '행정청', '실무위원회', '주무부처', '재단', '외국환은행', '정부', '사법경찰관', '하고자 하는 자', '물품관리관', '지방식품의약품안전청장', '식물검역기관', '추천위원회', '국장', '직업교육훈련기관', '지방환경청', '은행', '광역지방자치단체', '수산청', '보훈병원', '호의 기관', '중앙행정기관', '사범대학', '검역기관', '유치원', '국민안전처장관', '해양경찰청', '허가관청', '수면관리자', '공원관리청', '사업계획승인권자', '요구권자', '지방공기업', '관리권자', '국가기관', '대통령령으로 정하는 공공기관', '간사', '자치구', '감사', '노동부장관', '교육단체', '한국토지주택공사', '궤도사업자', '임용권자', '피해아동', '지역군사령관', '변호사', '소방청', '원자력안전위원회', '한국환경공단', '발주청', '특허청', '사업단', '법무부', '이전공공기관', '수익자', '재난관리책임기관', '관측기관', '자치구구청장', '학교', '지방토지수용위원회', '신고한 자', '도의회', '개발원', '신용카드업자', '보호기관', '중앙대책본부장', '통일부', '위원장', '대통령', '댐건설사업시행자', '군인', '금융기관', '지역자활센터', '처장', '시ㆍ군', '영사', '시행자', '하천관리청', '지방도로관리청', '한국보훈복지의료공단', '중앙회', '단체', '구조ㆍ구급대원', '공공단체', '국가유공자', '농림축산식품부', '시ㆍ군ㆍ자치구', '손실을 입은 자', '관장', '사업시행자', '진흥원', '국가기술표준원', '건강보험공단', '시·구', '심판원', '보장기관', '지방병무청', '관리', '법원', '납세의무자', '국무총리', '수사기관', '사업자', '연합체', '이사장', '공공하수도관리청', '이사회', '국립수산과학원', '검정기관', '정부출연연구기관', '경찰공무원', '교육장', '보건복지부장관', '근로복지공단', '직업안정기관의 장', '체육단체', '임대사업자', '법정대리인', '소방대', '부대', '일괄협의회', '건축위원회', '연구개발기관', '세관', '재외공관', '식물방제관', '의료기관', '시ㆍ도교육감', '농업ㆍ농촌및식품산업정책심의회', '공익법인', '기술원', '지방공단', '수립권자', '기술보증기금', '종합신용정보집중기관', '협회', '심의회', '사장', '시ㆍ도 가축방역기관', '특별자치도지사', '소방기관', '협의회', '중소벤처기업진흥공단', '읍장', '시ㆍ도', '토지주택공사', '경찰관', '분쟁조정위원회', '도지사', '보건의료기관', '관청', '아동복지시설', '교정시설', '군부대', '출자ㆍ출연 기관', '주무관청', '정신건강복지센터', '환경분쟁조정위원회', '병무청', '중소벤처기업부', '입안권자', '한국자산관리공사', '사업주체', '기금', '해양수산부', '시ㆍ도교육청', '철도운영자', '지역대책본부', '사령관', '지방대학', '공판장', '공무원', '기획재정부', '공사', '처분권자', '인사위원회', '공기업', '전문위원회', '시설관리자', '대통령령으로 정하는 자', '행정사법인', '연구원', '학교운영위원회', '국립대학', '식품의약품안전처', '산업대학', '승인관청', '군수', '특별자치도', '구호지원기관', '광주광역시', '하려는 자', '공단', '민방위 대장', '감사원', '국방부', '운영위원회', '함대사령관', '지정권자', '세종특별자치시', '중앙통제단장', '한국지역정보개발원', '국립학교', '면장', '신용보증기금', '국립농산물품질관리원', '가축방역기관장', '본부', '건설엔지니어링사업자', '시ㆍ도 교육청', '철도시설관리자', '시험연구기관', '연구기관', '중앙도시계획위원회', '경찰관서', '대도시', '도매시장 개설자', '행정안전부', '지방환경관서', '부처', '수습본부', '농촌진흥청', '총리', '감독기관', '수탁기관', '소유자', '사회복지법인', '세무공무원', '정책심의위원회', '국민건강보험공단', '세무서', '국민연금공단', '받은 자', '출납공무원', '장관', '국가균형발전위원회', '대학', '국세청', '지방고용노동관서', '센터', '지방도시계획위원회', '피해자', '보험회사', '허가권자', '사무소', '인증기관', '지방자치단체조합', '사립학교', '의장', '광역시', '소방관서', '교육행정기관', '읍·면', '체신관서', '공공보건의료기관', '설립자', '시ㆍ도경찰청', '지방해양수산청장', '문화체육관광부', '대법원', '이해관계인', '검찰청', '교육위원회', '지휘관', '평생교육시설', '교육부', '구청장', '등록관청', '실무위원', '중앙선거관리위원회', '원천징수의무자', '위원회', '초등학교', '지방자치단체', '지청', '대통령령으로 정하는 기관', '학교법인', '관리자', '중앙관서', '검역본부', '읍·면·동', '감정평가법인', '교육감', '산업단지지정권자', '특구 시ㆍ도지사', '영구기록물관리기관', '금융위원회', '한국은행', '교육지원청', '과학기술정보통신부', '전문대학', '교육기관', '민원실', '식물검역관', '금융위원', '심사위원회', '공공기관', '신고관청', '긴급구조기관', '관리주체', '지방공사', '국가', '유관기관', '경찰청', '지적소관청', '의료시설', '건설사업자', '구청', '기관', '질병관리청', '특별자치시ㆍ도', '검사', '시ㆍ도지사', '지방산림청', '한국농어촌공사', '문화재청', '발급기관', '산업통상자원부', '준정부기관', '지방분쟁조정위원회', '공정거래위원회', '위탁기관', '승인권자', '환경부', '지방검찰청', '읍ㆍ면ㆍ동', '중학교', '특별자치시', '행정협의회', '교육훈련기관', '시ㆍ도본부', '경찰서', '시ㆍ도 서비스원', '수납기관', '전문가', '외교부', '지방해양경찰청', '지방의회의 의장', '행정부', '판사', '정책위원회', '개발센터', '금융회사', '선거관리위원회', '유역환경청', '관리청', '소방대원', '세무서장', '발주자', '소재지', '지방교통위원회', '조달청', '거주자', '시ㆍ군ㆍ구', '국립가축방역기관', '사회보장위원회', '제주특별자치도', '검찰', '산림청', '경영자', '국립국제교육원', '육군', '일반수도사업자', '행정기관', '물류기업', '시·구·읍·면', '동장', '아동보호전문기관', '도로관리청', '배치기관', '수도사업자', '국회', '재무관', '사무처', '소위원회', '통제단장', '심의위원회', '이전기관', '시장', '소방서', '해양경찰서', '사법경찰관리', '진흥재단', '미술관', '테러대책협의회', '등록기관', '시·도지사', '읍ㆍ면', '보건소', '징계위원회', '소비자', '전라북도지사', '판매자', '지정행정기관의 장', '지원단', '시·군·구', '소관청', '시민고충처리위원회', '고용노동부', '제주자치도', '지하시설물관리자', '공인회계사회', '진흥공단', '도교육감', '박물관', '도시철도공사', '보장원', '지역통제단장', '자치구의 구청장', '교장', '지원센터', '한국수자원공사', '관리기관', '연합회', '통합심의위원회', '전담의료기관', '민방위대', '토지수용위원회', '시ㆍ도의 교육감', '국토교통부', '국립수목원', '등기소', '고등학교', '경찰', '입주자', '기록물관리기관', '업체', '서울특별시', '전문기관', '소방본부', '농업협동조합중앙회', '지원위원회', '정부기관', '주택건설등록업자', '원장', '여성가족부', '토양관련전문기관', '교육시설', '도서관', '연구회', '주무부장관'}\n개수: 452\n==================\n국가사무에만 존재\n주체: {'특별지방행정기관', '희귀질환지원센터', '자원봉사진흥위원회', '독학학위운영위원회', '외국세무자문사등록부', '조직은행', '농업재해보험심의회', '미합중국 주재 관할 총영사', '극장', '한국공정거래조정원', '야생동물검역기관', '수송관서', '국민건강증진정책심의위원회', '중앙방사능방재대책본부', '국민연금기금', '소년분류심사원', '제출대상법인', '수요기관', '국세예규심사위원회', '순천시', '지방우정청장', '중소기업유통센터', '인터넷주소관리기관', '온라인투자연계금융협회', '사립학교교직원연금공단', '복권위원회', '입영부대', '국립정신병원', '전자송달대행기관', '장기등이식윤리위원회', '자연경관심의위원회', '감염병관리위원회', '국가경찰위원회', '지방청장', '항공안전본부장', '발명기관', '예비군중대장', '혁신금융사업자', '재활시설운영심의위원회', '한국은행총재', '법교육위원회', '기술혁신 추진위원회', '국가시책사업심의회', '군무원', '군 책임운영기관운영위원회', '혁신금융심사위원회', '폐자원에너지센터', '친일반민족행위진상규명위원회', '출입국관리 공무원', '공공보건의료정책심의위원회', '비상장은행', '주 미합중국 대한민국 대사', '수도권정비위원회', '공급기관', '고등검찰청', '지방노동위원회', '국가정보자료관리협의회', '산업표준심의회', '지역지식재산센터', '청소년정책위원회', '합동성위원회', '수질오염방제센터', '청사관리기관의 장', '수입공무원', '대한민국법인', '해양경찰관서', '국가생물다양성센터', '수도권대기환경청', '국립종자원', '상공부', '첨단바이오의약품 심의위원회', '소형선박 등록관청', '세월호 선체조사위원', '한국교육개발원', '국무위원', '중앙방제대책본부', '차관보', '대통령기록물생산기관', '일자리위원회', '민주화운동관련자명예회복및보상심의위원회', '국가노후준비위원회', '국가기록관리위원회', '우편대체관서', '방첩기관', '임명권자', '심사원', '부문별관장기관의 장', '합참의장', '국립결핵병원', '광산안전위원회', '공공데이터제공책임관', '사행산업통합감독위원회', '지방교정청', '임금채권보장기금심의위원회', '대한공증인협회', '의료재활소년원', '책임경영지원센터', '말소된 등록을 회복하려는 자', '항만시설 소유자', '데이터기반행정 책임관', '주무장관', '유치지역지원위원회', '지방해양항만관청', '방송광고균형발전위원회', '등록공무원', '거래소', '한국보건의료연구원', '징벌위원회', '중장기전략위원회', '인증원', '조달품질원', '접경지세관', '등록공관', '출입항신고기관의 장', '영화진흥위원회', '해양항만관청', '국내대책위원회', '발송관서', '계정출납명령관', '기술진흥전문기관', '재외국민보호위원회', '국채사무처리기관', '군수사기관', '공적자금관리위원회', '중앙암등록본부', '국ㆍ공립의 박물관', '판매기관의 장', '파산참가기관', '전용실시권자', '우수품질인증을 받은 자', '협동조합정책심의위원회', '조직기증지원기관', '검찰부', '다문화가족정책위원회', '전문교육훈련기관', '녹색건축센터', '신고업무 수탁기관', '법령안 주관기관', '출입국관리사무소장', '항공운송사업자', '실무회의', '교육ㆍ사회 및 문화 관계장관회의', '군사망사고진상규명위원회', '공공측량시행자', '군교정시설', '심사대행기관', '특허심판원', '국가인권위원회', '기술정보진흥원', '대통령기록관', '국가통계위원', '첨단재생의료', '적립금운용심의회', '국가암관리위원회', '합동참모본부', '경제관계장관회의', '자활복지개발원장', '운항시각조정기관', '군사법원', '한국토지주택공사사장', '전력정책심의회', '예탁신청자', '중앙구조본부', '징발관', '대통령기록관리전문위원회', '도로관리권자', '한국은행 총재', '국가경찰관서', '장애인정책조정위원회', '도시ㆍ군관리계획의 결정권자', '디엔에이신원확인정보담당자', '소비자분쟁조정위원회', '이의신청심의위원회', '과거사연구재단', '국회 정보위원회', '기술전문위원회', '해양경찰관', '남북교류협력 추진협의회', '발령권자', '중앙수산조정위원회', '호송관', '자살유발정보예방협의회', '해상구조조정본부', '디자인등록출원인', '순국선열ㆍ애국지사사업기금 및 보훈기금운용심의회', '5·18민주화운동 진상규명조사위원회', '국가위원회', '증권선물위원회', '기금운용심의회', '국립해양조사원', '외국인정책위원회', '스마트도시협회', '양성평등교육심의회', '국가지식재산위원회', '수소경제위원회', '국립과학수사연구원', '재산관리관', '대통령기록물생산기관의 기록관', '긴급재정관리단체', '사업재편계획심의위원회', '국방정보화책임관협의회', '소년원', '우편관서', '다목의 기관의 장', '수출지원센터', '국가생명윤리심의위원회', '우정사업정보센터', '특수기록관', '대외경제장관회의', '한국원자력안전기술원의 장', '주민등록사무감독기관', '어업재해보험심의회', '한국승강기안전공단', '경찰교육기관', '징계권자의 차상급 부대 또는 기관', '금융투자상품거래청산회사', '본부심의회', '한국환경산업기술원', '검찰관', '의약품관리종합정보센터', '감항인증심의위원회', '검찰인사위원회', '고용보험위원회', '화물터미널운영자', '통상조약 국내대책위원회', '정부대표', '벤처기업확인기관', '신용평가회사', '시험실시권자', '경찰병원', '자치분권위원회', '경호처', '상장은행지주회사', '진상조사위원회', '한의약육성발전심의위원회', '국가물관리위원', '자동차보험정비협의회', '토지비축위원회', '국립소록도병원', '초고층 건축물등의 관리주체', '보훈기금운용심의회', '국가교육회의', '농약안전성심의위원회', '국립통일교육원', '신용정보협회', '경쟁력위원회', '물품사용공무원', '한강홍수통제소장', '금융보안원', '방위사업감독관', '국방과학연구소', '국립환경과학원', '수용기관', '공적연금연계협의체', '대한변호사협회', '지방법원판사', '금융복합기업집단', '무역위원회', '해병대사령부', '공공외교위원회', '선사용자금출납명령관', '전문수사자문위원', '지하정보관리기관의 장', '감사관', '석면피해구제심사위원회', '재결청', '사면심사위원회', '계엄사령관', '군보건의료기관', '자살예방정책위원회', '처리과의 장', '전문은행', '품질인정기관', '국가안전보장회의', '한국독립운동사연구소', '발급권한기관', '한국급경사지안전협회', '소방기장', '지역방송발전위원회', '한국수출입은행장', '세월호 선체조사위원회', '국가안보실', '취업지원실시기관', '국가치매관리위원회', '기금재수탁자', '중소기업자단체', '물류관련 전문기관', '책임운영기관운영심의회', '학교도서관진흥위원회', '농지보전부담금체납정리심의회', '시ㆍ도 협동조합정책협의회', '국가핵융합위원회', '휴면보험금등관리위원회', '국가평생교육진흥원', '출입국자', '지방항공청장', '납세자보호위원회', '한국원자력의학원의 장', '국방기술품질원', '한국직업능력개발원', '화학물질안전원장', '고위공직자범죄수사처', '국세심사위원회', '통제권자', '군교도관', '국가건축정책위원회', '치료감호심의위원회', '지방법원 판사', '검찰단장', '국가산학연협력위원회', '임상연구심의위원회', '방송분쟁조정위원회', '세무사징계위원회', '국립외교원', '추모위원회', '공공관리주체', '의약품안전관리원', '군검사', '관세심사위원회', '정부위원', '필수업무 지정 및 종사자', '국립환경인력개발원', '보관금을 납부한 자', '금융정보분석원', '금융분쟁조정위원회', '중요지표사용기관', '외국인보호소', '신속대응팀', '대체복무기관', '재난원인조사단', '교원소청심사위원회', '국무조정실', '산업융합 규제특례심의위원회', '주재무관', '법무연수원', '치료감호소', '한국해양교통안전공단', '중앙감염병병원', '국가인적자원위원회', '국민경제자문회의', '국가정보자원관리원장', '교도관', '아동자립지원추진협의회', '물류관련기관', '지방과학기술진흥협의회', '산업재해보상보험및예방심의위원회', '화학물질관리위원회', '소년원학교', '교수임용심의위원회', '중앙소음대책심의위원회', '소관부', '한국재정정보원', '수의사 국가시험위원회', '국가병원체자원은행', '지방고용노동청', '범죄피해재산환부심의회', '남극활동감시원', '재정운용위원회', '지방검찰청검사장', '환자안전위원회', '치료감호시설의 장', '산림탄소센터', '중증질환심의위원회', '통합환경관리정보공개심의위원회', '아동정책조정위원회', '군인복지위원회', '연구기관의 원장 및 감사', '금융감독위원회', '지방검찰청지청', '군사안보지원사령부', '행정자치부장관', '직할부대장', '중앙 사회서비스원', '전직 대통령', '검사위원회', '명예회복위원회', '국가표준심의회', '2023 순천만국제정원박람회조직위원회', '관서운영경비출납공무원', '우정사업본부', '중앙생활보장위원회', '군검찰관', '국가보안기관', '국립조직기증관리기관', '새만금청', '대검찰청', '여수ㆍ순천 10ㆍ19사건진상규명및희생자명예회복위원회', '북한인권기록보존소', '갈등관리심의위원회', '정책기획위원회', '정보수사기관', '맞춤형화장품판매업자', '수출지원기관', '한센인피해사건진상규명위원회', '청년고용촉진특별위원', '보안관찰처분심의위원회', '공공자금관리기금운용위원회', '미래창조과학부', '운영심의회', '공공데이터 포털', '분과위원회', '보험요율 산출기관', '한국산업안전보건공단', '농수산물품질관리심의회', '의무소방대 소속 기관', '특별검사', '가석방심사위원회', '국내복귀기업지원위원회', '공군작전사령관', '복지사업심의위원회', '화학물질평가위원회', '형사사법업무 처리기관 소속 공무원', '남북관계발전위원회', '자동차손해배상진흥원', '자격정책심의회', '군정비부대', '재원운영자', '이행관리원', '국립공원위원회', '국방개혁위원회', '일반군무원', '지하개발사업자', '공군참모총장', '장성급 지휘관', '한국교육학술정보원장', '출입국관리사무소출장소장', '군판사', '군사경찰부대의 지휘관', '통관지 세관장', '우정사업총괄기관', '중앙책임운영기관', '방송문화진흥회', '디엔에이인적관리자', '예탁결제원', '회계 관계 공무원', '신체등급판정 사무를 담당하는 병무청 소속기관', '긴급재정관리인', '보통징계위원회', '지방세무관서', '국가책임기관', '대사관', '특별노동위원회', '국가통계위원회', '유치장', '중앙사무관장기관', '국방부직할부대', '검역소', '징계권자의 부대', '고용정책심의회', '금고은행', '석면안전관리위원회', '특별검사후보추천위원회', '복무 기관', '통관지세관장', '전적학교', '대한소방공제회', '정부청사관리소', '임면권자', '법무부징계위원회', '면직심사위원회', '수형자', '심판장', '대한약전', '사세청', '유료도로관리청', '시ㆍ도 경제협의회', '근로시간면제심의위원회', '해양항만청장', '교수징계위원회', '국가경찰기관', '특례심의위원회', '한국인원자폭탄피해자지원위원회', '한국보건산업진흥원장', '갱생보호회지소장', '해군작전사령관', '전자수입인지업무대행기관', '국제감축심의회', '우체국보험특별회계', '진급권자', '융자기관', '보수지급기관', '최저임금위원회', '출국항 관할 세관장', '세관공무원', '화장품책임판매업자', '중증장애인생산품우선구매촉진위원회', '국가테러대책위원회', '중앙징계위원회', '제품검사기관', '수출입은행', '대한상공회의소', '북방경제협력위원회', '기상관측표준화위원회', '특별감찰관', '경제자유구역위원회', '중요지표산출기관', '실무조정회의', '처우ㆍ징계위원회', '경제교육단체', '우체국예금특별회계', '공관장', '방송통신심의위원회', '국가시범도시지원단', '사학분쟁조정위원회', '군종장교운영심사위원회', '참모총장', '식품산업진흥심의회', '소방장비관리 공무원', '중앙심판원', '해양경찰기관', '심판관', '발행은행', '작전지휘관', '사법연수원', '국가건강검진위원회', '도로교통공단', '국방관서', '세입징수관', '계약상대방', '주채무자', '한국인터넷진흥원', '한국장학재단', '국가수자원관리위원회', '유료도로관리권자', '대한민국재외공관', '한국의료기기안전정보원', '보험료부과제도개선위원회', '방위사업청', '행정부 내 각급 기관', '데이터전문기관', '징발집행관', '중앙기록물관리기관', '과제담당관', '납북피해자보상및지원심의위원회', '에너지위원회', '보세판매장 제도운영위원회', '경제사회노동위원회', '중앙응급의료위원회', '국정원', '국가헌혈추진협의회', '건축허가관청', '국가공간정보위원회', '의료기관인증위원회', '디자인권자', '건강보험분쟁조정위원회', '관세청', '공무원연금공단', '지역특화작목위원회', '책임운영기관의 장', '중앙주소정보위원회', '국사편찬위원회', '중소기업은행', '한국보건의료인국가시험원', '운송수단의 장', '예금보험공사', '보훈심사위원회', '근로감독관', '업무를 인계ㆍ인수하는 사람', '보행환경정책연구센터', '검찰서기', '국립재활원', '발굴단', '순회점검 공무원'}\n개수: 563\n==================\n지방사무에만 존재\n주체: {'면허의 부여기관', '징수공무원', '시ㆍ군ㆍ구대책본부', '공원수탁관리자', '우리나라의 권한 있는 당국', '명예시장', '지역민방위협의회', '부구청장', '재생사업지구지정권자', '지방보조사업자', '시ㆍ도교육위원회', '지역발달장애인지원센터', '충청북도', '범칙사건조사공무원', '시·군·구의 관할 보건소', '시ㆍ도특수교육운영위원회', '법제심의위원회', '대장소관청', '제주특별자치도세관장', '시ㆍ군ㆍ구기록물관리기관', '시ㆍ도 안전관리위원회', '등기ㆍ등록관서', '예산성과금심사위원회', '시ㆍ도대책본부', '권한을 대행하는 사람', '현장지휘관', '시·도위원회', '정신건강심의위원회', '검정고시위원회', '통합지휘조정통제센터', '사학정비심사위원회', '지방자치단체의 금고', '지역환경보건위원회', '시ㆍ도교육과정정상화심의위원회', '시ㆍ도기록물관리기관', '시ㆍ군ㆍ구 통합방위협의회', '시ㆍ도 협의회', '어항관리청', '제주자치도경찰청', '지역인적자원개발협의회', '시ㆍ도주소정보위원회', '여수ㆍ순천 10ㆍ19사건진상규명및희생자명예회복실무위원회', '시ㆍ도 공공보건의료위원회', '중학교입학추첨관리위원회', '스마트도시사업협의회', '시ㆍ군ㆍ구긴급구조통제단', '학력심의위원회', '시ㆍ도 사회서비스원', '충청북도지사', '의료기관개설위원회', '사용신고관청', '구ㆍ시ㆍ읍ㆍ면', '지방탄소중립녹색성장위원회', '시ㆍ군ㆍ구주소정보위원회', '사업승인권자', '가축전염병피해보상협의회', '자치경찰인사위원회', '해안권발전공동협의회', '국가교육위원회', '지방자치단체의 인사위원회', '사무과', '공공시설을 관리하는 자', '한국주택금융공사', '시ㆍ도긴급구조통제단', '면허부여기관', '부군수', '해양수산인재개발원장', '수급자격심의위원회', '신청지방자치단체', '스마트도시기반시설의 관리청', '예치기관', '진단자문위원회', '전국적 협의체', '시ㆍ군ㆍ구특수교육운영위원회', '수렵장설정자', '공공하수도를 설치하고자 하는 자', '시ㆍ도심리지원단', '보건지소', '지방자치인재개발원 원장', '기금관리조합', '시ㆍ군ㆍ구 안전관리위원회', '시·군위원회', '긴급구조관련기관', '공공하수도를 설치하려는 자', '시ㆍ도선거관리위원회', '부단체장', '공공처리시설설치자', '지방직영기업의 관리자', '학교도서관발전위원회', '승진후보자 명부 작성단위 기관', '시ㆍ도응급의료위원회', '기초정신건강심의위원회', '학교안전공제회', '도시공원위원회', '시ㆍ도인사위원회'}\n개수: 95\n==================\n공동사무에만 존재\n주체: {'상수도사업소', '감사활동을 수행하는 사람', '공항개발사업시행자', '공원사무소', '국유재산 관리청', '기금수탁자', '안산시', '국공립 연구소', '비관리청', '교육책임자', '청원기관의 장', '경계변경협의체', '한국문화예술위원회 위원장', '승진대상자명부 작성기관', '평생교육시설의 설립자ㆍ경영자', '중앙재난안전대책본부의 본부장', '징계의결 요구권자', '전산관리지정기관', '교육관련기관의 장', '한국철도시설공단', '행정협의조정위원회', '댐수탁관리자', '민방위 경보 통제소', '사립학교를 설치ㆍ경영하는 자', '협의체ㆍ연합체의 대표자', '공직유관단체', '한국수자원공사 사장', '아동학대 신고의무자가 소속된 기관ㆍ시설 등', '영재교육기관', '씨름단체', '방제조치기관', '경영책임자', '인가관청', '공항시설관리자', '울산광역시'}\n개수: 35\n==================\n\n\n\n# '국가'사무에만 존재하는 수행주체\ndf_1['수행주체_국가'] = df_1['조문'].apply(lambda x: sum(word in x for word in unique_country))\n# '지방' 사무에만 존재하는 수행주체\ndf_1['수행주체_지방'] = df_1['조문'].apply(lambda x: sum(word in x for word in unique_province))\n# '공동' 사무에만 존재하는 수행주체\ndf_1['수행주체_공동'] = df_1['조문'].apply(lambda x: sum(word in x for word in unique_both))\n\n\n# '국가' 사무에 들어있는 모든 수행주체\ndf_1['수행주체_국가_교'] = df_1['조문'].apply(lambda x: sum(word in x for word in set_country))\n# '지방' 사무에 들어있는 모든 수행주체\ndf_1['수행주체_지방_교'] = df_1['조문'].apply(lambda x: sum(word in x for word in set_province))\n# '공동' 사무에 들어있는 모든 수행주체\ndf_1['수행주체_공동_교'] = df_1['조문'].apply(lambda x: sum(word in x for word in set_both))\n\n\ndf_1[['수행주체_국가_교', '수행주체_지방_교', '수행주체_공동_교']].sum()\n\n수행주체_국가_교    230786\n수행주체_지방_교    224007\n수행주체_공동_교    224662\ndtype: int64\n\n\n\n\n3rd column 생성\n\n‘수행주체_국가n’: 행별로 ’new_수행주체’가 ’국가사무’에서 언급된 횟수 sum\n‘수행주체_지방n’: 행별로 ’new_수행주체’가 ’지방사무’에서 언급된 횟수 sum\n‘수행주체_공동n’: 행별로 ’new_수행주체’가 ’공동사무’에서 언급된 횟수 sum\n\n\n# subject_dic 만들기\nsubject_dic = {}\nfor subject in subject_list:\n    count_country = df_country['조문'].str.contains(subject).sum()\n    count_province = df_province['조문'].str.contains(subject).sum()\n    count_both = df_both['조문'].str.contains(subject).sum()\n    subject_dic[subject] = [count_country, count_province, count_both]\n\n\ndf['수행주체_국가n'] = 0\ndf['수행주체_지방n'] = 0\ndf['수행주체_공동n'] = 0\n\nfor i in tqdm(range(df.shape[0]), desc=\"Processing rows\"):\n    text = df.iloc[i, 5]\n    for subject in subject_list:\n        if subject in text:\n            df.at[i, '수행주체_국가n'] += subject_dic[subject][0]\n            df.at[i, '수행주체_지방n'] += subject_dic[subject][1]\n            df.at[i, '수행주체_공동n'] += subject_dic[subject][2]\n\n\n\n4th column 생성: 법령명\n\npd.set_option('display.max_colwidth',None)\npd.set_option('display.max_rows',None)\n\n\n# '시행규칙', '시행령' 제거\ndf_1['법령명'] = df_1['법령명'].apply(lambda x: re.sub(r'\\s?시행령|\\s?시행규칙', '', x))\n\n\ndf_1['법령명'].nunique()\n\n1950\n\n\n\n\n5th column 생성: 법령구분\n\npd.crosstab(df_1['법령구분'], df_1['사무유형(대분류)'])\n\n\n  \n    \n\n\n\n\n\n사무유형(대분류)\n공동\n국가\n지방\n\n\n법령구분\n\n\n\n\n\n\n\n1\n5939\n29751\n7567\n\n\n2\n577\n6293\n1295\n\n\n3\n158\n2443\n523"
  },
  {
    "objectID": "dev_posts/수민_사무유형구분_머신러닝.html#모델링",
    "href": "dev_posts/수민_사무유형구분_머신러닝.html#모델링",
    "title": "사무유형구분_Random Forest",
    "section": "2. 모델링",
    "text": "2. 모델링\n\n0) train-test split\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n\nX = df_1[['법령명', '법령구분', '수행주체_freq1', '수행주체_freq2', '수행주체_freq3', '수행주체_국가', '수행주체_지방', '수행주체_공동', '수행주체_국가_교', '수행주체_지방_교', '수행주체_공동_교']]\ny = df_1['사무유형(대분류)']\n\n\nstratified_splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train_index, val_index in stratified_splitter.split(X, y):\n    X_train = X.iloc[train_index]\n    y_train = y.iloc[train_index]\n    X_test = X.iloc[val_index]\n    y_test = y.iloc[val_index]\n\n\n# '법령명' label encoding 진행\nencoder = LabelEncoder()\nX_train['법령명'] = encoder.fit_transform(X_train['법령명']) # train set에는 fit_transform\n\nfor label in X_test['법령명']:\n    if label not in encoder.classes_:\n        encoder.classes_ = np.append(encoder.classes_,label)\n\nX_test['법령명'] = encoder.transform(X_test['법령명']) # test set에는 transform\n\nSettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_train['법령명'] = encoder.fit_transform(X_train['법령명']) # train set에는 fit_transform\n&lt;ipython-input-42-5ddf05ec193a&gt;:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_test['법령명'] = encoder.transform(X_test['법령명']) # test set에는 transform\n\n\n\n\n1) random forest\n\n# RandomForest Classifier\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ny_pred_proba = model.predict_proba(X_test)\nprint(y_pred_proba)\n\nprint(classification_report(y_test, y_pred))\n\nconf_matrix = confusion_matrix(y_test, y_pred)\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()\n\n[[0.         1.         0.        ]\n [0.13933333 0.86066667 0.        ]\n [0.         1.         0.        ]\n ...\n [0.44478175 0.41347672 0.14174154]\n [0.36       0.64       0.        ]\n [0.         0.74428571 0.25571429]]\n              precision    recall  f1-score   support\n\n          공동       0.53      0.48      0.50      1335\n          국가       0.88      0.89      0.89      7698\n          지방       0.65      0.64      0.65      1877\n\n    accuracy                           0.80     10910\n   macro avg       0.68      0.67      0.68     10910\nweighted avg       0.80      0.80      0.80     10910\n\n\n\n\n\n\n\nimportance = model.feature_importances_\nser = pd.Series(importance, index = X.columns)\n\n# 가장 중요한 feature 순으로 정렬\nimportance_sort = ser.sort_values(ascending=False)\nplt.figure(figsize=(8,6))\nplt.title('Feature Importances')\nsns.barplot(x=importance_sort, y=importance_sort.index)\nplt.show()"
  }
]